#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•´åˆä¸¦ç¯©é¸ 2.1-1 é†«ç™‚æœå‹™å“è³ªç†è«–æ–‡ç»
åˆä½µå…©æ¬¡æœå°‹çµæœï¼ˆ131+92=223ç¯‡ï¼‰ï¼Œç¯©é¸é«˜å“è³ªé†«ç™‚ç›¸é—œæ–‡ç»
"""

import json
import csv
import os

def load_json(file_path):
    """è¼‰å…¥JSONæª”æ¡ˆ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def is_healthcare_related(paper):
    """åˆ¤æ–·æ˜¯å¦ç‚ºé†«ç™‚ç›¸é—œæ–‡ç»"""
    healthcare_keywords = [
        'health', 'hospital', 'medical', 'patient', 'clinical',
        'nursing', 'doctor', 'physician', 'care', 'healthcare',
        'treatment', 'disease', 'clinic', 'surgery', 'pharmacy'
    ]

    # æª¢æŸ¥æ¨™é¡Œã€æœŸåˆŠã€æ‘˜è¦
    text = (
        paper.get('title', '').lower() + ' ' +
        paper.get('journal', '').lower() + ' ' +
        paper.get('abstract', '').lower()
    )

    return any(kw in text for kw in healthcare_keywords)

def has_theory_keywords(paper):
    """åˆ¤æ–·æ˜¯å¦åŒ…å«ç†è«–é—œéµè©"""
    theory_keywords = [
        'SERVQUAL', 'Donabedian', 'SERVPERF', 'Parasuraman',
        'service quality theory', 'quality framework', 'quality model',
        'quality dimensions', 'quality assessment'
    ]

    text = (
        paper.get('title', '') + ' ' +
        paper.get('abstract', '') + ' ' +
        paper.get('keywords', '')
    ).upper()

    return any(kw.upper() in text for kw in theory_keywords)

def should_keep_paper(paper):
    """åˆ¤æ–·æ˜¯å¦æ‡‰è©²ä¿ç•™æ­¤æ–‡ç»"""
    citations = int(paper.get('citations', 0))

    # ä¿ç•™æ¢ä»¶ï¼ˆä»»ä¸€ç¬¦åˆå³ä¿ç•™ï¼‰ï¼š
    # 1. é†«ç™‚ç›¸é—œ AND (å¼•ç”¨>5æ¬¡ OR åŒ…å«ç†è«–é—œéµè©)
    # 2. å¼•ç”¨>10æ¬¡ï¼ˆå³ä½¿éé†«ç™‚ï¼‰
    # 3. åŒ…å«å¤šå€‹ç†è«–é—œéµè©

    is_healthcare = is_healthcare_related(paper)
    has_theory = has_theory_keywords(paper)

    if citations > 10:
        return True

    if is_healthcare and (citations > 5 or has_theory):
        return True

    if has_theory and citations > 3:
        return True

    return False

def merge_and_filter():
    """åˆä½µä¸¦ç¯©é¸æ–‡ç»"""

    # æª”æ¡ˆè·¯å¾‘
    base_dir = "Literature_Review/Chapter_2.1_Healthcare_Service_Quality"
    file1 = f"{base_dir}/2.1-1_revised_é†«ç™‚æœå‹™å“è³ªåŸºç¤ç†è«–.json"
    file2 = f"{base_dir}/2.1-1_classic_theories_ç¶“å…¸æœå‹™å“è³ªç†è«–.json"

    print("=" * 80)
    print("ğŸ“š æ•´åˆä¸¦ç¯©é¸ 2.1-1 é†«ç™‚æœå‹™å“è³ªç†è«–æ–‡ç»")
    print("=" * 80)

    # è¼‰å…¥å…©å€‹æª”æ¡ˆ
    print(f"\nğŸ“– è¼‰å…¥æ–‡ç»...")
    papers1 = load_json(file1)
    papers2 = load_json(file2)

    print(f"   æª”æ¡ˆ1ï¼ˆrevisedï¼‰ï¼š{len(papers1)} ç¯‡")
    print(f"   æª”æ¡ˆ2ï¼ˆclassicï¼‰ï¼š{len(papers2)} ç¯‡")
    print(f"   ç¸½è¨ˆï¼š{len(papers1) + len(papers2)} ç¯‡")

    # åˆä½µä¸¦å»é‡ï¼ˆæ ¹æ“šDOIæˆ–UIDï¼‰
    print(f"\nğŸ”„ åˆä½µä¸¦å»é‡...")
    all_papers = {}

    for paper in papers1 + papers2:
        # ä½¿ç”¨ DOI æˆ– UID ä½œç‚ºå”¯ä¸€è­˜åˆ¥
        key = paper.get('doi', '') or paper.get('uid', '')
        if key and key not in all_papers:
            all_papers[key] = paper
        elif not key:
            # å¦‚æœæ²’æœ‰DOIå’ŒUIDï¼Œä½¿ç”¨æ¨™é¡Œ
            title_key = paper.get('title', '')
            if title_key and title_key not in [p.get('title', '') for p in all_papers.values()]:
                all_papers[title_key] = paper

    merged_papers = list(all_papers.values())
    print(f"   å»é‡å¾Œï¼š{len(merged_papers)} ç¯‡")

    # ç¯©é¸é«˜å“è³ªæ–‡ç»
    print(f"\nğŸ” ç¯©é¸é«˜å“è³ªé†«ç™‚ç›¸é—œæ–‡ç»...")
    print(f"   ç¯©é¸æ¢ä»¶ï¼š")
    print(f"   1. é†«ç™‚ç›¸é—œ AND (å¼•ç”¨>5æ¬¡ OR åŒ…å«ç†è«–é—œéµè©)")
    print(f"   2. å¼•ç”¨>10æ¬¡ï¼ˆå³ä½¿éé†«ç™‚ï¼‰")
    print(f"   3. åŒ…å«ç†è«–é—œéµè© AND å¼•ç”¨>3æ¬¡")

    filtered_papers = [p for p in merged_papers if should_keep_paper(p)]

    print(f"\nâœ… ç¯©é¸çµæœï¼š{len(filtered_papers)} ç¯‡ï¼ˆä¿ç•™ç‡ {len(filtered_papers)/len(merged_papers)*100:.1f}%ï¼‰")

    # æŒ‰å¼•ç”¨æ¬¡æ•¸æ’åº
    filtered_papers_sorted = sorted(filtered_papers, key=lambda x: int(x.get('citations', 0)), reverse=True)

    # çµ±è¨ˆåˆ†æ
    print(f"\nğŸ“Š ç¯©é¸å¾Œæ–‡ç»çµ±è¨ˆï¼š")

    # é†«ç™‚ç›¸é—œçµ±è¨ˆ
    healthcare_count = sum(1 for p in filtered_papers_sorted if is_healthcare_related(p))
    print(f"   é†«ç™‚ç›¸é—œï¼š{healthcare_count} ç¯‡ï¼ˆ{healthcare_count/len(filtered_papers_sorted)*100:.1f}%ï¼‰")

    # ç†è«–é—œéµè©çµ±è¨ˆ
    theory_count = sum(1 for p in filtered_papers_sorted if has_theory_keywords(p))
    print(f"   å«ç†è«–é—œéµè©ï¼š{theory_count} ç¯‡ï¼ˆ{theory_count/len(filtered_papers_sorted)*100:.1f}%ï¼‰")

    # å¼•ç”¨æ¬¡æ•¸çµ±è¨ˆ
    citations = [int(p.get('citations', 0)) for p in filtered_papers_sorted]
    print(f"   å¹³å‡å¼•ç”¨ï¼š{sum(citations)/len(citations):.1f} æ¬¡")
    print(f"   å¼•ç”¨ç¯„åœï¼š{min(citations)}-{max(citations)} æ¬¡")

    # å¹´ä»½åˆ†å¸ƒ
    year_dist = {}
    for p in filtered_papers_sorted:
        year = p.get('year', 'N/A')
        year_dist[year] = year_dist.get(year, 0) + 1

    print(f"\nğŸ“… å¹´ä»½åˆ†å¸ƒï¼ˆå‰10å¹´ï¼‰ï¼š")
    sorted_years = sorted(year_dist.items(), key=lambda x: x[1], reverse=True)[:10]
    for year, count in sorted_years:
        print(f"   {year}: {count} ç¯‡")

    # é¡¯ç¤ºé«˜å¼•ç”¨æ–‡ç»ï¼ˆTop 15ï¼‰
    print(f"\nğŸŒŸ é«˜å¼•ç”¨æ–‡ç»ï¼ˆTop 15ï¼‰ï¼š")
    print("=" * 80)
    for i, p in enumerate(filtered_papers_sorted[:15], 1):
        citations = int(p.get('citations', 0))
        title = p.get('title', 'N/A')
        year = p.get('year', 'N/A')
        journal = p.get('journal', 'N/A')

        is_hc = "ğŸ¥" if is_healthcare_related(p) else "  "
        has_th = "ğŸ“š" if has_theory_keywords(p) else "  "

        print(f"\n{i}. [{year}] è¢«å¼• {citations} æ¬¡ {is_hc}{has_th}")
        print(f"   {title[:90]}...")
        print(f"   {journal[:70]}")

    print(f"\nğŸ’¡ åœ–ç¤ºèªªæ˜ï¼šğŸ¥=é†«ç™‚ç›¸é—œ ğŸ“š=å«ç†è«–é—œéµè©")

    # å„²å­˜çµæœ
    output_base = f"{base_dir}/2.1-1_FINAL_é†«ç™‚æœå‹™å“è³ªåŸºç¤ç†è«–"

    # å„²å­˜ JSON
    with open(f"{output_base}.json", 'w', encoding='utf-8') as f:
        json.dump(filtered_papers_sorted, f, ensure_ascii=False, indent=2)

    # å„²å­˜ CSV
    if filtered_papers_sorted:
        fieldnames = ['title', 'authors', 'year', 'journal', 'doi', 'uid',
                     'countries', 'abstract', 'citations', 'references',
                     'keywords', 'subtypeDescription']

        with open(f"{output_base}.csv", 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for paper in filtered_papers_sorted:
                # ç¢ºä¿æ‰€æœ‰æ¬„ä½éƒ½å­˜åœ¨
                row = {field: paper.get(field, '') for field in fieldnames}
                writer.writerow(row)

    print(f"\nğŸ’¾ çµæœå·²å„²å­˜ï¼š")
    print(f"   - {output_base}.json")
    print(f"   - {output_base}.csv")

    # ç”Ÿæˆç¯©é¸å ±å‘Š
    report_file = f"{base_dir}/2.1-1_FILTERING_REPORT.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# 2.1-1 é†«ç™‚æœå‹™å“è³ªåŸºç¤ç†è«–æ–‡ç»ç¯©é¸å ±å‘Š\n\n")
        f.write(f"**ç”Ÿæˆæ™‚é–“**ï¼š{os.popen('date').read().strip()}\n\n")
        f.write("---\n\n")

        f.write("## ğŸ“Š ç¯©é¸æµç¨‹\n\n")
        f.write(f"1. **åˆå§‹æ–‡ç»**ï¼š{len(papers1) + len(papers2)} ç¯‡\n")
        f.write(f"   - æœå°‹1ï¼ˆrevisedï¼‰ï¼š{len(papers1)} ç¯‡\n")
        f.write(f"   - æœå°‹2ï¼ˆclassicï¼‰ï¼š{len(papers2)} ç¯‡\n\n")
        f.write(f"2. **å»é‡å¾Œ**ï¼š{len(merged_papers)} ç¯‡\n\n")
        f.write(f"3. **ç¯©é¸å¾Œ**ï¼š{len(filtered_papers_sorted)} ç¯‡\n")
        f.write(f"   - ä¿ç•™ç‡ï¼š{len(filtered_papers_sorted)/len(merged_papers)*100:.1f}%\n\n")

        f.write("---\n\n")
        f.write("## ğŸ” ç¯©é¸æ¢ä»¶\n\n")
        f.write("ä¿ç•™æ–‡ç»éœ€ç¬¦åˆä»¥ä¸‹**ä»»ä¸€æ¢ä»¶**ï¼š\n\n")
        f.write("1. **é†«ç™‚ç›¸é—œ** AND (**å¼•ç”¨>5æ¬¡** OR **åŒ…å«ç†è«–é—œéµè©**)\n")
        f.write("2. **å¼•ç”¨>10æ¬¡**ï¼ˆå³ä½¿éé†«ç™‚ï¼‰\n")
        f.write("3. **åŒ…å«ç†è«–é—œéµè©** AND **å¼•ç”¨>3æ¬¡**\n\n")

        f.write("**é†«ç™‚é—œéµè©**ï¼šhealth, hospital, medical, patient, clinical, nursing, doctor, physician, care, treatment, disease, clinic, surgery, pharmacy\n\n")
        f.write("**ç†è«–é—œéµè©**ï¼šSERVQUAL, Donabedian, SERVPERF, Parasuraman, service quality theory, quality framework, quality model, quality dimensions, quality assessment\n\n")

        f.write("---\n\n")
        f.write("## ğŸ“ˆ ç¯©é¸çµæœçµ±è¨ˆ\n\n")
        f.write(f"- **é†«ç™‚ç›¸é—œ**ï¼š{healthcare_count} ç¯‡ï¼ˆ{healthcare_count/len(filtered_papers_sorted)*100:.1f}%ï¼‰\n")
        f.write(f"- **å«ç†è«–é—œéµè©**ï¼š{theory_count} ç¯‡ï¼ˆ{theory_count/len(filtered_papers_sorted)*100:.1f}%ï¼‰\n")
        f.write(f"- **å¹³å‡å¼•ç”¨**ï¼š{sum(citations)/len(citations):.1f} æ¬¡\n")
        f.write(f"- **å¼•ç”¨ç¯„åœ**ï¼š{min(citations)}-{max(citations)} æ¬¡\n\n")

        f.write("---\n\n")
        f.write("## ğŸŒŸ Top 20 é«˜å¼•ç”¨æ–‡ç»\n\n")
        for i, p in enumerate(filtered_papers_sorted[:20], 1):
            citations = int(p.get('citations', 0))
            title = p.get('title', 'N/A')
            year = p.get('year', 'N/A')
            journal = p.get('journal', 'N/A')

            is_hc = "ğŸ¥" if is_healthcare_related(p) else ""
            has_th = "ğŸ“š" if has_theory_keywords(p) else ""

            f.write(f"### {i}. [{year}] è¢«å¼• {citations} æ¬¡ {is_hc}{has_th}\n\n")
            f.write(f"**æ¨™é¡Œ**ï¼š{title}\n\n")
            f.write(f"**æœŸåˆŠ**ï¼š{journal}\n\n")
            f.write(f"**DOI**ï¼š{p.get('doi', 'N/A')}\n\n")
            f.write("---\n\n")

    print(f"   - {report_file}")

    print(f"\nâœ… æ•´åˆç¯©é¸å®Œæˆï¼")
    print("=" * 80)

if __name__ == "__main__":
    merge_and_filter()
