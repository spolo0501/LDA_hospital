#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‹±åœ‹é†«é™¢è©•è«–è³‡æ–™å‰è™•ç†
åŠŸèƒ½ï¼š
1. åˆä½µ 20 å®¶è‹±åœ‹é†«é™¢çš„ Google è©•è«–è³‡æ–™
2. ç¯©é¸æœ€è¿‘ä¸€å¹´çš„è©•è«–
3. åˆªé™¤ç©ºç™½è©•è«–
4. æº–å‚™ LDA åˆ†æçš„è³‡æ–™
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("UK Hospital Reviews - Data Preprocessing")
print("è‹±åœ‹é†«é™¢è©•è«– - è³‡æ–™å‰è™•ç†")
print("="*80)

# è¨­å®šè·¯å¾‘
data_dir = Path("google_reviews_output/hospitals/uk/")
output_dir = Path("data/processed/hospitals/uk/")
output_dir.mkdir(parents=True, exist_ok=True)

print(f"\nğŸ“‚ è³‡æ–™ä¾†æº: {data_dir}")
print(f"ğŸ“‚ è¼¸å‡ºç›®éŒ„: {output_dir}")

# è¼‰å…¥æ‰€æœ‰é†«é™¢çš„è©•è«–
print("\n" + "="*80)
print("è¼‰å…¥è©•è«–è³‡æ–™...")
print("="*80)

all_reviews = []
csv_files = list(data_dir.glob("*.csv"))
# æ’é™¤ stats æª”æ¡ˆ
csv_files = [f for f in csv_files if "_stats.csv" not in f.name]

print(f"æ‰¾åˆ° {len(csv_files)} å€‹é†«é™¢è³‡æ–™æª”æ¡ˆ\n")

for csv_file in sorted(csv_files):
    hospital_name = csv_file.stem
    try:
        df = pd.read_csv(csv_file, encoding='utf-8-sig')
        print(f"âœ“ {hospital_name:<40} {len(df):>6,} æ¢è©•è«–")

        # æ–°å¢é†«é™¢åç¨±æ¬„ä½
        df['hospital_name'] = hospital_name
        all_reviews.append(df)

    except Exception as e:
        print(f"âœ— {hospital_name:<40} è¼‰å…¥å¤±æ•—: {e}")

# åˆä½µæ‰€æœ‰è³‡æ–™
df_all = pd.concat(all_reviews, ignore_index=True)
print(f"\n{'='*80}")
print(f"âœ“ ç¸½è¨ˆè¼‰å…¥ {len(df_all):,} æ¢è©•è«–ï¼Œä¾†è‡ª {len(all_reviews)} å®¶é†«é™¢")
print(f"{'='*80}")

# æª¢è¦–è³‡æ–™çµæ§‹
print("\nè³‡æ–™æ¬„ä½:")
print(df_all.columns.tolist())
print(f"\nè³‡æ–™ç¶­åº¦: {df_all.shape}")

# çµ±è¨ˆè³‡è¨Š
print(f"\n{'='*80}")
print("åŸå§‹è³‡æ–™çµ±è¨ˆ")
print(f"{'='*80}")
print(f"ç¸½è©•è«–æ•¸: {len(df_all):,}")
print(f"è©•è«–å…§å®¹ç©ºç™½: {df_all['è©•è«–å…§å®¹'].isna().sum():,} ({df_all['è©•è«–å…§å®¹'].isna().sum()/len(df_all)*100:.1f}%)")
print(f"è©•è«–å…§å®¹ç‚ºç©ºå­—ä¸²: {(df_all['è©•è«–å…§å®¹'].str.strip() == '').sum():,}")

# è©•åˆ†åˆ†å¸ƒ
print(f"\nè©•åˆ†åˆ†å¸ƒ:")
rating_dist = df_all['è©•åˆ†'].value_counts().sort_index()
for rating, count in rating_dist.items():
    percentage = count / len(df_all) * 100
    print(f"  {rating} æ˜Ÿ: {count:>6,} ({percentage:>5.1f}%)")
print(f"  å¹³å‡è©•åˆ†: {df_all['è©•åˆ†'].mean():.2f} æ˜Ÿ")

# è™•ç†æ—¥æœŸ
print(f"\n{'='*80}")
print("è™•ç†è©•è«–æ—¥æœŸ...")
print(f"{'='*80}")

def parse_relative_date(date_str):
    """è§£æç›¸å°æ—¥æœŸï¼ˆä¾‹å¦‚ï¼š'a day ago', '3 weeks ago'ï¼‰"""
    if pd.isna(date_str):
        return None

    date_str = str(date_str).lower().strip()
    now = datetime.now()

    # è™•ç†å„ç¨®ç›¸å°æ™‚é–“æ ¼å¼
    if 'hour' in date_str or 'hours' in date_str:
        hours = int(''.join(filter(str.isdigit, date_str))) if any(c.isdigit() for c in date_str) else 1
        return now - timedelta(hours=hours)
    elif 'day' in date_str or 'days' in date_str:
        days = int(''.join(filter(str.isdigit, date_str))) if any(c.isdigit() for c in date_str) else 1
        return now - timedelta(days=days)
    elif 'week' in date_str or 'weeks' in date_str:
        weeks = int(''.join(filter(str.isdigit, date_str))) if any(c.isdigit() for c in date_str) else 1
        return now - timedelta(weeks=weeks)
    elif 'month' in date_str or 'months' in date_str:
        months = int(''.join(filter(str.isdigit, date_str))) if any(c.isdigit() for c in date_str) else 1
        return now - timedelta(days=months*30)
    elif 'year' in date_str or 'years' in date_str:
        years = int(''.join(filter(str.isdigit, date_str))) if any(c.isdigit() for c in date_str) else 1
        return now - timedelta(days=years*365)
    else:
        return None

df_all['parsed_date'] = df_all['è©•è«–æ—¥æœŸ'].apply(parse_relative_date)

# çµ±è¨ˆæœ‰æ•ˆæ—¥æœŸ
valid_dates = df_all['parsed_date'].notna().sum()
print(f"âœ“ æˆåŠŸè§£æ {valid_dates:,} æ¢è©•è«–çš„æ—¥æœŸ ({valid_dates/len(df_all)*100:.1f}%)")

# ç¯©é¸æœ€è¿‘ä¸€å¹´çš„è©•è«–
one_year_ago = datetime.now() - timedelta(days=365)
df_recent = df_all[df_all['parsed_date'] >= one_year_ago].copy()

print(f"\nç¯©é¸çµæœ:")
print(f"  åŸå§‹è©•è«–æ•¸: {len(df_all):,}")
print(f"  æœ€è¿‘ä¸€å¹´è©•è«–: {len(df_recent):,} ({len(df_recent)/len(df_all)*100:.1f}%)")
print(f"  æ—¥æœŸç¯„åœ: {one_year_ago.strftime('%Y-%m-%d')} ~ {datetime.now().strftime('%Y-%m-%d')}")

# æ¸…ç†è³‡æ–™
print(f"\n{'='*80}")
print("æ¸…ç†è³‡æ–™...")
print(f"{'='*80}")

# 1. åˆªé™¤ç©ºç™½è©•è«–
df_clean = df_recent.copy()
before_count = len(df_clean)

# åˆªé™¤è©•è«–å…§å®¹ç‚ºç©ºæˆ–åªæœ‰ç©ºç™½çš„
df_clean = df_clean[df_clean['è©•è«–å…§å®¹'].notna()].copy()
df_clean = df_clean[df_clean['è©•è«–å…§å®¹'].str.strip() != ''].copy()

after_count = len(df_clean)
removed = before_count - after_count

print(f"åˆªé™¤ç©ºç™½è©•è«–: {removed:,} æ¢")
print(f"ä¿ç•™è©•è«–æ•¸: {after_count:,}")

# 2. ç¢ºä¿è©•åˆ†æœ‰æ•ˆ
df_clean = df_clean[df_clean['è©•åˆ†'].notna()].copy()
df_clean = df_clean[df_clean['è©•åˆ†'].between(1, 5)].copy()

print(f"âœ“ è©•åˆ†æœ‰æ•ˆæª¢æŸ¥: {len(df_clean):,} æ¢è©•è«–")

# 3. çµ±è¨ˆæ¸…ç†å¾Œçš„è³‡æ–™
print(f"\n{'='*80}")
print("æ¸…ç†å¾Œè³‡æ–™çµ±è¨ˆ")
print(f"{'='*80}")
print(f"ç¸½è©•è«–æ•¸: {len(df_clean):,}")
print(f"ä¾†è‡ªé†«é™¢æ•¸: {df_clean['hospital_name'].nunique()}")
print(f"å¹³å‡è©•åˆ†: {df_clean['è©•åˆ†'].mean():.2f} æ˜Ÿ")

print(f"\nè©•åˆ†åˆ†å¸ƒ:")
rating_dist_clean = df_clean['è©•åˆ†'].value_counts().sort_index()
for rating, count in rating_dist_clean.items():
    percentage = count / len(df_clean) * 100
    print(f"  {rating} æ˜Ÿ: {count:>6,} ({percentage:>5.1f}%)")

print(f"\næ¯å®¶é†«é™¢çš„è©•è«–æ•¸:")
hospital_counts = df_clean['hospital_name'].value_counts()
for hospital, count in hospital_counts.items():
    print(f"  {hospital:<40} {count:>5,} æ¢")

# å„²å­˜æ¸…ç†å¾Œçš„è³‡æ–™
output_file = output_dir / "uk_hospitals_cleaned_recent_1year.csv"
df_clean.to_csv(output_file, index=False, encoding='utf-8-sig')
print(f"\n{'='*80}")
print(f"âœ“ æ¸…ç†å¾Œè³‡æ–™å·²å„²å­˜: {output_file}")
print(f"{'='*80}")

# ç”Ÿæˆæ‘˜è¦çµ±è¨ˆ
summary_stats = {
    'çµ±è¨ˆé …ç›®': [
        'åŸå§‹è©•è«–ç¸½æ•¸',
        'æœ€è¿‘ä¸€å¹´è©•è«–æ•¸',
        'åˆªé™¤ç©ºç™½è©•è«–æ•¸',
        'æœ€çµ‚æœ‰æ•ˆè©•è«–æ•¸',
        'æ¶µè“‹é†«é™¢æ•¸',
        'å¹³å‡è©•åˆ†',
        'æ—¥æœŸç¯„åœèµ·å§‹',
        'æ—¥æœŸç¯„åœçµæŸ',
        'è™•ç†æ—¥æœŸ'
    ],
    'æ•¸å€¼': [
        f"{len(df_all):,}",
        f"{len(df_recent):,}",
        f"{removed:,}",
        f"{len(df_clean):,}",
        f"{df_clean['hospital_name'].nunique()}",
        f"{df_clean['è©•åˆ†'].mean():.2f}",
        one_year_ago.strftime('%Y-%m-%d'),
        datetime.now().strftime('%Y-%m-%d'),
        datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    ]
}

summary_df = pd.DataFrame(summary_stats)
summary_file = output_dir / "uk_hospitals_preprocessing_summary.csv"
summary_df.to_csv(summary_file, index=False, encoding='utf-8-sig')
print(f"âœ“ è™•ç†æ‘˜è¦å·²å„²å­˜: {summary_file}")

print(f"\n{'='*80}")
print("è³‡æ–™å‰è™•ç†å®Œæˆï¼")
print(f"{'='*80}")
print(f"\nğŸ“ ç”Ÿæˆçš„æª”æ¡ˆ:")
print(f"   1. {output_file}")
print(f"   2. {summary_file}")
print(f"\nä¸‹ä¸€æ­¥: åŸ·è¡Œ LDA åˆ†æ")
