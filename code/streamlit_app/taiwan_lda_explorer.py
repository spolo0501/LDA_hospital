#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°ç£é†«é™¢ LDA ä¸»é¡Œåˆ†æžäº’å‹•å¼æ‡‰ç”¨ç¨‹å¼
ä½¿ç”¨ Streamlit å»ºç«‹äº’å‹•å¼ä»‹é¢ä¾†æŽ¢ç´¢å’Œæ¯”è¼ƒé†«é™¢è©•è«–çš„ä¸»é¡Œåˆ†ä½ˆ
"""

import streamlit as st
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
import jieba
import re
import os
warnings.filterwarnings('ignore')

# å°Žå…¥é†«é™¢åç¨±å°ç…§è¡¨å’Œä¸»é¡Œé…ç½®
import sys
sys.path.append(str(Path(__file__).parent))
from hospital_names import get_hospital_name, HOSPITAL_NAMES
from comparison_config import TAIWAN_TOPICS

# è¨­å®š matplotlib ä¸­æ–‡å­—é«”
# åœ¨ Streamlit Cloud ä¸Šéœ€è¦ç‰¹æ®Šè™•ç†
import matplotlib.font_manager as fm

def setup_chinese_font():
    """è¨­å®šä¸­æ–‡å­—åž‹ï¼Œæ”¯æ´æœ¬æ©Ÿå’Œ Streamlit Cloud"""
    import matplotlib

    # å¼·åˆ¶é‡æ–°è¼‰å…¥å­—åž‹ç®¡ç†å™¨
    matplotlib.font_manager._load_fontmanager(try_read_cache=False)

    # è¨­å®š matplotlib ä½¿ç”¨ sans-serif å­—åž‹ï¼Œä¸¦æŒ‡å®šå„ªå…ˆé †åº
    matplotlib.rcParams['font.family'] = 'sans-serif'
    matplotlib.rcParams['font.sans-serif'] = [
        'Noto Sans CJK TC',
        'Noto Sans CJK SC',
        'Noto Sans CJK JP',  # Streamlit Cloud å®‰è£çš„æ˜¯ JP ç‰ˆæœ¬
        'Noto Sans CJK KR',
        'Noto Sans TC',
        'Noto Sans SC',
        'DejaVu Sans',
        'Arial Unicode MS',
        'Microsoft YaHei',
        'SimHei',
        'STHeiti',
        'PingFang TC',
        'sans-serif'
    ]
    matplotlib.rcParams['axes.unicode_minus'] = False

    # æª¢æŸ¥å¯ç”¨å­—åž‹
    available_fonts = [f.name for f in matplotlib.font_manager.fontManager.ttflist]
    found_fonts = [f for f in matplotlib.rcParams['font.sans-serif'] if f in available_fonts]

    if found_fonts:
        print(f"âœ… æ‰¾åˆ°ä¸­æ–‡å­—åž‹: {found_fonts[0]}")
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°å„ªå…ˆå­—åž‹ï¼Œä½¿ç”¨ç³»çµ±é è¨­")
        print(f"   å¯ç”¨çš„ Noto å­—åž‹: {[f for f in available_fonts if 'Noto' in f][:3]}")

# åœ¨è¼‰å…¥æ™‚è¨­å®šä¸€æ¬¡
setup_chinese_font()

# åŒæ™‚è¨­å®š pyplot
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = [
    'Noto Sans CJK TC',
    'Noto Sans CJK SC',
    'Noto Sans CJK JP',  # Streamlit Cloud å¯¦éš›å®‰è£çš„ç‰ˆæœ¬
    'Noto Sans CJK KR',
    'Noto Sans TC',
    'Noto Sans SC',
    'DejaVu Sans',
    'sans-serif'
]
plt.rcParams['axes.unicode_minus'] = False

# ============================================================================
# é é¢è¨­å®š
# ============================================================================
st.set_page_config(
    page_title="å°ç£é†«é™¢ LDA ä¸»é¡Œåˆ†æž",
    page_icon="ðŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# è·¯å¾‘è¨­å®š
# ============================================================================
BASE_DIR = Path(__file__).resolve().parent.parent.parent

# è³‡æ–™è·¯å¾‘è¨­å®š
# å„ªå…ˆä½¿ç”¨å®Œæ•´è³‡æ–™ï¼Œå¦‚æžœä¸å­˜åœ¨å‰‡å›žé€€åˆ° demo è³‡æ–™
DATA_DIR = BASE_DIR / "data"
DATA_DEMO_DIR = BASE_DIR / "data_demo"

# æª¢æŸ¥å®Œæ•´è³‡æ–™æ˜¯å¦å­˜åœ¨
if (DATA_DIR / "raw" / "taiwan").exists():
    RAW_DATA_DIR = DATA_DIR / "raw" / "taiwan"
    PROCESSED_DATA_DIR = DATA_DIR / "processed" / "taiwan"
    RESULTS_DIR = BASE_DIR / "results"
    print("[INFO] Using full data directory")
else:
    RAW_DATA_DIR = DATA_DEMO_DIR / "raw" / "taiwan"
    PROCESSED_DATA_DIR = DATA_DEMO_DIR / "processed"
    RESULTS_DIR = BASE_DIR / "results_demo"
    print("[INFO] Full data not found, falling back to demo data")

# ============================================================================
# å¿«å–è³‡æ–™è¼‰å…¥å‡½æ•¸
# ============================================================================

@st.cache_data(ttl=60)  # å¼·åˆ¶æ¯ 60 ç§’é‡æ–°è¼‰å…¥ä¸€æ¬¡
def load_hospital_list():
    """è¼‰å…¥é†«é™¢åˆ—è¡¨ï¼ˆè¿”å›žè‹±æ–‡ç¸®å¯«åˆ—è¡¨ï¼‰"""
    hospitals = []
    print(f"[DEBUG] RAW_DATA_DIR = {RAW_DATA_DIR}")
    print(f"[DEBUG] RAW_DATA_DIR.exists() = {RAW_DATA_DIR.exists()}")

    if RAW_DATA_DIR.exists():
        xlsx_files = list(RAW_DATA_DIR.glob("*.xlsx"))
        print(f"[DEBUG] Found {len(xlsx_files)} xlsx files")

        for file in sorted(xlsx_files):
            # æŽ’é™¤åˆ†æžçµæžœæª”æ¡ˆ
            if 'lda_k' in file.stem or 'analysis' in file.stem:
                continue

            name_part = file.stem.split('_')
            print(f"[DEBUG] File: {file.name}, Parts: {name_part}")

            if len(name_part) >= 2:
                hospital_abbr = name_part[1]  # è‹±æ–‡ç¸®å¯«
                hospitals.append(hospital_abbr)
    else:
        print(f"[ERROR] RAW_DATA_DIR does not exist: {RAW_DATA_DIR}")

    print(f"[DEBUG] Loaded {len(hospitals)} hospitals: {hospitals}")
    return hospitals

@st.cache_resource
def load_lda_model(k=7):
    """è¼‰å…¥ LDA æ¨¡åž‹"""
    model_dir = RESULTS_DIR / f"taiwan_lda_k{k}"
    model_path = model_dir / f"lda_k{k}_lda_model.pkl"

    if not model_path.exists():
        # å˜—è©¦è¼‰å…¥å…¶ä»–å‘½åæ ¼å¼
        alt_paths = list(model_dir.glob("*lda_model.pkl"))
        if alt_paths:
            model_path = alt_paths[0]
        else:
            return None, None, None

    try:
        with open(model_path, 'rb') as f:
            loaded_data = pickle.load(f)

        # æª¢æŸ¥æ˜¯å¦ç‚ºå­—å…¸æ ¼å¼ï¼ˆåŒ…å«å¤šå€‹è³‡è¨Šï¼‰
        if isinstance(loaded_data, dict):
            if 'lda_model' in loaded_data:
                # å­—å…¸æ ¼å¼ï¼Œæå– LDA æ¨¡åž‹
                model = loaded_data['lda_model']
            else:
                st.error(f"æ¨¡åž‹æª”æ¡ˆæ ¼å¼éŒ¯èª¤: æ‰¾ä¸åˆ° 'lda_model' éµ")
                st.error(f"å¯ç”¨çš„éµ: {list(loaded_data.keys())}")
                return None, None, None
        else:
            # ç›´æŽ¥æ˜¯æ¨¡åž‹ç‰©ä»¶
            model = loaded_data

        # å˜—è©¦è¼‰å…¥å­—å…¸å’Œèªžæ–™åº«
        dictionary = model.id2word if hasattr(model, 'id2word') else None

        return model, dictionary, model_path
    except Exception as e:
        st.error(f"è¼‰å…¥æ¨¡åž‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None, None, None

@st.cache_data
def load_analysis_results(k=7):
    """è¼‰å…¥åˆ†æžçµæžœ Excel æª”æ¡ˆ"""
    results_dir = RESULTS_DIR / f"taiwan_lda_k{k}" / "visualizations"
    results_path = results_dir / f"lda_k{k}_analysis_results.xlsx"

    if not results_path.exists():
        return None

    try:
        # è®€å–æ‰€æœ‰ sheets
        excel_file = pd.ExcelFile(results_path)
        sheets = {}
        for sheet_name in excel_file.sheet_names:
            sheets[sheet_name] = pd.read_excel(excel_file, sheet_name=sheet_name)
        return sheets
    except Exception as e:
        st.error(f"è¼‰å…¥åˆ†æžçµæžœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

@st.cache_data
def load_reviews_data():
    """è¼‰å…¥è©•è«–è³‡æ–™"""
    reviews_path = PROCESSED_DATA_DIR / "reviews_for_lda.txt"

    if not reviews_path.exists():
        return None

    try:
        reviews = []
        with open(reviews_path, 'r', encoding='utf-8') as f:
            for line in f:
                reviews.append(line.strip())
        return reviews
    except Exception as e:
        st.error(f"è¼‰å…¥è©•è«–è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

@st.cache_data
def load_raw_hospital_data(hospital_name):
    """è¼‰å…¥ç‰¹å®šé†«é™¢çš„åŽŸå§‹è³‡æ–™"""
    if RAW_DATA_DIR.exists():
        for file in RAW_DATA_DIR.glob("*.xlsx"):
            if hospital_name in file.stem:
                try:
                    df = pd.read_excel(file)
                    return df
                except Exception as e:
                    st.error(f"è¼‰å…¥ {hospital_name} è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    return None
    return None

@st.cache_data
def load_stopwords():
    """è¼‰å…¥åœç”¨è©ž"""
    stopwords = set()
    stopwords_path = BASE_DIR / "stopwords_custom.txt"

    if stopwords_path.exists():
        with open(stopwords_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    stopwords.add(line)

    # æ·»åŠ å¸¸è¦‹åœç”¨è©ž
    common_stopwords = ['çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€å€‹', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'èªª', 'è¦', 'åŽ»', 'ä½ ', 'æœƒ', 'è‘—', 'æ²’æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'é€™']
    stopwords.update(common_stopwords)

    return stopwords

@st.cache_data
def load_all_reviews_with_ratings():
    """è¼‰å…¥æ‰€æœ‰é†«é™¢çš„è©•è«–è³‡æ–™ï¼ˆåŒ…å«è©•åˆ†ï¼‰"""
    if not RAW_DATA_DIR.exists():
        print(f"[ERROR] RAW_DATA_DIR ä¸å­˜åœ¨: {RAW_DATA_DIR}")
        return None

    all_reviews = []
    file_count = 0
    try:
        for file in sorted(RAW_DATA_DIR.glob("*.xlsx")):
            # è·³éŽåˆ†æžçµæžœæª”æ¡ˆ
            if 'analysis' in file.name or 'lda_k' in file.name:
                continue

            file_count += 1
            df = pd.read_excel(file)
            if 'review_text' in df.columns and 'rating' in df.columns:
                # æå–éœ€è¦çš„æ¬„ä½
                hospital_name = file.stem.split('_')[1] if '_' in file.stem else file.stem
                print(f"[DEBUG] è¼‰å…¥æª”æ¡ˆ: {file.name} -> é†«é™¢: {hospital_name}, è©•è«–æ•¸: {len(df)}")

                for _, row in df.iterrows():
                    # ç¢ºä¿ review_text æ˜¯å­—ä¸²ä¸”ä¸ç‚ºç©º
                    review_text = row['review_text']

                    # è™•ç†å„ç¨®è³‡æ–™é¡žåž‹
                    if pd.isna(review_text):
                        continue

                    # è½‰æ›ç‚ºå­—ä¸²
                    if not isinstance(review_text, str):
                        review_text = str(review_text)

                    # åŽ»é™¤ç©ºç™½ä¸¦æª¢æŸ¥æ˜¯å¦ç‚ºç©º
                    review_text = review_text.strip()
                    if not review_text:
                        continue

                    # è™•ç†è©•åˆ†
                    rating = row['rating'] if pd.notna(row['rating']) else 0
                    if not isinstance(rating, (int, float)):
                        try:
                            rating = float(rating)
                        except:
                            rating = 0

                    # è™•ç†è©•è«–è€…åç¨±
                    reviewer = row.get('reviewer_name', 'åŒ¿å')
                    if pd.isna(reviewer):
                        reviewer = 'åŒ¿å'
                    elif not isinstance(reviewer, str):
                        reviewer = str(reviewer)

                    # è™•ç†æ—¥æœŸ
                    date = row.get('review_date', '')
                    if pd.isna(date):
                        date = ''
                    elif not isinstance(date, str):
                        date = str(date)

                    all_reviews.append({
                        'hospital': hospital_name,
                        'text': review_text,
                        'rating': rating,
                        'reviewer': reviewer,
                        'date': date
                    })

        print(f"[DEBUG] ç¸½å…±è¼‰å…¥ {file_count} å€‹æª”æ¡ˆ, {len(all_reviews)} æ¢è©•è«–")
        if all_reviews:
            df = pd.DataFrame(all_reviews)
            unique_hospitals = df['hospital'].unique()
            print(f"[DEBUG] å”¯ä¸€é†«é™¢æ•¸: {len(unique_hospitals)}, é†«é™¢åˆ—è¡¨: {list(unique_hospitals)}")
            return df
        else:
            print("[ERROR] æ²’æœ‰è¼‰å…¥ä»»ä½•è©•è«–è³‡æ–™")
            return None
    except Exception as e:
        st.error(f"è¼‰å…¥è©•è«–è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        st.error(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        return None

def assign_topics_to_reviews(_model, dictionary, reviews_df):
    """å°‡ä¸»é¡Œåˆ†é…çµ¦è©•è«–ï¼ˆç›´æŽ¥è™•ç†åŽŸå§‹è©•è«–ï¼‰"""
    if reviews_df is None or len(reviews_df) == 0:
        return None

    # è¼‰å…¥åœç”¨è©ž
    stopwords = load_stopwords()

    topic_assignments = []

    for _, row in reviews_df.iterrows():
        review_text = row['text']

        # ä½¿ç”¨ jieba é€²è¡Œåˆ†è©ž
        words = jieba.cut(review_text)

        # éŽæ¿¾åœç”¨è©žã€å–®å­—ç¬¦ã€æ•¸å­—
        filtered_words = [
            word for word in words
            if len(word) > 1 and
               word not in stopwords and
               not word.isdigit() and
               not re.match(r'^[a-zA-Z]+$', word)
        ]

        # è½‰æ›ç‚º bag-of-words
        bow = dictionary.doc2bow(filtered_words)

        if len(bow) == 0:
            # å¦‚æžœæ²’æœ‰æœ‰æ•ˆè©žå½™ï¼Œåˆ†é…åˆ°ä¸»é¡Œ0ï¼Œæ©ŸçŽ‡è¨­ç‚º0
            topic_assignments.append({
                'topic_id': 0,
                'probability': 0.0
            })
            continue

        # å–å¾—ä¸»é¡Œåˆ†ä½ˆ
        topic_dist = _model.get_document_topics(bow, minimum_probability=0)

        # æ‰¾å‡ºä¸»å°Žä¸»é¡Œ
        if len(topic_dist) > 0:
            dominant_topic = max(topic_dist, key=lambda x: x[1])
            topic_assignments.append({
                'topic_id': dominant_topic[0],
                'probability': dominant_topic[1]
            })
        else:
            topic_assignments.append({
                'topic_id': 0,
                'probability': 0.0
            })

    # åŠ å…¥ä¸»é¡Œè³‡è¨Šåˆ° DataFrame
    reviews_df['topic_id'] = [t['topic_id'] for t in topic_assignments]
    reviews_df['topic_probability'] = [t['probability'] for t in topic_assignments]

    return reviews_df

# ============================================================================
# åˆ†æžå‡½æ•¸
# ============================================================================

def get_topic_keywords(model, num_words=10):
    """å–å¾—æ¯å€‹ä¸»é¡Œçš„é—œéµè©ž"""
    topics = []
    for topic_id in range(model.num_topics):
        topic_words = model.show_topic(topic_id, topn=num_words)
        topics.append({
            'topic_id': topic_id,
            'keywords': [word for word, _ in topic_words],
            'weights': [weight for _, weight in topic_words]
        })
    return topics

def calculate_hospital_topic_distribution(model, dictionary, hospital_reviews):
    """è¨ˆç®—ç‰¹å®šé†«é™¢çš„ä¸»é¡Œåˆ†ä½ˆ"""
    if not hospital_reviews:
        return None

    topic_dist = np.zeros(model.num_topics)

    for review in hospital_reviews:
        # å°‡è©•è«–è½‰æ›ç‚º bag-of-words
        bow = dictionary.doc2bow(review.split())
        # å–å¾—ä¸»é¡Œåˆ†ä½ˆ
        doc_topics = model.get_document_topics(bow)
        for topic_id, prob in doc_topics:
            topic_dist[topic_id] += prob

    # æ­£è¦åŒ–
    topic_dist = topic_dist / len(hospital_reviews)
    return topic_dist

# ============================================================================
# è¦–è¦ºåŒ–å‡½æ•¸
# ============================================================================

def plot_topic_keywords(topics, selected_topics=None, figsize=None):
    """ç¹ªè£½ä¸»é¡Œé—œéµè©žæ¢ç‹€åœ–"""
    if selected_topics is None:
        selected_topics = range(len(topics))

    n_topics = len(selected_topics)

    # ä½¿ç”¨è‡ªå®šç¾©å°ºå¯¸æˆ–é»˜èªå°ºå¯¸
    if figsize is None:
        figsize = (12, 3*n_topics)

    fig, axes = plt.subplots(n_topics, 1, figsize=figsize)

    if n_topics == 1:
        axes = [axes]

    for idx, topic_idx in enumerate(selected_topics):
        topic = topics[topic_idx]
        keywords = topic['keywords'][:10]
        weights = topic['weights'][:10]

        axes[idx].barh(keywords, weights, color='steelblue')
        axes[idx].set_xlabel('æ¬Šé‡', fontsize=10)
        axes[idx].set_title(f'ä¸»é¡Œ {topic_idx}: {", ".join(keywords[:5])}...',
                           fontsize=12, fontweight='bold')
        axes[idx].invert_yaxis()

    plt.tight_layout()
    return fig

def plot_hospital_comparison(hospital_distributions, hospital_names, k=7):
    """ç¹ªè£½é†«é™¢ä¸»é¡Œåˆ†ä½ˆæ¯”è¼ƒåœ–"""
    fig, ax = plt.subplots(figsize=(12, 6))

    x = np.arange(k)
    width = 0.8 / len(hospital_names)

    for idx, (hospital_name, dist) in enumerate(zip(hospital_names, hospital_distributions)):
        offset = (idx - len(hospital_names)/2) * width + width/2
        ax.bar(x + offset, dist, width, label=hospital_name, alpha=0.8)

    ax.set_xlabel('ä¸»é¡Œç·¨è™Ÿ', fontsize=12)
    ax.set_ylabel('ä¸»é¡Œæ¯”ä¾‹', fontsize=12)
    ax.set_title('é†«é™¢ä¸»é¡Œåˆ†ä½ˆæ¯”è¼ƒ', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels([f'ä¸»é¡Œ{i}' for i in range(k)])
    ax.legend(loc='upper right')
    ax.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    return fig

def plot_topic_heatmap(hospital_distributions, hospital_names, k=7):
    """ç¹ªè£½é†«é™¢-ä¸»é¡Œç†±åŠ›åœ–"""
    fig, ax = plt.subplots(figsize=(10, len(hospital_names)*0.5 + 2))

    data = np.array(hospital_distributions)

    sns.heatmap(data,
                xticklabels=[f'ä¸»é¡Œ{i}' for i in range(k)],
                yticklabels=hospital_names,
                cmap='YlOrRd',
                annot=True,
                fmt='.3f',
                cbar_kws={'label': 'ä¸»é¡Œæ¯”ä¾‹'},
                ax=ax)

    ax.set_title('é†«é™¢-ä¸»é¡Œåˆ†ä½ˆç†±åŠ›åœ–', fontsize=14, fontweight='bold', pad=20)

    plt.tight_layout()
    return fig

# ============================================================================
# ä¸»ç¨‹å¼
# ============================================================================

def main():
    # æ¨™é¡Œ
    st.title("ðŸ¥ å°ç£é†«é™¢ LDA ä¸»é¡Œåˆ†æžç³»çµ±")

    st.markdown("---")

    # å›ºå®šä½¿ç”¨ K=7ï¼ˆå·²ç¢ºå®šç‚ºæœ€ä½³ä¸»é¡Œæ•¸ï¼‰
    k_value = 7

    # å´é‚Šæ¬„
    with st.sidebar:
        st.header("âš™ï¸ å°Žè¦½")

        # åŠŸèƒ½é¸æ“‡
        page = st.radio(
            "é¸æ“‡åˆ†æžæ¨¡çµ„",
            ["ðŸ“Š ä¸»é¡Œç¸½è¦½", "ðŸ” ä¸»é¡Œæ·±å…¥æŽ¢ç´¢", "ðŸ¥ é†«é™¢è©•åˆ†æ¯”è¼ƒ", "ðŸ“ˆ çµ±è¨ˆå„€è¡¨æ¿"],
            label_visibility="visible"
        )

        st.markdown("---")

        # é¡¯ç¤ºæ¨¡åž‹è³‡è¨Š
        st.info(f"ðŸ“Œ ä½¿ç”¨æ¨¡åž‹ï¼šK=7 ä¸»é¡Œ\n\nðŸ’¡ é¦–æ¬¡è¼‰å…¥éœ€è¦å¹¾ç§’é˜")

    # è¼‰å…¥æ¨¡åž‹
    with st.spinner(f"è¼‰å…¥ K={k_value} çš„ LDA æ¨¡åž‹..."):
        model, dictionary, model_path = load_lda_model(k=k_value)

    if model is None:
        st.error(f"âŒ æ‰¾ä¸åˆ° K={k_value} çš„ LDA æ¨¡åž‹ï¼")
        st.info(f"è«‹ç¢ºèªä»¥ä¸‹è·¯å¾‘å­˜åœ¨æ¨¡åž‹æª”æ¡ˆ: {RESULTS_DIR / f'taiwan_lda_k{k_value}'}")
        return

    st.success(f"âœ… æˆåŠŸè¼‰å…¥ K={k_value} çš„ LDA æ¨¡åž‹")

    # æ ¹æ“šé¸æ“‡çš„é é¢é¡¯ç¤ºä¸åŒå…§å®¹
    if page == "ðŸ“Š ä¸»é¡Œç¸½è¦½":
        show_topic_overview(model, k_value)

    elif page == "ðŸ” ä¸»é¡Œæ·±å…¥æŽ¢ç´¢":
        show_topic_exploration(model, k_value)

    elif page == "ðŸ¥ é†«é™¢è©•åˆ†æ¯”è¼ƒ":
        show_hospital_rating_comparison(model, dictionary, k_value)

    elif page == "ðŸ“ˆ çµ±è¨ˆå„€è¡¨æ¿":
        show_statistics_dashboard(k_value)

# ============================================================================
# å„å€‹é é¢çš„é¡¯ç¤ºå‡½æ•¸
# ============================================================================

def show_topic_overview(model, k_value):
    """é¡¯ç¤ºä¸»é¡Œç¸½è¦½é é¢"""
    st.header("ðŸ“Š ä¸»é¡Œç¸½è¦½")

    # å–å¾—ä¸»é¡Œé—œéµè©žï¼ˆå¢žåŠ åˆ° 30 å€‹ï¼‰
    topics = get_topic_keywords(model, num_words=30)

    # é¡¯ç¤ºé¸é …
    col1, col2 = st.columns([1, 3])
    with col1:
        num_keywords = st.slider("é¡¯ç¤ºé—œéµè©žæ•¸é‡", 5, 30, 15)  # é è¨­15ï¼Œæœ€å¤š30
    with col2:
        display_mode = st.radio(
            "é¡¯ç¤ºæ¨¡å¼",
            ["è¡¨æ ¼", "è¦–è¦ºåŒ–"],
            horizontal=True
        )

    st.markdown("---")

    if display_mode == "è¡¨æ ¼":
        # è¡¨æ ¼é¡¯ç¤º
        for topic in topics:
            # é¡¯ç¤ºæ›´å¤šé—œéµè©žåœ¨æ¨™é¡Œ
            topic_id = topic['topic_id']
            topic_label = TAIWAN_TOPICS[topic_id]['label_zh'] if topic_id in TAIWAN_TOPICS else f"ä¸»é¡Œ {topic_id}"
            with st.expander(f"**{topic_label}**: {', '.join(topic['keywords'][:8])}..."):
                topic_df = pd.DataFrame({
                    'é—œéµè©ž': topic['keywords'][:num_keywords],
                    'æ¬Šé‡': topic['weights'][:num_keywords]
                })
                st.dataframe(topic_df, use_container_width=True)
    else:
        # è¦–è¦ºåŒ–é¡¯ç¤º - ç¸®å°åœ–è¡¨
        col1, col2, col3 = st.columns([1, 1, 1])

        with col1:
            st.subheader("é—œéµè©žè¦–è¦ºåŒ–")
            fig = plot_topic_keywords(topics, figsize=(6, 12))
            st.pyplot(fig)
            plt.close()

        with col2:
            st.subheader("ä¸»é¡Œåˆ†ä½ˆ")
            viz_dir = RESULTS_DIR / f"taiwan_lda_k{k_value}" / "visualizations"
            dist_path = viz_dir / f"lda_k{k_value}_distribution.png"
            if dist_path.exists():
                st.image(str(dist_path), use_container_width=True)
            else:
                st.info("æš«ç„¡ä¸»é¡Œåˆ†ä½ˆåœ–")

        with col3:
            st.subheader("ä¸»é¡Œæ–‡å­—é›²")
            viz_dir = RESULTS_DIR / f"taiwan_lda_k{k_value}" / "visualizations"
            wordcloud_path = viz_dir / f"lda_k{k_value}_wordclouds.png"
            if wordcloud_path.exists():
                st.image(str(wordcloud_path), use_container_width=True)
            else:
                st.info("æš«ç„¡æ–‡å­—é›²åœ–")

def show_hospital_rating_comparison(model, dictionary, k_value):
    """é¡¯ç¤ºé†«é™¢åœ¨å„ä¸»é¡Œçš„è©•åˆ†æ¯”è¼ƒ"""
    st.header("ðŸ¥ é†«é™¢è©•åˆ†æ¯”è¼ƒåˆ†æž")

    st.markdown("""
    æ­¤é é¢é¡¯ç¤ºä¸åŒé†«é™¢åœ¨å„å€‹ä¸»é¡Œçš„å¹³å‡è©•åˆ†ï¼Œå¹«åŠ©æ‚¨äº†è§£ï¼š
    - å“ªäº›é†«é™¢åœ¨ç‰¹å®šæœå‹™é¢å‘ï¼ˆä¸»é¡Œï¼‰è¡¨ç¾è¼ƒå¥½
    - å„ä¸»é¡Œçš„æ•´é«”è©•åˆ†è¶¨å‹¢
    - é†«é™¢é–“çš„æœå‹™å“è³ªå·®ç•°
    """)

    st.markdown("---")

    # è¼‰å…¥æ‰€æœ‰è©•è«–è³‡æ–™
    with st.spinner("è¼‰å…¥è©•è«–è³‡æ–™ä¸¦åˆ†æžä¸»é¡Œ..."):
        reviews_df = load_all_reviews_with_ratings()

        if reviews_df is None or len(reviews_df) == 0:
            st.error("âŒ ç„¡æ³•è¼‰å…¥è©•è«–è³‡æ–™")
            return

        # åˆ†é…ä¸»é¡Œ
        reviews_with_topics = assign_topics_to_reviews(model, model.id2word, reviews_df)

        if reviews_with_topics is None:
            st.error("âŒ ç„¡æ³•é€²è¡Œä¸»é¡Œåˆ†é…")
            return

    st.success(f"âœ… æˆåŠŸåˆ†æž {len(reviews_with_topics)} æ¢è©•è«–")

    # ç²å–æ‰€æœ‰é†«é™¢åˆ—è¡¨ï¼ˆè‹±æ–‡ç¸®å¯«ï¼‰
    all_hospitals_abbr = sorted(reviews_with_topics['hospital'].unique())

    # é™¤éŒ¯è¨Šæ¯
    print(f"[DEBUG] é†«é™¢è©•åˆ†æ¯”è¼ƒ - æ‰¾åˆ° {len(all_hospitals_abbr)} å®¶é†«é™¢")
    print(f"[DEBUG] é†«é™¢ç¸®å¯«åˆ—è¡¨: {all_hospitals_abbr}")

    # æª¢æŸ¥æ˜¯å¦æœ‰é†«é™¢è³‡æ–™
    if len(all_hospitals_abbr) == 0:
        st.error("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•é†«é™¢è³‡æ–™ï¼è«‹æª¢æŸ¥è³‡æ–™è¼‰å…¥ã€‚")
        st.info(f"è³‡æ–™ç›®éŒ„: {RAW_DATA_DIR}")
        st.info(f"è©•è«–ç¸½æ•¸: {len(reviews_with_topics)}")
        return

    # å‰µå»ºä¸­è‹±æ–‡å°ç…§ï¼ˆé¡¯ç¤ºç”¨ä¸­æ–‡ï¼Œå€¼ç”¨è‹±æ–‡ç¸®å¯«ï¼‰
    hospital_options = {get_hospital_name(abbr): abbr for abbr in all_hospitals_abbr}
    print(f"[DEBUG] é†«é™¢é¸é …æ•¸é‡: {len(hospital_options)}")

    # é¸æ“‡è¦æ¯”è¼ƒçš„é†«é™¢
    st.subheader("é¸æ“‡è¦æ¯”è¼ƒçš„é†«é™¢")
    selected_hospital_names = st.multiselect(
        "é¸æ“‡é†«é™¢ï¼ˆå»ºè­° 3-8 å®¶ä»¥ä¾¿æ¸…æ¥šæ¯”è¼ƒï¼‰",
        options=list(hospital_options.keys()),  # é¡¯ç¤ºä¸­æ–‡åç¨±
        default=list(hospital_options.keys())[:5] if len(hospital_options) >= 5 else list(hospital_options.keys())
    )

    # è½‰æ›å›žè‹±æ–‡ç¸®å¯«é€²è¡Œè³‡æ–™è™•ç†
    selected_hospitals = [hospital_options[name] for name in selected_hospital_names]

    if len(selected_hospitals) == 0:
        st.warning("âš ï¸ è«‹è‡³å°‘é¸æ“‡ 1 å®¶é†«é™¢")
        return

    st.markdown("---")

    # è¨ˆç®—æ¯å®¶é†«é™¢åœ¨å„ä¸»é¡Œçš„å¹³å‡è©•åˆ†
    topic_ratings = []
    for hospital in selected_hospitals:
        hospital_data = reviews_with_topics[reviews_with_topics['hospital'] == hospital]
        hospital_ratings = []
        for topic_id in range(k_value):
            topic_data = hospital_data[hospital_data['topic_id'] == topic_id]
            if len(topic_data) > 0:
                avg_rating = topic_data['rating'].mean()
                count = len(topic_data)
            else:
                avg_rating = 0
                count = 0
            hospital_ratings.append({
                'hospital': hospital,
                'topic': topic_id,
                'avg_rating': avg_rating,
                'count': count
            })
        topic_ratings.extend(hospital_ratings)

    ratings_df = pd.DataFrame(topic_ratings)

    # é¡¯ç¤ºé¸é …
    viz_type = st.radio(
        "é¸æ“‡è¦–è¦ºåŒ–é¡žåž‹",
        ["ðŸ“Š åˆ†çµ„é•·æ¢åœ–", "ðŸ”¥ ç†±åŠ›åœ–", "ðŸ“ˆ æŠ˜ç·šåœ–"],
        horizontal=True
    )

    st.markdown("---")

    if viz_type == "ðŸ“Š åˆ†çµ„é•·æ¢åœ–":
        # åˆ†çµ„é•·æ¢åœ–ï¼šæ¯å€‹ä¸»é¡Œé¡¯ç¤ºå„é†«é™¢è©•åˆ†
        st.subheader("å„ä¸»é¡Œçš„é†«é™¢è©•åˆ†æ¯”è¼ƒ")

        fig, ax = plt.subplots(figsize=(14, 6))

        x = np.arange(k_value)
        width = 0.8 / len(selected_hospitals)

        for idx, hospital in enumerate(selected_hospitals):
            hospital_data = ratings_df[ratings_df['hospital'] == hospital]
            ratings = [hospital_data[hospital_data['topic'] == t]['avg_rating'].values[0] for t in range(k_value)]
            offset = (idx - len(selected_hospitals)/2) * width + width/2
            # ä½¿ç”¨ç°¡çŸ­ä¸­æ–‡åç¨±ä½œç‚ºåœ–ä¾‹
            hospital_display = get_hospital_name(hospital, use_short=True)
            ax.bar(x + offset, ratings, width, label=hospital_display, alpha=0.8)

        ax.set_xlabel('ä¸»é¡Œç·¨è™Ÿ', fontsize=12)
        ax.set_ylabel('å¹³å‡è©•åˆ†ï¼ˆæ˜Ÿç´šï¼‰', fontsize=12)
        ax.set_title('å„ä¸»é¡Œçš„é†«é™¢å¹³å‡è©•åˆ†æ¯”è¼ƒ', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels([f'ä¸»é¡Œ {i}' for i in range(k_value)])
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax.set_ylim(0, 5)
        ax.grid(axis='y', alpha=0.3)
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

    elif viz_type == "ðŸ”¥ ç†±åŠ›åœ–":
        # ç†±åŠ›åœ–ï¼šé†«é™¢ x ä¸»é¡Œ
        st.subheader("é†«é™¢-ä¸»é¡Œè©•åˆ†ç†±åŠ›åœ–")

        # å»ºç«‹çŸ©é™£
        heatmap_data = []
        for hospital in selected_hospitals:
            hospital_data = ratings_df[ratings_df['hospital'] == hospital]
            ratings = [hospital_data[hospital_data['topic'] == t]['avg_rating'].values[0] for t in range(k_value)]
            heatmap_data.append(ratings)

        fig, ax = plt.subplots(figsize=(10, max(6, len(selected_hospitals)*0.5)))
        im = ax.imshow(heatmap_data, cmap='RdYlGn', aspect='auto', vmin=0, vmax=5)

        # è¨­å®šåº§æ¨™è»¸
        ax.set_xticks(np.arange(k_value))
        ax.set_yticks(np.arange(len(selected_hospitals)))
        ax.set_xticklabels([f'ä¸»é¡Œ {i}' for i in range(k_value)])
        # ä½¿ç”¨ç°¡çŸ­ä¸­æ–‡åç¨±
        ax.set_yticklabels([get_hospital_name(h, use_short=True) for h in selected_hospitals])

        # åœ¨æ ¼å­ä¸­é¡¯ç¤ºæ•¸å€¼
        for i in range(len(selected_hospitals)):
            for j in range(k_value):
                text = ax.text(j, i, f'{heatmap_data[i][j]:.2f}',
                             ha="center", va="center", color="black", fontsize=9)

        ax.set_title('é†«é™¢åœ¨å„ä¸»é¡Œçš„å¹³å‡è©•åˆ†', fontsize=14, fontweight='bold')
        fig.colorbar(im, ax=ax, label='å¹³å‡è©•åˆ†ï¼ˆæ˜Ÿç´šï¼‰')
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

    else:  # æŠ˜ç·šåœ–
        st.subheader("é†«é™¢è©•åˆ†è¶¨å‹¢æ¯”è¼ƒ")

        fig, ax = plt.subplots(figsize=(12, 6))

        for hospital in selected_hospitals:
            hospital_data = ratings_df[ratings_df['hospital'] == hospital]
            ratings = [hospital_data[hospital_data['topic'] == t]['avg_rating'].values[0] for t in range(k_value)]
            # ä½¿ç”¨ç°¡çŸ­ä¸­æ–‡åç¨±
            hospital_display = get_hospital_name(hospital, use_short=True)
            ax.plot(range(k_value), ratings, marker='o', label=hospital_display, linewidth=2)

        ax.set_xlabel('ä¸»é¡Œç·¨è™Ÿ', fontsize=12)
        ax.set_ylabel('å¹³å‡è©•åˆ†ï¼ˆæ˜Ÿç´šï¼‰', fontsize=12)
        ax.set_title('å„é†«é™¢åœ¨ä¸åŒä¸»é¡Œçš„è©•åˆ†è¶¨å‹¢', fontsize=14, fontweight='bold')
        ax.set_xticks(range(k_value))
        ax.set_xticklabels([f'ä¸»é¡Œ {i}' for i in range(k_value)])
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax.set_ylim(0, 5)
        ax.grid(True, alpha=0.3)
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

    # é¡¯ç¤ºè©³ç´°æ•¸æ“šè¡¨æ ¼
    st.markdown("---")
    with st.expander("ðŸ“‹ æŸ¥çœ‹è©³ç´°è©•åˆ†æ•¸æ“š", expanded=False):
        # é‡æ–°æ•´ç†æ•¸æ“šç‚ºè¡¨æ ¼æ ¼å¼
        pivot_df = ratings_df.pivot(index='hospital', columns='topic', values='avg_rating')
        pivot_df.columns = [f'ä¸»é¡Œ {i}' for i in range(k_value)]

        # æ·»åŠ å¹³å‡åˆ†åˆ—
        pivot_df['æ•´é«”å¹³å‡'] = pivot_df.mean(axis=1)

        # åªé¡¯ç¤ºé¸ä¸­çš„é†«é™¢
        pivot_df = pivot_df.loc[selected_hospitals]

        st.dataframe(pivot_df.style.format("{:.2f}").background_gradient(cmap='RdYlGn', vmin=0, vmax=5),
                    use_container_width=True)

        # é¡¯ç¤ºè©•è«–æ•¸é‡
        st.markdown("#### å„ä¸»é¡Œçš„è©•è«–æ•¸é‡")
        count_pivot = ratings_df.pivot(index='hospital', columns='topic', values='count')
        count_pivot.columns = [f'ä¸»é¡Œ {i}' for i in range(k_value)]
        count_pivot = count_pivot.loc[selected_hospitals]
        st.dataframe(count_pivot, use_container_width=True)

def show_hospital_comparison(model, dictionary, k_value):
    """é¡¯ç¤ºé†«é™¢æ¯”è¼ƒé é¢ï¼ˆèˆŠç‰ˆï¼Œä¿ç•™ä»¥é˜²è¬ä¸€ï¼‰"""
    st.header("ðŸ¥ é†«é™¢æ¯”è¼ƒåˆ†æž")

    # è¼‰å…¥é†«é™¢åˆ—è¡¨
    hospitals = load_hospital_list()

    if not hospitals:
        st.error("âŒ æ‰¾ä¸åˆ°é†«é™¢è³‡æ–™ï¼")
        return

    # é¸æ“‡è¦æ¯”è¼ƒçš„é†«é™¢
    selected_hospitals = st.multiselect(
        "é¸æ“‡è¦æ¯”è¼ƒçš„é†«é™¢ï¼ˆå»ºè­°é¸æ“‡ 2-5 å®¶ï¼‰",
        hospitals,
        default=hospitals[:3] if len(hospitals) >= 3 else hospitals
    )

    if len(selected_hospitals) < 2:
        st.warning("âš ï¸ è«‹è‡³å°‘é¸æ“‡ 2 å®¶é†«é™¢é€²è¡Œæ¯”è¼ƒ")
        return

    st.markdown("---")

    # è¼‰å…¥è©•è«–è³‡æ–™
    with st.spinner("è¼‰å…¥è©•è«–è³‡æ–™..."):
        all_reviews = load_reviews_data()

    if all_reviews is None:
        st.error("âŒ æ‰¾ä¸åˆ°è©•è«–è³‡æ–™ï¼")
        return

    # è¨ˆç®—å„é†«é™¢çš„ä¸»é¡Œåˆ†ä½ˆï¼ˆé€™è£¡ç°¡åŒ–è™•ç†ï¼Œå¯¦éš›æ‡‰è©²è¦æœ‰é†«é™¢æ¨™è¨˜ï¼‰
    st.info("â„¹ï¸ æ³¨æ„ï¼šç›®å‰ä½¿ç”¨æ•´é«”è³‡æ–™çš„ä¸»é¡Œåˆ†ä½ˆä½œç‚ºç¤ºç¯„ã€‚å®Œæ•´ç‰ˆéœ€è¦å€‹åˆ¥é†«é™¢çš„è©•è«–æ¨™è¨˜ã€‚")

    # ç¤ºç¯„ï¼šä½¿ç”¨æ¨¡åž‹çš„æ•´é«”ä¸»é¡Œåˆ†ä½ˆ
    topic_dist = np.zeros((len(selected_hospitals), model.num_topics))

    # å¾žåˆ†æžçµæžœè¼‰å…¥ï¼ˆå¦‚æžœæœ‰çš„è©±ï¼‰
    analysis_results = load_analysis_results(k=k_value)

    if analysis_results and 'topic_distribution' in analysis_results:
        st.success("âœ… å·²è¼‰å…¥ä¸»é¡Œåˆ†ä½ˆè³‡æ–™")
        # é€™è£¡å¯ä»¥é€²ä¸€æ­¥è™•ç†

    # ç¤ºç¯„è³‡æ–™ï¼ˆéš¨æ©Ÿç”Ÿæˆï¼Œå¯¦éš›æ‡‰è©²å¾žçœŸå¯¦è³‡æ–™è¨ˆç®—ï¼‰
    for i in range(len(selected_hospitals)):
        # ç”Ÿæˆéš¨æ©Ÿä½†åˆç†çš„ä¸»é¡Œåˆ†ä½ˆ
        np.random.seed(i * 42)  # å›ºå®šç¨®å­ä»¥ä¿æŒä¸€è‡´æ€§
        random_dist = np.random.dirichlet(np.ones(model.num_topics) * 5)
        topic_dist[i] = random_dist

    # é¡¯ç¤ºè¦–è¦ºåŒ–é¸é …
    viz_type = st.radio(
        "é¸æ“‡è¦–è¦ºåŒ–é¡žåž‹",
        ["é•·æ¢åœ–æ¯”è¼ƒ", "ç†±åŠ›åœ–"],
        horizontal=True
    )

    if viz_type == "é•·æ¢åœ–æ¯”è¼ƒ":
        fig = plot_hospital_comparison(topic_dist, selected_hospitals, k=k_value)
        st.pyplot(fig)
        plt.close()
    else:
        fig = plot_topic_heatmap(topic_dist, selected_hospitals, k=k_value)
        st.pyplot(fig)
        plt.close()

    # é¡¯ç¤ºæ•¸å€¼è¡¨æ ¼
    with st.expander("ðŸ“Š æŸ¥çœ‹è©³ç´°æ•¸å€¼"):
        dist_df = pd.DataFrame(
            topic_dist,
            columns=[f'ä¸»é¡Œ{i}' for i in range(k_value)],
            index=selected_hospitals
        )
        st.dataframe(dist_df.style.format("{:.4f}"), use_container_width=True)

def get_topic_label(topic_id):
    """ç²å–ä¸»é¡Œçš„ä¸­æ–‡æ¨™ç±¤"""
    if topic_id in TAIWAN_TOPICS:
        return f"ä¸»é¡Œ {topic_id}: {TAIWAN_TOPICS[topic_id]['label_zh']}"
    return f"ä¸»é¡Œ {topic_id}"

def show_topic_exploration(model, k_value):
    """é¡¯ç¤ºä¸»é¡Œæ·±å…¥æŽ¢ç´¢é é¢"""
    st.header("ðŸ” ä¸»é¡Œæ·±å…¥æŽ¢ç´¢")

    # é¸æ“‡è¦æŽ¢ç´¢çš„ä¸»é¡Œ
    topic_id = st.selectbox(
        "é¸æ“‡ä¸»é¡Œ",
        range(model.num_topics),
        format_func=lambda x: get_topic_label(x)
    )

    st.markdown("---")

    # é¡¯ç¤ºä¸»é¡Œé—œéµè©žï¼ˆå¢žåŠ åˆ°30å€‹ï¼‰
    topic_label = TAIWAN_TOPICS[topic_id]['label_zh'] if topic_id in TAIWAN_TOPICS else f"ä¸»é¡Œ {topic_id}"
    st.subheader(f"{topic_label} - é—œéµè©žèˆ‡æ¬Šé‡")
    topic_words = model.show_topic(topic_id, topn=30)
    topic_df = pd.DataFrame(topic_words, columns=['é—œéµè©ž', 'æ¬Šé‡'])

    # ä½¿ç”¨å…©æ¬„é¡¯ç¤ºè¡¨æ ¼ï¼Œç¯€çœç©ºé–“
    col1, col2 = st.columns(2)
    with col1:
        st.dataframe(topic_df.head(15), use_container_width=True, height=400)
    with col2:
        st.dataframe(topic_df.tail(15), use_container_width=True, height=400)

    # æ–°å¢žï¼šé¡¯ç¤ºè©²ä¸»é¡Œçš„è©•è«–
    st.markdown("---")
    st.subheader(f"ðŸ“ {topic_label} çš„ä»£è¡¨æ€§è©•è«–")

    with st.spinner("è¼‰å…¥è©•è«–è³‡æ–™..."):
        # è¼‰å…¥è©•è«–è³‡æ–™
        reviews_df = load_all_reviews_with_ratings()

        if reviews_df is not None:
            # åˆ†é…ä¸»é¡Œï¼ˆç›´æŽ¥è™•ç†åŽŸå§‹è©•è«–ï¼‰
            reviews_with_topics = assign_topics_to_reviews(model, model.id2word, reviews_df)

            if reviews_with_topics is not None:
                # ç¯©é¸è©²ä¸»é¡Œçš„è©•è«–
                topic_reviews = reviews_with_topics[reviews_with_topics['topic_id'] == topic_id].copy()
                topic_reviews = topic_reviews.sort_values('topic_probability', ascending=False)

                # é¡¯ç¤ºçµ±è¨ˆ
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("è©•è«–æ•¸é‡", len(topic_reviews))
                with col2:
                    avg_rating = topic_reviews['rating'].mean()
                    st.metric("å¹³å‡è©•åˆ†", f"{avg_rating:.2f} â­")
                with col3:
                    rating_dist = topic_reviews['rating'].value_counts().sort_index(ascending=False)
                    st.metric("æœ€å¸¸è¦‹è©•åˆ†", f"{rating_dist.index[0]} æ˜Ÿ")

                # é¡¯ç¤ºè©•åˆ†åˆ†ä½ˆ
                st.markdown("#### è©•åˆ†åˆ†ä½ˆ")
                rating_counts = topic_reviews['rating'].value_counts().sort_index(ascending=False)
                fig, ax = plt.subplots(figsize=(10, 4))
                ax.bar(rating_counts.index.astype(str), rating_counts.values, color='steelblue')
                ax.set_xlabel('è©•åˆ†ï¼ˆæ˜Ÿç´šï¼‰')
                ax.set_ylabel('è©•è«–æ•¸é‡')
                ax.set_title(f'ä¸»é¡Œ {topic_id} çš„è©•åˆ†åˆ†ä½ˆ')
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()

                # é¡¯ç¤ºä»£è¡¨æ€§è©•è«–
                st.markdown("#### ä»£è¡¨æ€§è©•è«–ï¼ˆæŒ‰ä¸»é¡Œç›¸é—œåº¦æŽ’åºï¼‰")

                # ç¯©é¸æ¢ä»¶
                col1, col2 = st.columns([1, 1])
                with col1:
                    selected_rating = st.selectbox(
                        "ç¯©é¸è©•åˆ†",
                        ["å…¨éƒ¨"] + [f"{i} æ˜Ÿ" for i in range(5, 0, -1)]
                    )
                with col2:
                    num_reviews = st.slider("é¡¯ç¤ºè©•è«–æ•¸é‡", 5, 50, 10)

                # æ‡‰ç”¨ç¯©é¸
                filtered_reviews = topic_reviews.copy()
                if selected_rating != "å…¨éƒ¨":
                    rating_value = int(selected_rating.split()[0])
                    filtered_reviews = filtered_reviews[filtered_reviews['rating'] == rating_value]

                # é¡¯ç¤ºè©•è«–ï¼ˆé è¨­å±•é–‹ï¼‰
                if len(filtered_reviews) == 0:
                    st.info("ðŸ” æ­¤ç¯©é¸æ¢ä»¶ä¸‹æ²’æœ‰è©•è«–")
                else:
                    for idx, (_, row) in enumerate(filtered_reviews.head(num_reviews).iterrows(), 1):
                        # ä½¿ç”¨å¡ç‰‡å¼é¡¯ç¤ºï¼Œé è¨­å±•é–‹
                        with st.container():
                            st.markdown(f"#### è©•è«– {idx}")
                            col_meta1, col_meta2, col_meta3 = st.columns(3)
                            with col_meta1:
                                st.metric("è©•åˆ†", f"{row['rating']} â­")
                            with col_meta2:
                                st.metric("ä¸»é¡Œç›¸é—œåº¦", f"{row['topic_probability']:.1%}")
                            with col_meta3:
                                st.metric("é†«é™¢", "")
                                st.caption(row['hospital'])

                            st.markdown("**è©•è«–å…§å®¹ï¼š**")
                            st.write(row['text'])

                            if row['date']:
                                st.caption(f"ðŸ“… æ—¥æœŸ: {row['date']}")

                            st.markdown("---")
            else:
                st.warning("ç„¡æ³•åˆ†é…ä¸»é¡Œåˆ°è©•è«–")
        else:
            st.info("ðŸ’¡ è©•è«–è³‡æ–™è¼‰å…¥ä¸­æˆ–ä¸å¯ç”¨ã€‚æ­¤åŠŸèƒ½éœ€è¦åŽŸå§‹è©•è«–è³‡æ–™ã€‚")

def show_statistics_dashboard(k_value):
    """é¡¯ç¤ºçµ±è¨ˆå„€è¡¨æ¿é é¢"""
    st.header("ðŸ“ˆ çµ±è¨ˆå„€è¡¨æ¿")

    # è¼‰å…¥é è™•ç†çµ±è¨ˆ
    stats_path = PROCESSED_DATA_DIR / "preprocessing_stats.txt"

    if stats_path.exists():
        with open(stats_path, 'r', encoding='utf-8') as f:
            stats_content = f.read()

        # è§£æžçµ±è¨ˆè³‡è¨Š
        lines = stats_content.strip().split('\n')

        # é¡¯ç¤ºç¸½é«”çµ±è¨ˆ
        st.subheader("ðŸ“Š è³‡æ–™é›†çµ±è¨ˆ")

        col1, col2, col3, col4 = st.columns(4)

        # æå–æ•¸å­—
        total_reviews = int(lines[2].split(': ')[1])
        num_hospitals = int(lines[3].split(': ')[1])
        avg_words = float(lines[4].split(': ')[1])

        col1.metric("ç¸½è©•è«–æ•¸", f"{total_reviews:,}")
        col2.metric("é†«é™¢æ•¸é‡", f"{num_hospitals}")
        col3.metric("å¹³å‡è©žæ•¸", f"{avg_words:.1f}")
        col4.metric("LDA ä¸»é¡Œæ•¸", k_value)

        st.markdown("---")

        # å„é†«é™¢è©•è«–æ•¸é‡
        st.subheader("ðŸ¥ å„é†«é™¢è©•è«–æ•¸é‡")

        # æ‰¾åˆ°é†«é™¢åˆ—è¡¨é–‹å§‹çš„è¡Œ
        hospital_start_idx = None
        for i, line in enumerate(lines):
            if "=== å„é†«é™¢è©•è«–æ•¸é‡ ===" in line:
                hospital_start_idx = i + 2
                break

        if hospital_start_idx:
            hospital_data = []
            for line in lines[hospital_start_idx:]:
                if line.strip() and ':' in line:
                    parts = line.split(': ')
                    if len(parts) == 2:
                        hospital_data.append({
                            'é†«é™¢åç¨±': parts[0].strip(),
                            'è©•è«–æ•¸': int(parts[1].strip())
                        })

            if hospital_data:
                hospital_df = pd.DataFrame(hospital_data)
                hospital_df = hospital_df.sort_values('è©•è«–æ•¸', ascending=False)

                # é•·æ¢åœ–
                fig, ax = plt.subplots(figsize=(12, 8))
                ax.barh(hospital_df['é†«é™¢åç¨±'], hospital_df['è©•è«–æ•¸'], color='steelblue')
                ax.set_xlabel('è©•è«–æ•¸', fontsize=12)
                ax.set_title('å„é†«é™¢è©•è«–æ•¸é‡åˆ†ä½ˆ', fontsize=14, fontweight='bold')
                ax.invert_yaxis()
                ax.grid(axis='x', alpha=0.3)
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()

                # é¡¯ç¤ºè¡¨æ ¼
                with st.expander("ðŸ“‹ æŸ¥çœ‹è©³ç´°æ•¸æ“š"):
                    st.dataframe(hospital_df, use_container_width=True, height=400)

    # è¼‰å…¥ç¾æœ‰çš„è¦–è¦ºåŒ–åœ–è¡¨
    st.markdown("---")
    st.subheader("ðŸ“Š LDA åˆ†æžçµæžœè¦–è¦ºåŒ–")

    viz_dir = RESULTS_DIR / f"taiwan_lda_k{k_value}" / "visualizations"
    if viz_dir.exists():
        col1, col2 = st.columns(2)

        with col1:
            dist_path = viz_dir / f"lda_k{k_value}_distribution.png"
            if dist_path.exists():
                st.image(str(dist_path), caption="ä¸»é¡Œåˆ†ä½ˆåœ–", use_container_width=True)

        with col2:
            heatmap_path = viz_dir / f"lda_k{k_value}_rating_heatmap.png"
            if heatmap_path.exists():
                st.image(str(heatmap_path), caption="è©•åˆ†ç†±åŠ›åœ–", use_container_width=True)

# ============================================================================
# åŸ·è¡Œä¸»ç¨‹å¼
# ============================================================================

if __name__ == "__main__":
    main()
