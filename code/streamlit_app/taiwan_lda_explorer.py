#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°ç£é†«é™¢ LDA ä¸»é¡Œåˆ†æžäº’å‹•å¼æ‡‰ç”¨ç¨‹å¼
ä½¿ç”¨ Streamlit å»ºç«‹äº’å‹•å¼ä»‹é¢ä¾†æŽ¢ç´¢å’Œæ¯”è¼ƒé†«é™¢è©•è«–çš„ä¸»é¡Œåˆ†ä½ˆ
"""

import streamlit as st
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
import jieba
import re
import os
warnings.filterwarnings('ignore')

# è¨­å®š matplotlib ä¸­æ–‡å­—é«”
# åœ¨ Streamlit Cloud ä¸Šéœ€è¦ç‰¹æ®Šè™•ç†
import matplotlib.font_manager as fm

def setup_chinese_font():
    """è¨­å®šä¸­æ–‡å­—åž‹ï¼Œæ”¯æ´æœ¬æ©Ÿå’Œ Streamlit Cloud"""
    # é‡æ–°è¼‰å…¥å­—åž‹å¿«å–ï¼ˆé‡è¦ï¼ï¼‰
    fm._load_fontmanager(try_read_cache=False)

    # å˜—è©¦ä½¿ç”¨ç³»çµ±å­—åž‹
    available_fonts = [f.name for f in fm.fontManager.ttflist]

    # å„ªå…ˆé †åºåˆ—è¡¨
    chinese_fonts = [
        'Noto Sans CJK TC',  # Streamlit Cloud é€éŽ packages.txt å®‰è£
        'Noto Sans CJK SC',
        'Noto Sans TC',
        'Noto Sans SC',
        'Arial Unicode MS',  # macOS
        'Microsoft YaHei',   # Windows
        'SimHei',
        'STHeiti',
        'PingFang TC'
    ]

    # æ‰¾åˆ°ç¬¬ä¸€å€‹å¯ç”¨çš„å­—åž‹
    selected_font = None
    for font in chinese_fonts:
        if font in available_fonts:
            selected_font = font
            plt.rcParams['font.sans-serif'] = [font]
            print(f"âœ… ä½¿ç”¨ä¸­æ–‡å­—åž‹: {font}")
            break

    if selected_font is None:
        # å¦‚æžœéƒ½æ‰¾ä¸åˆ°ï¼Œå˜—è©¦ä½¿ç”¨è·¯å¾‘ç›´æŽ¥æŒ‡å®š
        plt.rcParams['font.sans-serif'] = ['Noto Sans CJK TC', 'sans-serif']
        print("âš ï¸ æœªæ‰¾åˆ°é è¨­ä¸­æ–‡å­—åž‹ï¼Œä½¿ç”¨å‚™ç”¨è¨­å®š")
        # é¡¯ç¤ºå¯ç”¨çš„å­—åž‹ï¼ˆç”¨æ–¼é™¤éŒ¯ï¼‰
        noto_fonts = [f for f in available_fonts if 'Noto' in f or 'CJK' in f]
        if noto_fonts:
            print(f"å¯ç”¨çš„ Noto/CJK å­—åž‹: {', '.join(noto_fonts[:5])}")

    plt.rcParams['axes.unicode_minus'] = False

setup_chinese_font()

# ============================================================================
# é é¢è¨­å®š
# ============================================================================
st.set_page_config(
    page_title="å°ç£é†«é™¢ LDA ä¸»é¡Œåˆ†æž",
    page_icon="ðŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# è·¯å¾‘è¨­å®š
# ============================================================================
BASE_DIR = Path(__file__).resolve().parent.parent.parent

# æ”¯æ´å±•ç¤ºæ¨¡å¼ï¼ˆç”¨æ–¼ Streamlit Cloud éƒ¨ç½²ï¼‰
# æœ¬åœ°é–‹ç™¼ï¼šä½¿ç”¨å®Œæ•´è³‡æ–™
# Streamlit Cloudï¼šä½¿ç”¨å±•ç¤ºè³‡æ–™ï¼ˆé€éŽç’°å¢ƒè®Šæ•¸æˆ– secrets è¨­å®šï¼‰
# è‡ªå‹•åµæ¸¬ Streamlit Cloud ç’°å¢ƒ
IS_STREAMLIT_CLOUD = os.getenv('STREAMLIT_SHARING_MODE') is not None or \
                      os.path.exists('/mount/src')

# å®‰å…¨åœ°æª¢æŸ¥ secrets
USE_DEMO_FROM_SECRETS = False
try:
    USE_DEMO_FROM_SECRETS = st.secrets.get('USE_DEMO_DATA', False)
except Exception:
    pass

USE_DEMO = os.getenv('USE_DEMO_DATA', 'false').lower() == 'true' or \
           USE_DEMO_FROM_SECRETS or \
           IS_STREAMLIT_CLOUD

# å¼·åˆ¶ä½¿ç”¨ demo è³‡æ–™åœ¨ Streamlit Cloud
# åµæ¸¬ /mount/src è·¯å¾‘ï¼ˆStreamlit Cloud ç‰¹å¾µï¼‰
if os.path.exists('/mount/src'):
    USE_DEMO = True

if USE_DEMO:
    DATA_DIR = BASE_DIR / "data_demo"
    RESULTS_DIR = BASE_DIR / "results_demo"
else:
    DATA_DIR = BASE_DIR / "data"
    RESULTS_DIR = BASE_DIR / "results"

RAW_DATA_DIR = DATA_DIR / "raw" / "taiwan"
PROCESSED_DATA_DIR = DATA_DIR / "processed" / "taiwan" if not USE_DEMO else DATA_DIR / "processed"

# ============================================================================
# å¿«å–è³‡æ–™è¼‰å…¥å‡½æ•¸
# ============================================================================

@st.cache_data
def load_hospital_list():
    """è¼‰å…¥é†«é™¢åˆ—è¡¨"""
    hospitals = []
    if RAW_DATA_DIR.exists():
        for file in sorted(RAW_DATA_DIR.glob("*.xlsx")):
            name_part = file.stem.split('_')
            if len(name_part) >= 2:
                hospital_name = name_part[1]
                hospitals.append(hospital_name)
    return hospitals

@st.cache_resource
def load_lda_model(k=7):
    """è¼‰å…¥ LDA æ¨¡åž‹"""
    model_dir = RESULTS_DIR / f"taiwan_lda_k{k}"
    model_path = model_dir / f"lda_k{k}_lda_model.pkl"

    if not model_path.exists():
        # å˜—è©¦è¼‰å…¥å…¶ä»–å‘½åæ ¼å¼
        alt_paths = list(model_dir.glob("*lda_model.pkl"))
        if alt_paths:
            model_path = alt_paths[0]
        else:
            return None, None, None

    try:
        with open(model_path, 'rb') as f:
            loaded_data = pickle.load(f)

        # æª¢æŸ¥æ˜¯å¦ç‚ºå­—å…¸æ ¼å¼ï¼ˆåŒ…å«å¤šå€‹è³‡è¨Šï¼‰
        if isinstance(loaded_data, dict):
            if 'lda_model' in loaded_data:
                # å­—å…¸æ ¼å¼ï¼Œæå– LDA æ¨¡åž‹
                model = loaded_data['lda_model']
            else:
                st.error(f"æ¨¡åž‹æª”æ¡ˆæ ¼å¼éŒ¯èª¤: æ‰¾ä¸åˆ° 'lda_model' éµ")
                st.error(f"å¯ç”¨çš„éµ: {list(loaded_data.keys())}")
                return None, None, None
        else:
            # ç›´æŽ¥æ˜¯æ¨¡åž‹ç‰©ä»¶
            model = loaded_data

        # å˜—è©¦è¼‰å…¥å­—å…¸å’Œèªžæ–™åº«
        dictionary = model.id2word if hasattr(model, 'id2word') else None

        return model, dictionary, model_path
    except Exception as e:
        st.error(f"è¼‰å…¥æ¨¡åž‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None, None, None

@st.cache_data
def load_analysis_results(k=7):
    """è¼‰å…¥åˆ†æžçµæžœ Excel æª”æ¡ˆ"""
    results_dir = RESULTS_DIR / f"taiwan_lda_k{k}" / "visualizations"
    results_path = results_dir / f"lda_k{k}_analysis_results.xlsx"

    if not results_path.exists():
        return None

    try:
        # è®€å–æ‰€æœ‰ sheets
        excel_file = pd.ExcelFile(results_path)
        sheets = {}
        for sheet_name in excel_file.sheet_names:
            sheets[sheet_name] = pd.read_excel(excel_file, sheet_name=sheet_name)
        return sheets
    except Exception as e:
        st.error(f"è¼‰å…¥åˆ†æžçµæžœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

@st.cache_data
def load_reviews_data():
    """è¼‰å…¥è©•è«–è³‡æ–™"""
    reviews_path = PROCESSED_DATA_DIR / "reviews_for_lda.txt"

    if not reviews_path.exists():
        return None

    try:
        reviews = []
        with open(reviews_path, 'r', encoding='utf-8') as f:
            for line in f:
                reviews.append(line.strip())
        return reviews
    except Exception as e:
        st.error(f"è¼‰å…¥è©•è«–è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

@st.cache_data
def load_raw_hospital_data(hospital_name):
    """è¼‰å…¥ç‰¹å®šé†«é™¢çš„åŽŸå§‹è³‡æ–™"""
    if RAW_DATA_DIR.exists():
        for file in RAW_DATA_DIR.glob("*.xlsx"):
            if hospital_name in file.stem:
                try:
                    df = pd.read_excel(file)
                    return df
                except Exception as e:
                    st.error(f"è¼‰å…¥ {hospital_name} è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    return None
    return None

@st.cache_data
def load_stopwords():
    """è¼‰å…¥åœç”¨è©ž"""
    stopwords = set()
    stopwords_path = BASE_DIR / "stopwords_custom.txt"

    if stopwords_path.exists():
        with open(stopwords_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    stopwords.add(line)

    # æ·»åŠ å¸¸è¦‹åœç”¨è©ž
    common_stopwords = ['çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€å€‹', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'èªª', 'è¦', 'åŽ»', 'ä½ ', 'æœƒ', 'è‘—', 'æ²’æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'é€™']
    stopwords.update(common_stopwords)

    return stopwords

@st.cache_data
def load_all_reviews_with_ratings():
    """è¼‰å…¥æ‰€æœ‰é†«é™¢çš„è©•è«–è³‡æ–™ï¼ˆåŒ…å«è©•åˆ†ï¼‰"""
    if not RAW_DATA_DIR.exists():
        return None

    all_reviews = []
    try:
        for file in sorted(RAW_DATA_DIR.glob("*.xlsx")):
            # è·³éŽåˆ†æžçµæžœæª”æ¡ˆ
            if 'analysis' in file.name or 'lda_k' in file.name:
                continue

            df = pd.read_excel(file)
            if 'review_text' in df.columns and 'rating' in df.columns:
                # æå–éœ€è¦çš„æ¬„ä½
                hospital_name = file.stem.split('_')[1] if '_' in file.stem else file.stem

                for _, row in df.iterrows():
                    # ç¢ºä¿ review_text æ˜¯å­—ä¸²ä¸”ä¸ç‚ºç©º
                    review_text = row['review_text']

                    # è™•ç†å„ç¨®è³‡æ–™é¡žåž‹
                    if pd.isna(review_text):
                        continue

                    # è½‰æ›ç‚ºå­—ä¸²
                    if not isinstance(review_text, str):
                        review_text = str(review_text)

                    # åŽ»é™¤ç©ºç™½ä¸¦æª¢æŸ¥æ˜¯å¦ç‚ºç©º
                    review_text = review_text.strip()
                    if not review_text:
                        continue

                    # è™•ç†è©•åˆ†
                    rating = row['rating'] if pd.notna(row['rating']) else 0
                    if not isinstance(rating, (int, float)):
                        try:
                            rating = float(rating)
                        except:
                            rating = 0

                    # è™•ç†è©•è«–è€…åç¨±
                    reviewer = row.get('reviewer_name', 'åŒ¿å')
                    if pd.isna(reviewer):
                        reviewer = 'åŒ¿å'
                    elif not isinstance(reviewer, str):
                        reviewer = str(reviewer)

                    # è™•ç†æ—¥æœŸ
                    date = row.get('review_date', '')
                    if pd.isna(date):
                        date = ''
                    elif not isinstance(date, str):
                        date = str(date)

                    all_reviews.append({
                        'hospital': hospital_name,
                        'text': review_text,
                        'rating': rating,
                        'reviewer': reviewer,
                        'date': date
                    })

        return pd.DataFrame(all_reviews) if all_reviews else None
    except Exception as e:
        st.error(f"è¼‰å…¥è©•è«–è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        st.error(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        return None

def assign_topics_to_reviews(_model, dictionary, reviews_df):
    """å°‡ä¸»é¡Œåˆ†é…çµ¦è©•è«–ï¼ˆç›´æŽ¥è™•ç†åŽŸå§‹è©•è«–ï¼‰"""
    if reviews_df is None or len(reviews_df) == 0:
        return None

    # è¼‰å…¥åœç”¨è©ž
    stopwords = load_stopwords()

    topic_assignments = []

    for _, row in reviews_df.iterrows():
        review_text = row['text']

        # ä½¿ç”¨ jieba é€²è¡Œåˆ†è©ž
        words = jieba.cut(review_text)

        # éŽæ¿¾åœç”¨è©žã€å–®å­—ç¬¦ã€æ•¸å­—
        filtered_words = [
            word for word in words
            if len(word) > 1 and
               word not in stopwords and
               not word.isdigit() and
               not re.match(r'^[a-zA-Z]+$', word)
        ]

        # è½‰æ›ç‚º bag-of-words
        bow = dictionary.doc2bow(filtered_words)

        if len(bow) == 0:
            # å¦‚æžœæ²’æœ‰æœ‰æ•ˆè©žå½™ï¼Œåˆ†é…åˆ°ä¸»é¡Œ0ï¼Œæ©ŸçŽ‡è¨­ç‚º0
            topic_assignments.append({
                'topic_id': 0,
                'probability': 0.0
            })
            continue

        # å–å¾—ä¸»é¡Œåˆ†ä½ˆ
        topic_dist = _model.get_document_topics(bow, minimum_probability=0)

        # æ‰¾å‡ºä¸»å°Žä¸»é¡Œ
        if len(topic_dist) > 0:
            dominant_topic = max(topic_dist, key=lambda x: x[1])
            topic_assignments.append({
                'topic_id': dominant_topic[0],
                'probability': dominant_topic[1]
            })
        else:
            topic_assignments.append({
                'topic_id': 0,
                'probability': 0.0
            })

    # åŠ å…¥ä¸»é¡Œè³‡è¨Šåˆ° DataFrame
    reviews_df['topic_id'] = [t['topic_id'] for t in topic_assignments]
    reviews_df['topic_probability'] = [t['probability'] for t in topic_assignments]

    return reviews_df

# ============================================================================
# åˆ†æžå‡½æ•¸
# ============================================================================

def get_topic_keywords(model, num_words=10):
    """å–å¾—æ¯å€‹ä¸»é¡Œçš„é—œéµè©ž"""
    topics = []
    for topic_id in range(model.num_topics):
        topic_words = model.show_topic(topic_id, topn=num_words)
        topics.append({
            'topic_id': topic_id,
            'keywords': [word for word, _ in topic_words],
            'weights': [weight for _, weight in topic_words]
        })
    return topics

def calculate_hospital_topic_distribution(model, dictionary, hospital_reviews):
    """è¨ˆç®—ç‰¹å®šé†«é™¢çš„ä¸»é¡Œåˆ†ä½ˆ"""
    if not hospital_reviews:
        return None

    topic_dist = np.zeros(model.num_topics)

    for review in hospital_reviews:
        # å°‡è©•è«–è½‰æ›ç‚º bag-of-words
        bow = dictionary.doc2bow(review.split())
        # å–å¾—ä¸»é¡Œåˆ†ä½ˆ
        doc_topics = model.get_document_topics(bow)
        for topic_id, prob in doc_topics:
            topic_dist[topic_id] += prob

    # æ­£è¦åŒ–
    topic_dist = topic_dist / len(hospital_reviews)
    return topic_dist

# ============================================================================
# è¦–è¦ºåŒ–å‡½æ•¸
# ============================================================================

def plot_topic_keywords(topics, selected_topics=None, figsize=None):
    """ç¹ªè£½ä¸»é¡Œé—œéµè©žæ¢ç‹€åœ–"""
    if selected_topics is None:
        selected_topics = range(len(topics))

    n_topics = len(selected_topics)

    # ä½¿ç”¨è‡ªå®šç¾©å°ºå¯¸æˆ–é»˜èªå°ºå¯¸
    if figsize is None:
        figsize = (12, 3*n_topics)

    fig, axes = plt.subplots(n_topics, 1, figsize=figsize)

    if n_topics == 1:
        axes = [axes]

    for idx, topic_idx in enumerate(selected_topics):
        topic = topics[topic_idx]
        keywords = topic['keywords'][:10]
        weights = topic['weights'][:10]

        axes[idx].barh(keywords, weights, color='steelblue')
        axes[idx].set_xlabel('æ¬Šé‡', fontsize=10)
        axes[idx].set_title(f'ä¸»é¡Œ {topic_idx}: {", ".join(keywords[:5])}...',
                           fontsize=12, fontweight='bold')
        axes[idx].invert_yaxis()

    plt.tight_layout()
    return fig

def plot_hospital_comparison(hospital_distributions, hospital_names, k=7):
    """ç¹ªè£½é†«é™¢ä¸»é¡Œåˆ†ä½ˆæ¯”è¼ƒåœ–"""
    fig, ax = plt.subplots(figsize=(12, 6))

    x = np.arange(k)
    width = 0.8 / len(hospital_names)

    for idx, (hospital_name, dist) in enumerate(zip(hospital_names, hospital_distributions)):
        offset = (idx - len(hospital_names)/2) * width + width/2
        ax.bar(x + offset, dist, width, label=hospital_name, alpha=0.8)

    ax.set_xlabel('ä¸»é¡Œç·¨è™Ÿ', fontsize=12)
    ax.set_ylabel('ä¸»é¡Œæ¯”ä¾‹', fontsize=12)
    ax.set_title('é†«é™¢ä¸»é¡Œåˆ†ä½ˆæ¯”è¼ƒ', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels([f'ä¸»é¡Œ{i}' for i in range(k)])
    ax.legend(loc='upper right')
    ax.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    return fig

def plot_topic_heatmap(hospital_distributions, hospital_names, k=7):
    """ç¹ªè£½é†«é™¢-ä¸»é¡Œç†±åŠ›åœ–"""
    fig, ax = plt.subplots(figsize=(10, len(hospital_names)*0.5 + 2))

    data = np.array(hospital_distributions)

    sns.heatmap(data,
                xticklabels=[f'ä¸»é¡Œ{i}' for i in range(k)],
                yticklabels=hospital_names,
                cmap='YlOrRd',
                annot=True,
                fmt='.3f',
                cbar_kws={'label': 'ä¸»é¡Œæ¯”ä¾‹'},
                ax=ax)

    ax.set_title('é†«é™¢-ä¸»é¡Œåˆ†ä½ˆç†±åŠ›åœ–', fontsize=14, fontweight='bold', pad=20)

    plt.tight_layout()
    return fig

# ============================================================================
# ä¸»ç¨‹å¼
# ============================================================================

def main():
    # æ¨™é¡Œ
    st.title("ðŸ¥ å°ç£é†«é™¢ LDA ä¸»é¡Œåˆ†æžç³»çµ±")

    # é¡¯ç¤ºå±•ç¤ºæ¨¡å¼æç¤º
    if USE_DEMO:
        st.info("ðŸ“Š å±•ç¤ºæ¨¡å¼ï¼šä½¿ç”¨ 5 å®¶é†«é™¢è³‡æ–™é€²è¡Œå±•ç¤º | å®Œæ•´ç‰ˆæœ¬åŒ…å« 26 å®¶é†«ç™‚ä¸­å¿ƒ")

    st.markdown("---")

    # å›ºå®šä½¿ç”¨ K=7ï¼ˆå·²ç¢ºå®šç‚ºæœ€ä½³ä¸»é¡Œæ•¸ï¼‰
    k_value = 7

    # å´é‚Šæ¬„
    with st.sidebar:
        st.header("âš™ï¸ å°Žè¦½")

        # åŠŸèƒ½é¸æ“‡
        page = st.radio(
            "é¸æ“‡åˆ†æžæ¨¡çµ„",
            ["ðŸ“Š ä¸»é¡Œç¸½è¦½", "ðŸ” ä¸»é¡Œæ·±å…¥æŽ¢ç´¢", "ðŸ¥ é†«é™¢è©•åˆ†æ¯”è¼ƒ", "ðŸ“ˆ çµ±è¨ˆå„€è¡¨æ¿"],
            label_visibility="visible"
        )

        st.markdown("---")

        # é¡¯ç¤ºæ¨¡åž‹è³‡è¨Š
        st.info(f"ðŸ“Œ ä½¿ç”¨æ¨¡åž‹ï¼šK=7 ä¸»é¡Œ\n\nðŸ’¡ é¦–æ¬¡è¼‰å…¥éœ€è¦å¹¾ç§’é˜")

    # è¼‰å…¥æ¨¡åž‹
    with st.spinner(f"è¼‰å…¥ K={k_value} çš„ LDA æ¨¡åž‹..."):
        model, dictionary, model_path = load_lda_model(k=k_value)

    if model is None:
        st.error(f"âŒ æ‰¾ä¸åˆ° K={k_value} çš„ LDA æ¨¡åž‹ï¼")
        st.info(f"è«‹ç¢ºèªä»¥ä¸‹è·¯å¾‘å­˜åœ¨æ¨¡åž‹æª”æ¡ˆ: {RESULTS_DIR / f'taiwan_lda_k{k_value}'}")
        return

    st.success(f"âœ… æˆåŠŸè¼‰å…¥ K={k_value} çš„ LDA æ¨¡åž‹")

    # æ ¹æ“šé¸æ“‡çš„é é¢é¡¯ç¤ºä¸åŒå…§å®¹
    if page == "ðŸ“Š ä¸»é¡Œç¸½è¦½":
        show_topic_overview(model, k_value)

    elif page == "ðŸ” ä¸»é¡Œæ·±å…¥æŽ¢ç´¢":
        show_topic_exploration(model, k_value)

    elif page == "ðŸ¥ é†«é™¢è©•åˆ†æ¯”è¼ƒ":
        show_hospital_rating_comparison(model, dictionary, k_value)

    elif page == "ðŸ“ˆ çµ±è¨ˆå„€è¡¨æ¿":
        show_statistics_dashboard(k_value)

# ============================================================================
# å„å€‹é é¢çš„é¡¯ç¤ºå‡½æ•¸
# ============================================================================

def show_topic_overview(model, k_value):
    """é¡¯ç¤ºä¸»é¡Œç¸½è¦½é é¢"""
    st.header("ðŸ“Š ä¸»é¡Œç¸½è¦½")

    # å–å¾—ä¸»é¡Œé—œéµè©žï¼ˆå¢žåŠ åˆ° 30 å€‹ï¼‰
    topics = get_topic_keywords(model, num_words=30)

    # é¡¯ç¤ºé¸é …
    col1, col2 = st.columns([1, 3])
    with col1:
        num_keywords = st.slider("é¡¯ç¤ºé—œéµè©žæ•¸é‡", 5, 30, 15)  # é è¨­15ï¼Œæœ€å¤š30
    with col2:
        display_mode = st.radio(
            "é¡¯ç¤ºæ¨¡å¼",
            ["è¡¨æ ¼", "è¦–è¦ºåŒ–"],
            horizontal=True
        )

    st.markdown("---")

    if display_mode == "è¡¨æ ¼":
        # è¡¨æ ¼é¡¯ç¤º
        for topic in topics:
            # é¡¯ç¤ºæ›´å¤šé—œéµè©žåœ¨æ¨™é¡Œ
            with st.expander(f"**ä¸»é¡Œ {topic['topic_id']}**: {', '.join(topic['keywords'][:8])}..."):
                topic_df = pd.DataFrame({
                    'é—œéµè©ž': topic['keywords'][:num_keywords],
                    'æ¬Šé‡': topic['weights'][:num_keywords]
                })
                st.dataframe(topic_df, use_container_width=True)
    else:
        # è¦–è¦ºåŒ–é¡¯ç¤º - ç¸®å°åœ–è¡¨
        col1, col2, col3 = st.columns([1, 1, 1])

        with col1:
            st.subheader("é—œéµè©žè¦–è¦ºåŒ–")
            fig = plot_topic_keywords(topics, figsize=(6, 12))
            st.pyplot(fig)
            plt.close()

        with col2:
            st.subheader("ä¸»é¡Œåˆ†ä½ˆ")
            viz_dir = RESULTS_DIR / f"taiwan_lda_k{k_value}" / "visualizations"
            dist_path = viz_dir / f"lda_k{k_value}_distribution.png"
            if dist_path.exists():
                st.image(str(dist_path), use_container_width=True)
            else:
                st.info("æš«ç„¡ä¸»é¡Œåˆ†ä½ˆåœ–")

        with col3:
            st.subheader("ä¸»é¡Œæ–‡å­—é›²")
            viz_dir = RESULTS_DIR / f"taiwan_lda_k{k_value}" / "visualizations"
            wordcloud_path = viz_dir / f"lda_k{k_value}_wordclouds.png"
            if wordcloud_path.exists():
                st.image(str(wordcloud_path), use_container_width=True)
            else:
                st.info("æš«ç„¡æ–‡å­—é›²åœ–")

def show_hospital_rating_comparison(model, dictionary, k_value):
    """é¡¯ç¤ºé†«é™¢åœ¨å„ä¸»é¡Œçš„è©•åˆ†æ¯”è¼ƒ"""
    st.header("ðŸ¥ é†«é™¢è©•åˆ†æ¯”è¼ƒåˆ†æž")

    st.markdown("""
    æ­¤é é¢é¡¯ç¤ºä¸åŒé†«é™¢åœ¨å„å€‹ä¸»é¡Œçš„å¹³å‡è©•åˆ†ï¼Œå¹«åŠ©æ‚¨äº†è§£ï¼š
    - å“ªäº›é†«é™¢åœ¨ç‰¹å®šæœå‹™é¢å‘ï¼ˆä¸»é¡Œï¼‰è¡¨ç¾è¼ƒå¥½
    - å„ä¸»é¡Œçš„æ•´é«”è©•åˆ†è¶¨å‹¢
    - é†«é™¢é–“çš„æœå‹™å“è³ªå·®ç•°
    """)

    st.markdown("---")

    # è¼‰å…¥æ‰€æœ‰è©•è«–è³‡æ–™
    with st.spinner("è¼‰å…¥è©•è«–è³‡æ–™ä¸¦åˆ†æžä¸»é¡Œ..."):
        reviews_df = load_all_reviews_with_ratings()

        if reviews_df is None or len(reviews_df) == 0:
            st.error("âŒ ç„¡æ³•è¼‰å…¥è©•è«–è³‡æ–™")
            return

        # åˆ†é…ä¸»é¡Œ
        reviews_with_topics = assign_topics_to_reviews(model, model.id2word, reviews_df)

        if reviews_with_topics is None:
            st.error("âŒ ç„¡æ³•é€²è¡Œä¸»é¡Œåˆ†é…")
            return

    st.success(f"âœ… æˆåŠŸåˆ†æž {len(reviews_with_topics)} æ¢è©•è«–")

    # ç²å–æ‰€æœ‰é†«é™¢åˆ—è¡¨
    all_hospitals = sorted(reviews_with_topics['hospital'].unique())

    # é¸æ“‡è¦æ¯”è¼ƒçš„é†«é™¢
    st.subheader("é¸æ“‡è¦æ¯”è¼ƒçš„é†«é™¢")
    selected_hospitals = st.multiselect(
        "é¸æ“‡é†«é™¢ï¼ˆå»ºè­° 3-8 å®¶ä»¥ä¾¿æ¸…æ¥šæ¯”è¼ƒï¼‰",
        all_hospitals,
        default=all_hospitals[:5] if len(all_hospitals) >= 5 else all_hospitals
    )

    if len(selected_hospitals) == 0:
        st.warning("âš ï¸ è«‹è‡³å°‘é¸æ“‡ 1 å®¶é†«é™¢")
        return

    st.markdown("---")

    # è¨ˆç®—æ¯å®¶é†«é™¢åœ¨å„ä¸»é¡Œçš„å¹³å‡è©•åˆ†
    topic_ratings = []
    for hospital in selected_hospitals:
        hospital_data = reviews_with_topics[reviews_with_topics['hospital'] == hospital]
        hospital_ratings = []
        for topic_id in range(k_value):
            topic_data = hospital_data[hospital_data['topic_id'] == topic_id]
            if len(topic_data) > 0:
                avg_rating = topic_data['rating'].mean()
                count = len(topic_data)
            else:
                avg_rating = 0
                count = 0
            hospital_ratings.append({
                'hospital': hospital,
                'topic': topic_id,
                'avg_rating': avg_rating,
                'count': count
            })
        topic_ratings.extend(hospital_ratings)

    ratings_df = pd.DataFrame(topic_ratings)

    # é¡¯ç¤ºé¸é …
    viz_type = st.radio(
        "é¸æ“‡è¦–è¦ºåŒ–é¡žåž‹",
        ["ðŸ“Š åˆ†çµ„é•·æ¢åœ–", "ðŸ”¥ ç†±åŠ›åœ–", "ðŸ“ˆ æŠ˜ç·šåœ–"],
        horizontal=True
    )

    st.markdown("---")

    if viz_type == "ðŸ“Š åˆ†çµ„é•·æ¢åœ–":
        # åˆ†çµ„é•·æ¢åœ–ï¼šæ¯å€‹ä¸»é¡Œé¡¯ç¤ºå„é†«é™¢è©•åˆ†
        st.subheader("å„ä¸»é¡Œçš„é†«é™¢è©•åˆ†æ¯”è¼ƒ")

        fig, ax = plt.subplots(figsize=(14, 6))

        x = np.arange(k_value)
        width = 0.8 / len(selected_hospitals)

        for idx, hospital in enumerate(selected_hospitals):
            hospital_data = ratings_df[ratings_df['hospital'] == hospital]
            ratings = [hospital_data[hospital_data['topic'] == t]['avg_rating'].values[0] for t in range(k_value)]
            offset = (idx - len(selected_hospitals)/2) * width + width/2
            ax.bar(x + offset, ratings, width, label=hospital, alpha=0.8)

        ax.set_xlabel('ä¸»é¡Œç·¨è™Ÿ', fontsize=12)
        ax.set_ylabel('å¹³å‡è©•åˆ†ï¼ˆæ˜Ÿç´šï¼‰', fontsize=12)
        ax.set_title('å„ä¸»é¡Œçš„é†«é™¢å¹³å‡è©•åˆ†æ¯”è¼ƒ', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels([f'ä¸»é¡Œ {i}' for i in range(k_value)])
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax.set_ylim(0, 5)
        ax.grid(axis='y', alpha=0.3)
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

    elif viz_type == "ðŸ”¥ ç†±åŠ›åœ–":
        # ç†±åŠ›åœ–ï¼šé†«é™¢ x ä¸»é¡Œ
        st.subheader("é†«é™¢-ä¸»é¡Œè©•åˆ†ç†±åŠ›åœ–")

        # å»ºç«‹çŸ©é™£
        heatmap_data = []
        for hospital in selected_hospitals:
            hospital_data = ratings_df[ratings_df['hospital'] == hospital]
            ratings = [hospital_data[hospital_data['topic'] == t]['avg_rating'].values[0] for t in range(k_value)]
            heatmap_data.append(ratings)

        fig, ax = plt.subplots(figsize=(10, max(6, len(selected_hospitals)*0.5)))
        im = ax.imshow(heatmap_data, cmap='RdYlGn', aspect='auto', vmin=0, vmax=5)

        # è¨­å®šåº§æ¨™è»¸
        ax.set_xticks(np.arange(k_value))
        ax.set_yticks(np.arange(len(selected_hospitals)))
        ax.set_xticklabels([f'ä¸»é¡Œ {i}' for i in range(k_value)])
        ax.set_yticklabels(selected_hospitals)

        # åœ¨æ ¼å­ä¸­é¡¯ç¤ºæ•¸å€¼
        for i in range(len(selected_hospitals)):
            for j in range(k_value):
                text = ax.text(j, i, f'{heatmap_data[i][j]:.2f}',
                             ha="center", va="center", color="black", fontsize=9)

        ax.set_title('é†«é™¢åœ¨å„ä¸»é¡Œçš„å¹³å‡è©•åˆ†', fontsize=14, fontweight='bold')
        fig.colorbar(im, ax=ax, label='å¹³å‡è©•åˆ†ï¼ˆæ˜Ÿç´šï¼‰')
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

    else:  # æŠ˜ç·šåœ–
        st.subheader("é†«é™¢è©•åˆ†è¶¨å‹¢æ¯”è¼ƒ")

        fig, ax = plt.subplots(figsize=(12, 6))

        for hospital in selected_hospitals:
            hospital_data = ratings_df[ratings_df['hospital'] == hospital]
            ratings = [hospital_data[hospital_data['topic'] == t]['avg_rating'].values[0] for t in range(k_value)]
            ax.plot(range(k_value), ratings, marker='o', label=hospital, linewidth=2)

        ax.set_xlabel('ä¸»é¡Œç·¨è™Ÿ', fontsize=12)
        ax.set_ylabel('å¹³å‡è©•åˆ†ï¼ˆæ˜Ÿç´šï¼‰', fontsize=12)
        ax.set_title('å„é†«é™¢åœ¨ä¸åŒä¸»é¡Œçš„è©•åˆ†è¶¨å‹¢', fontsize=14, fontweight='bold')
        ax.set_xticks(range(k_value))
        ax.set_xticklabels([f'ä¸»é¡Œ {i}' for i in range(k_value)])
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax.set_ylim(0, 5)
        ax.grid(True, alpha=0.3)
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

    # é¡¯ç¤ºè©³ç´°æ•¸æ“šè¡¨æ ¼
    st.markdown("---")
    with st.expander("ðŸ“‹ æŸ¥çœ‹è©³ç´°è©•åˆ†æ•¸æ“š", expanded=False):
        # é‡æ–°æ•´ç†æ•¸æ“šç‚ºè¡¨æ ¼æ ¼å¼
        pivot_df = ratings_df.pivot(index='hospital', columns='topic', values='avg_rating')
        pivot_df.columns = [f'ä¸»é¡Œ {i}' for i in range(k_value)]

        # æ·»åŠ å¹³å‡åˆ†åˆ—
        pivot_df['æ•´é«”å¹³å‡'] = pivot_df.mean(axis=1)

        # åªé¡¯ç¤ºé¸ä¸­çš„é†«é™¢
        pivot_df = pivot_df.loc[selected_hospitals]

        st.dataframe(pivot_df.style.format("{:.2f}").background_gradient(cmap='RdYlGn', vmin=0, vmax=5),
                    use_container_width=True)

        # é¡¯ç¤ºè©•è«–æ•¸é‡
        st.markdown("#### å„ä¸»é¡Œçš„è©•è«–æ•¸é‡")
        count_pivot = ratings_df.pivot(index='hospital', columns='topic', values='count')
        count_pivot.columns = [f'ä¸»é¡Œ {i}' for i in range(k_value)]
        count_pivot = count_pivot.loc[selected_hospitals]
        st.dataframe(count_pivot, use_container_width=True)

def show_hospital_comparison(model, dictionary, k_value):
    """é¡¯ç¤ºé†«é™¢æ¯”è¼ƒé é¢ï¼ˆèˆŠç‰ˆï¼Œä¿ç•™ä»¥é˜²è¬ä¸€ï¼‰"""
    st.header("ðŸ¥ é†«é™¢æ¯”è¼ƒåˆ†æž")

    # è¼‰å…¥é†«é™¢åˆ—è¡¨
    hospitals = load_hospital_list()

    if not hospitals:
        st.error("âŒ æ‰¾ä¸åˆ°é†«é™¢è³‡æ–™ï¼")
        return

    # é¸æ“‡è¦æ¯”è¼ƒçš„é†«é™¢
    selected_hospitals = st.multiselect(
        "é¸æ“‡è¦æ¯”è¼ƒçš„é†«é™¢ï¼ˆå»ºè­°é¸æ“‡ 2-5 å®¶ï¼‰",
        hospitals,
        default=hospitals[:3] if len(hospitals) >= 3 else hospitals
    )

    if len(selected_hospitals) < 2:
        st.warning("âš ï¸ è«‹è‡³å°‘é¸æ“‡ 2 å®¶é†«é™¢é€²è¡Œæ¯”è¼ƒ")
        return

    st.markdown("---")

    # è¼‰å…¥è©•è«–è³‡æ–™
    with st.spinner("è¼‰å…¥è©•è«–è³‡æ–™..."):
        all_reviews = load_reviews_data()

    if all_reviews is None:
        st.error("âŒ æ‰¾ä¸åˆ°è©•è«–è³‡æ–™ï¼")
        return

    # è¨ˆç®—å„é†«é™¢çš„ä¸»é¡Œåˆ†ä½ˆï¼ˆé€™è£¡ç°¡åŒ–è™•ç†ï¼Œå¯¦éš›æ‡‰è©²è¦æœ‰é†«é™¢æ¨™è¨˜ï¼‰
    st.info("â„¹ï¸ æ³¨æ„ï¼šç›®å‰ä½¿ç”¨æ•´é«”è³‡æ–™çš„ä¸»é¡Œåˆ†ä½ˆä½œç‚ºç¤ºç¯„ã€‚å®Œæ•´ç‰ˆéœ€è¦å€‹åˆ¥é†«é™¢çš„è©•è«–æ¨™è¨˜ã€‚")

    # ç¤ºç¯„ï¼šä½¿ç”¨æ¨¡åž‹çš„æ•´é«”ä¸»é¡Œåˆ†ä½ˆ
    topic_dist = np.zeros((len(selected_hospitals), model.num_topics))

    # å¾žåˆ†æžçµæžœè¼‰å…¥ï¼ˆå¦‚æžœæœ‰çš„è©±ï¼‰
    analysis_results = load_analysis_results(k=k_value)

    if analysis_results and 'topic_distribution' in analysis_results:
        st.success("âœ… å·²è¼‰å…¥ä¸»é¡Œåˆ†ä½ˆè³‡æ–™")
        # é€™è£¡å¯ä»¥é€²ä¸€æ­¥è™•ç†

    # ç¤ºç¯„è³‡æ–™ï¼ˆéš¨æ©Ÿç”Ÿæˆï¼Œå¯¦éš›æ‡‰è©²å¾žçœŸå¯¦è³‡æ–™è¨ˆç®—ï¼‰
    for i in range(len(selected_hospitals)):
        # ç”Ÿæˆéš¨æ©Ÿä½†åˆç†çš„ä¸»é¡Œåˆ†ä½ˆ
        np.random.seed(i * 42)  # å›ºå®šç¨®å­ä»¥ä¿æŒä¸€è‡´æ€§
        random_dist = np.random.dirichlet(np.ones(model.num_topics) * 5)
        topic_dist[i] = random_dist

    # é¡¯ç¤ºè¦–è¦ºåŒ–é¸é …
    viz_type = st.radio(
        "é¸æ“‡è¦–è¦ºåŒ–é¡žåž‹",
        ["é•·æ¢åœ–æ¯”è¼ƒ", "ç†±åŠ›åœ–"],
        horizontal=True
    )

    if viz_type == "é•·æ¢åœ–æ¯”è¼ƒ":
        fig = plot_hospital_comparison(topic_dist, selected_hospitals, k=k_value)
        st.pyplot(fig)
        plt.close()
    else:
        fig = plot_topic_heatmap(topic_dist, selected_hospitals, k=k_value)
        st.pyplot(fig)
        plt.close()

    # é¡¯ç¤ºæ•¸å€¼è¡¨æ ¼
    with st.expander("ðŸ“Š æŸ¥çœ‹è©³ç´°æ•¸å€¼"):
        dist_df = pd.DataFrame(
            topic_dist,
            columns=[f'ä¸»é¡Œ{i}' for i in range(k_value)],
            index=selected_hospitals
        )
        st.dataframe(dist_df.style.format("{:.4f}"), use_container_width=True)

def show_topic_exploration(model, k_value):
    """é¡¯ç¤ºä¸»é¡Œæ·±å…¥æŽ¢ç´¢é é¢"""
    st.header("ðŸ” ä¸»é¡Œæ·±å…¥æŽ¢ç´¢")

    # é¸æ“‡è¦æŽ¢ç´¢çš„ä¸»é¡Œ
    topic_id = st.selectbox(
        "é¸æ“‡ä¸»é¡Œ",
        range(model.num_topics),
        format_func=lambda x: f"ä¸»é¡Œ {x}"
    )

    st.markdown("---")

    # é¡¯ç¤ºä¸»é¡Œé—œéµè©žï¼ˆå¢žåŠ åˆ°30å€‹ï¼‰
    st.subheader(f"ä¸»é¡Œ {topic_id} - é—œéµè©žèˆ‡æ¬Šé‡")
    topic_words = model.show_topic(topic_id, topn=30)
    topic_df = pd.DataFrame(topic_words, columns=['é—œéµè©ž', 'æ¬Šé‡'])

    # ä½¿ç”¨å…©æ¬„é¡¯ç¤ºè¡¨æ ¼ï¼Œç¯€çœç©ºé–“
    col1, col2 = st.columns(2)
    with col1:
        st.dataframe(topic_df.head(15), use_container_width=True, height=400)
    with col2:
        st.dataframe(topic_df.tail(15), use_container_width=True, height=400)

    # æ–°å¢žï¼šé¡¯ç¤ºè©²ä¸»é¡Œçš„è©•è«–
    st.markdown("---")
    st.subheader(f"ðŸ“ ä¸»é¡Œ {topic_id} çš„ä»£è¡¨æ€§è©•è«–")

    with st.spinner("è¼‰å…¥è©•è«–è³‡æ–™..."):
        # è¼‰å…¥è©•è«–è³‡æ–™
        reviews_df = load_all_reviews_with_ratings()

        if reviews_df is not None:
            # åˆ†é…ä¸»é¡Œï¼ˆç›´æŽ¥è™•ç†åŽŸå§‹è©•è«–ï¼‰
            reviews_with_topics = assign_topics_to_reviews(model, model.id2word, reviews_df)

            if reviews_with_topics is not None:
                # ç¯©é¸è©²ä¸»é¡Œçš„è©•è«–
                topic_reviews = reviews_with_topics[reviews_with_topics['topic_id'] == topic_id].copy()
                topic_reviews = topic_reviews.sort_values('topic_probability', ascending=False)

                # é¡¯ç¤ºçµ±è¨ˆ
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("è©•è«–æ•¸é‡", len(topic_reviews))
                with col2:
                    avg_rating = topic_reviews['rating'].mean()
                    st.metric("å¹³å‡è©•åˆ†", f"{avg_rating:.2f} â­")
                with col3:
                    rating_dist = topic_reviews['rating'].value_counts().sort_index(ascending=False)
                    st.metric("æœ€å¸¸è¦‹è©•åˆ†", f"{rating_dist.index[0]} æ˜Ÿ")

                # é¡¯ç¤ºè©•åˆ†åˆ†ä½ˆ
                st.markdown("#### è©•åˆ†åˆ†ä½ˆ")
                rating_counts = topic_reviews['rating'].value_counts().sort_index(ascending=False)
                fig, ax = plt.subplots(figsize=(10, 4))
                ax.bar(rating_counts.index.astype(str), rating_counts.values, color='steelblue')
                ax.set_xlabel('è©•åˆ†ï¼ˆæ˜Ÿç´šï¼‰')
                ax.set_ylabel('è©•è«–æ•¸é‡')
                ax.set_title(f'ä¸»é¡Œ {topic_id} çš„è©•åˆ†åˆ†ä½ˆ')
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()

                # é¡¯ç¤ºä»£è¡¨æ€§è©•è«–
                st.markdown("#### ä»£è¡¨æ€§è©•è«–ï¼ˆæŒ‰ä¸»é¡Œç›¸é—œåº¦æŽ’åºï¼‰")

                # ç¯©é¸æ¢ä»¶
                col1, col2 = st.columns([1, 1])
                with col1:
                    selected_rating = st.selectbox(
                        "ç¯©é¸è©•åˆ†",
                        ["å…¨éƒ¨"] + [f"{i} æ˜Ÿ" for i in range(5, 0, -1)]
                    )
                with col2:
                    num_reviews = st.slider("é¡¯ç¤ºè©•è«–æ•¸é‡", 5, 50, 10)

                # æ‡‰ç”¨ç¯©é¸
                filtered_reviews = topic_reviews.copy()
                if selected_rating != "å…¨éƒ¨":
                    rating_value = int(selected_rating.split()[0])
                    filtered_reviews = filtered_reviews[filtered_reviews['rating'] == rating_value]

                # é¡¯ç¤ºè©•è«–ï¼ˆé è¨­å±•é–‹ï¼‰
                if len(filtered_reviews) == 0:
                    st.info("ðŸ” æ­¤ç¯©é¸æ¢ä»¶ä¸‹æ²’æœ‰è©•è«–")
                else:
                    for idx, (_, row) in enumerate(filtered_reviews.head(num_reviews).iterrows(), 1):
                        # ä½¿ç”¨å¡ç‰‡å¼é¡¯ç¤ºï¼Œé è¨­å±•é–‹
                        with st.container():
                            st.markdown(f"#### è©•è«– {idx}")
                            col_meta1, col_meta2, col_meta3 = st.columns(3)
                            with col_meta1:
                                st.metric("è©•åˆ†", f"{row['rating']} â­")
                            with col_meta2:
                                st.metric("ä¸»é¡Œç›¸é—œåº¦", f"{row['topic_probability']:.1%}")
                            with col_meta3:
                                st.metric("é†«é™¢", "")
                                st.caption(row['hospital'])

                            st.markdown("**è©•è«–å…§å®¹ï¼š**")
                            st.write(row['text'])

                            if row['date']:
                                st.caption(f"ðŸ“… æ—¥æœŸ: {row['date']}")

                            st.markdown("---")
            else:
                st.warning("ç„¡æ³•åˆ†é…ä¸»é¡Œåˆ°è©•è«–")
        else:
            st.info("ðŸ’¡ è©•è«–è³‡æ–™è¼‰å…¥ä¸­æˆ–ä¸å¯ç”¨ã€‚æ­¤åŠŸèƒ½éœ€è¦åŽŸå§‹è©•è«–è³‡æ–™ã€‚")

def show_statistics_dashboard(k_value):
    """é¡¯ç¤ºçµ±è¨ˆå„€è¡¨æ¿é é¢"""
    st.header("ðŸ“ˆ çµ±è¨ˆå„€è¡¨æ¿")

    # è¼‰å…¥é è™•ç†çµ±è¨ˆ
    stats_path = PROCESSED_DATA_DIR / "preprocessing_stats.txt"

    if stats_path.exists():
        with open(stats_path, 'r', encoding='utf-8') as f:
            stats_content = f.read()

        # è§£æžçµ±è¨ˆè³‡è¨Š
        lines = stats_content.strip().split('\n')

        # é¡¯ç¤ºç¸½é«”çµ±è¨ˆ
        st.subheader("ðŸ“Š è³‡æ–™é›†çµ±è¨ˆ")

        col1, col2, col3, col4 = st.columns(4)

        # æå–æ•¸å­—
        total_reviews = int(lines[2].split(': ')[1])
        num_hospitals = int(lines[3].split(': ')[1])
        avg_words = float(lines[4].split(': ')[1])

        col1.metric("ç¸½è©•è«–æ•¸", f"{total_reviews:,}")
        col2.metric("é†«é™¢æ•¸é‡", f"{num_hospitals}")
        col3.metric("å¹³å‡è©žæ•¸", f"{avg_words:.1f}")
        col4.metric("LDA ä¸»é¡Œæ•¸", k_value)

        st.markdown("---")

        # å„é†«é™¢è©•è«–æ•¸é‡
        st.subheader("ðŸ¥ å„é†«é™¢è©•è«–æ•¸é‡")

        # æ‰¾åˆ°é†«é™¢åˆ—è¡¨é–‹å§‹çš„è¡Œ
        hospital_start_idx = None
        for i, line in enumerate(lines):
            if "=== å„é†«é™¢è©•è«–æ•¸é‡ ===" in line:
                hospital_start_idx = i + 2
                break

        if hospital_start_idx:
            hospital_data = []
            for line in lines[hospital_start_idx:]:
                if line.strip() and ':' in line:
                    parts = line.split(': ')
                    if len(parts) == 2:
                        hospital_data.append({
                            'é†«é™¢åç¨±': parts[0].strip(),
                            'è©•è«–æ•¸': int(parts[1].strip())
                        })

            if hospital_data:
                hospital_df = pd.DataFrame(hospital_data)
                hospital_df = hospital_df.sort_values('è©•è«–æ•¸', ascending=False)

                # é•·æ¢åœ–
                fig, ax = plt.subplots(figsize=(12, 8))
                ax.barh(hospital_df['é†«é™¢åç¨±'], hospital_df['è©•è«–æ•¸'], color='steelblue')
                ax.set_xlabel('è©•è«–æ•¸', fontsize=12)
                ax.set_title('å„é†«é™¢è©•è«–æ•¸é‡åˆ†ä½ˆ', fontsize=14, fontweight='bold')
                ax.invert_yaxis()
                ax.grid(axis='x', alpha=0.3)
                plt.tight_layout()
                st.pyplot(fig)
                plt.close()

                # é¡¯ç¤ºè¡¨æ ¼
                with st.expander("ðŸ“‹ æŸ¥çœ‹è©³ç´°æ•¸æ“š"):
                    st.dataframe(hospital_df, use_container_width=True, height=400)

    # è¼‰å…¥ç¾æœ‰çš„è¦–è¦ºåŒ–åœ–è¡¨
    st.markdown("---")
    st.subheader("ðŸ“Š LDA åˆ†æžçµæžœè¦–è¦ºåŒ–")

    viz_dir = RESULTS_DIR / f"taiwan_lda_k{k_value}" / "visualizations"
    if viz_dir.exists():
        col1, col2 = st.columns(2)

        with col1:
            dist_path = viz_dir / f"lda_k{k_value}_distribution.png"
            if dist_path.exists():
                st.image(str(dist_path), caption="ä¸»é¡Œåˆ†ä½ˆåœ–", use_container_width=True)

        with col2:
            heatmap_path = viz_dir / f"lda_k{k_value}_rating_heatmap.png"
            if heatmap_path.exists():
                st.image(str(heatmap_path), caption="è©•åˆ†ç†±åŠ›åœ–", use_container_width=True)

# ============================================================================
# åŸ·è¡Œä¸»ç¨‹å¼
# ============================================================================

if __name__ == "__main__":
    main()
