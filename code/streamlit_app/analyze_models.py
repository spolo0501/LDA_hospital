#!/usr/bin/env python3
"""
åˆ†æå°ç£ K=7 å’Œç¾åœ‹ K=6 LDA æ¨¡å‹ï¼Œç”Ÿæˆä¸»é¡Œæ¨™ç±¤
"""

import pickle
from pathlib import Path
import pandas as pd

# è·¯å¾‘è¨­å®š
BASE_DIR = Path(__file__).resolve().parent.parent.parent
TAIWAN_MODEL_PATH = BASE_DIR / "results/taiwan_lda_k7/lda_k7_lda_model.pkl"
USA_MODEL_PATH = BASE_DIR / "results/usa_lda_k7/usa_gensim_lda_k6_model.pkl"
USA_DATA_PATH = BASE_DIR / "results/usa_lda_k7/usa_k6_topic_analysis_20251107_122236.csv"

print("=" * 80)
print("ğŸ” å°ç£ K=7 LDA æ¨¡å‹åˆ†æ")
print("=" * 80)

# è¼‰å…¥å°ç£æ¨¡å‹
with open(TAIWAN_MODEL_PATH, 'rb') as f:
    taiwan_data = pickle.load(f)
    taiwan_model = taiwan_data['lda_model']
    taiwan_dictionary = taiwan_model.id2word

print(f"\nå°ç£æ¨¡å‹è³‡è¨Šï¼š")
print(f"  ä¸»é¡Œæ•¸é‡: {taiwan_model.num_topics}")
print(f"  è©å½™æ•¸é‡: {len(taiwan_dictionary)}")

print("\nå°ç£ 7 å€‹ä¸»é¡Œçš„é—œéµè©ï¼š")
for topic_id in range(taiwan_model.num_topics):
    words = taiwan_model.show_topic(topic_id, topn=15)
    words_str = ", ".join([f"{w}({p:.3f})" for w, p in words])
    print(f"\nTopic {topic_id}:")
    print(f"  {words_str}")

print("\n" + "=" * 80)
print("ğŸ” ç¾åœ‹ K=6 LDA æ¨¡å‹åˆ†æ")
print("=" * 80)

# è¼‰å…¥ç¾åœ‹æ¨¡å‹
with open(USA_MODEL_PATH, 'rb') as f:
    usa_data = pickle.load(f)
    usa_model = usa_data['lda_model']
    usa_dictionary = usa_data['dictionary']

print(f"\nç¾åœ‹æ¨¡å‹è³‡è¨Šï¼š")
print(f"  ä¸»é¡Œæ•¸é‡: {usa_model.num_topics}")
print(f"  è©å½™æ•¸é‡: {len(usa_dictionary)}")

print("\nç¾åœ‹ 6 å€‹ä¸»é¡Œçš„é—œéµè©ï¼š")
for topic_id in range(usa_model.num_topics):
    words = usa_model.show_topic(topic_id, topn=15)
    words_str = ", ".join([f"{w}({p:.3f})" for w, p in words])
    print(f"\nTopic {topic_id}:")
    print(f"  {words_str}")

# è¼‰å…¥ç¾åœ‹è©•è«–è³‡æ–™ï¼Œåˆ†æä¸»é¡Œåˆ†ä½ˆ
print("\n" + "=" * 80)
print("ğŸ“Š ç¾åœ‹ä¸»é¡Œåˆ†ä½ˆèˆ‡è©•åˆ†åˆ†æ")
print("=" * 80)

usa_df = pd.read_csv(USA_DATA_PATH)
print(f"\nç¾åœ‹è©•è«–ç¸½æ•¸: {len(usa_df)}")

# çµ±è¨ˆæ¯å€‹ä¸»é¡Œçš„è©•è«–æ•¸å’Œå¹³å‡è©•åˆ†
topic_stats = usa_df.groupby('dominant_topic').agg({
    'è©•åˆ†': ['count', 'mean'],
    'topic_probability': 'mean'
}).round(2)

topic_stats.columns = ['è©•è«–æ•¸', 'å¹³å‡è©•åˆ†', 'å¹³å‡æ©Ÿç‡']
topic_stats['æ¯”ä¾‹(%)'] = (topic_stats['è©•è«–æ•¸'] / len(usa_df) * 100).round(1)

print("\nç¾åœ‹å„ä¸»é¡Œçµ±è¨ˆï¼š")
print(topic_stats)

print("\n" + "=" * 80)
print("âœ… åˆ†æå®Œæˆï¼")
print("=" * 80)
