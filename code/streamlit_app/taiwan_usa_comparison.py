#!/usr/bin/env python3
"""
å°ç¾é†«é™¢è©•è«–è·¨æ–‡åŒ–æ¯”è¼ƒåˆ†æç³»çµ±
Taiwan-USA Hospital Review Cross-Cultural Comparison System

Author: Claude Code
Date: 2025-11-12
"""

import streamlit as st
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# å°å…¥é…ç½®
from comparison_config import *

# è¨­å®šé é¢é…ç½®
st.set_page_config(**PAGE_CONFIG)

# ============================================
# è³‡æ–™è¼‰å…¥å‡½æ•¸
# ============================================

@st.cache_resource
def load_taiwan_model():
    """è¼‰å…¥å°ç£ LDA K=7 æ¨¡å‹"""
    with open(TAIWAN_MODEL_PATH, 'rb') as f:
        data = pickle.load(f)
    return data['lda_model'], data

@st.cache_resource
def load_usa_model():
    """è¼‰å…¥ç¾åœ‹ LDA K=6 æ¨¡å‹"""
    with open(USA_MODEL_PATH, 'rb') as f:
        data = pickle.load(f)
    return data['lda_model'], data

@st.cache_data
def load_usa_reviews():
    """è¼‰å…¥ç¾åœ‹è©•è«–è³‡æ–™"""
    df = pd.read_csv(USA_DATA_PATH)
    return df

# ============================================
# è³‡æ–™è™•ç†å‡½æ•¸
# ============================================

def get_topic_statistics(df, country="usa"):
    """è¨ˆç®—ä¸»é¡Œçµ±è¨ˆ"""
    stats = df.groupby('dominant_topic').agg({
        'è©•åˆ†': ['count', 'mean', 'std'],
        'topic_probability': 'mean'
    }).round(2)

    stats.columns = ['è©•è«–æ•¸', 'å¹³å‡è©•åˆ†', 'è©•åˆ†æ¨™æº–å·®', 'å¹³å‡æ©Ÿç‡']
    stats['æ¯”ä¾‹(%)'] = (stats['è©•è«–æ•¸'] / len(df) * 100).round(1)

    return stats

def create_comparison_dataframe():
    """å»ºç«‹å°ç¾æ¯”è¼ƒè³‡æ–™è¡¨"""
    comparison_data = []

    # å°ç£è³‡æ–™
    for topic_id, info in TAIWAN_TOPICS.items():
        comparison_data.append({
            "åœ‹å®¶": "ğŸ‡¹ğŸ‡¼ å°ç£",
            "ä¸»é¡ŒID": topic_id,
            "ä¸»é¡Œæ¨™ç±¤": f"{info['emoji']} {info['label_zh']}",
            "è‹±æ–‡æ¨™ç±¤": info['label_en'],
            "æƒ…ç·’": info['sentiment'],
            "é—œéµè©": ", ".join(info['keywords'][:5])
        })

    # ç¾åœ‹è³‡æ–™
    for topic_id, info in USA_TOPICS.items():
        comparison_data.append({
            "åœ‹å®¶": "ğŸ‡ºğŸ‡¸ ç¾åœ‹",
            "ä¸»é¡ŒID": topic_id,
            "ä¸»é¡Œæ¨™ç±¤": f"{info['emoji']} {info['label_zh']}",
            "è‹±æ–‡æ¨™ç±¤": info['label_en'],
            "æƒ…ç·’": info['sentiment'],
            "é—œéµè©": ", ".join(info['keywords'][:5])
        })

    return pd.DataFrame(comparison_data)

# ============================================
# è¦–è¦ºåŒ–å‡½æ•¸
# ============================================

def plot_model_quality_comparison():
    """ç¹ªè£½æ¨¡å‹å“è³ªæ¯”è¼ƒåœ–"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

    # Coherence Score
    countries = ['Taiwan\nK=7', 'USA\nK=6']
    coherence = [DATASET_INFO['taiwan']['coherence'], DATASET_INFO['usa']['coherence']]
    colors = [COLORS['taiwan']['primary'], COLORS['usa']['primary']]

    ax1.bar(countries, coherence, color=colors, alpha=0.7, edgecolor='black')
    ax1.set_ylabel('Coherence Score', fontsize=12)
    ax1.set_title('Model Coherence Comparison', fontsize=14, fontweight='bold')
    ax1.set_ylim([0, 0.45])
    ax1.grid(axis='y', alpha=0.3)

    # æ·»åŠ æ•¸å€¼æ¨™ç±¤
    for i, v in enumerate(coherence):
        ax1.text(i, v + 0.01, f'{v:.4f}', ha='center', fontweight='bold')

    # Perplexity (çµ•å°å€¼)
    perplexity = [abs(DATASET_INFO['taiwan']['perplexity']),
                  abs(DATASET_INFO['usa']['perplexity'])]

    ax2.bar(countries, perplexity, color=colors, alpha=0.7, edgecolor='black')
    ax2.set_ylabel('Perplexity (Absolute Value)', fontsize=12)
    ax2.set_title('Model Perplexity Comparison', fontsize=14, fontweight='bold')
    ax2.grid(axis='y', alpha=0.3)

    # æ·»åŠ æ•¸å€¼æ¨™ç±¤
    for i, v in enumerate(perplexity):
        ax2.text(i, v + 0.1, f'{v:.2f}', ha='center', fontweight='bold')

    plt.tight_layout()
    return fig

def plot_dataset_size_comparison():
    """ç¹ªè£½è³‡æ–™é›†è¦æ¨¡æ¯”è¼ƒ"""
    fig, ax = plt.subplots(figsize=(8, 5))

    countries = ['Taiwan', 'USA']
    reviews = [DATASET_INFO['taiwan']['reviews'], DATASET_INFO['usa']['reviews']]
    colors = [COLORS['taiwan']['primary'], COLORS['usa']['primary']]

    bars = ax.barh(countries, reviews, color=colors, alpha=0.7, edgecolor='black')
    ax.set_xlabel('Number of Reviews', fontsize=12)
    ax.set_title('Dataset Size Comparison', fontsize=14, fontweight='bold')
    ax.grid(axis='x', alpha=0.3)

    # æ·»åŠ æ•¸å€¼æ¨™ç±¤
    for i, (bar, v) in enumerate(zip(bars, reviews)):
        ax.text(v + 50, i, f'{v:,}', va='center', fontweight='bold')

    plt.tight_layout()
    return fig

def plot_sentiment_distribution(usa_df):
    """ç¹ªè£½æƒ…ç·’åˆ†ä½ˆæ¯”è¼ƒ"""
    # è¨ˆç®—ç¾åœ‹å„ä¸»é¡Œçš„æƒ…ç·’
    usa_sentiment_counts = {'positive': 0, 'negative': 0, 'neutral': 0}

    for topic_id in range(6):
        topic_reviews = len(usa_df[usa_df['dominant_topic'] == topic_id])
        sentiment = USA_TOPICS[topic_id]['sentiment']
        usa_sentiment_counts[sentiment] += topic_reviews

    # è¨ˆç®—å°ç£å„ä¸»é¡Œçš„æƒ…ç·’ï¼ˆä½¿ç”¨æ¯”ä¾‹ä¼°ç®—ï¼‰
    taiwan_total = DATASET_INFO['taiwan']['reviews']
    taiwan_sentiment_counts = {'positive': 0, 'negative': 0, 'neutral': 0}

    # å¾ä¸»é¡Œåˆ†ä½ˆä¼°ç®—ï¼ˆé€™è£¡éœ€è¦å¯¦éš›è³‡æ–™ï¼Œæš«æ™‚ä½¿ç”¨æ¨¡æ“¬ï¼‰
    # å¯¦éš›æ‡‰ç”¨æ™‚éœ€è¦è¼‰å…¥å°ç£è©•è«–è³‡æ–™
    taiwan_topic_dist = [0.249, 0.151, 0.173, 0.102, 0.096, 0.125, 0.103]  # å¾å ±å‘Šä¸­ç²å–
    for topic_id in range(7):
        reviews = int(taiwan_total * taiwan_topic_dist[topic_id])
        sentiment = TAIWAN_TOPICS[topic_id]['sentiment']
        taiwan_sentiment_counts[sentiment] += reviews

    # è½‰æ›ç‚ºç™¾åˆ†æ¯”
    taiwan_pct = {k: v/taiwan_total*100 for k, v in taiwan_sentiment_counts.items()}
    usa_pct = {k: v/len(usa_df)*100 for k, v in usa_sentiment_counts.items()}

    # ç¹ªåœ–
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

    sentiments = ['Positive', 'Neutral', 'Negative']
    taiwan_values = [taiwan_pct['positive'], taiwan_pct['neutral'], taiwan_pct['negative']]
    usa_values = [usa_pct['positive'], usa_pct['neutral'], usa_pct['negative']]
    sentiment_colors = [COLORS['sentiment']['positive'],
                       COLORS['sentiment']['neutral'],
                       COLORS['sentiment']['negative']]

    # å°ç£
    wedges1, texts1, autotexts1 = ax1.pie(taiwan_values, labels=sentiments, autopct='%1.1f%%',
                                            colors=sentiment_colors, startangle=90)
    ax1.set_title('ğŸ‡¹ğŸ‡¼ Taiwan Sentiment Distribution', fontsize=12, fontweight='bold')

    # ç¾åœ‹
    wedges2, texts2, autotexts2 = ax2.pie(usa_values, labels=sentiments, autopct='%1.1f%%',
                                            colors=sentiment_colors, startangle=90)
    ax2.set_title('ğŸ‡ºğŸ‡¸ USA Sentiment Distribution', fontsize=12, fontweight='bold')

    plt.tight_layout()
    return fig

def plot_topic_mapping_sankey():
    """ç¹ªè£½ä¸»é¡Œå°æ‡‰æ¡‘åŸºåœ–"""
    # å»ºç«‹ç¯€é»æ¨™ç±¤ï¼ˆç°¡çŸ­ç‰ˆæœ¬ï¼Œæ–¹ä¾¿é¡¯ç¤ºï¼‰
    taiwan_labels = [
        "T0: é†«ç™‚å°ˆæ¥­èªå¯",
        "T1: å°±è¨ºæµç¨‹ç­‰å€™",
        "T2: æœå‹™æ…‹åº¦å•é¡Œ",
        "T3: è¨­æ–½ä¾¿åˆ©æ€§",
        "T4: æ‰‹è¡“æ²»ç™‚æˆåŠŸ",
        "T5: ä½é™¢ç…§è­·",
        "T6: æ€¥è¨ºæºé€š"
    ]

    usa_labels = [
        "T0: é‡ç—‡ç…§è­·",
        "T1: æ€¥è¨ºç­‰å€™",
        "T2: ç–¼ç—›ç®¡ç†",
        "T3: è­·ç†å“è³ª",
        "T4: æ­£é¢è©•åƒ¹",
        "T5: å¸³å–®å•é¡Œ"
    ]

    # åˆä½µæ¨™ç±¤
    nodes = taiwan_labels + usa_labels

    # ç¯€é»é¡è‰²
    node_colors = [COLORS['taiwan']['primary']] * 7 + [COLORS['usa']['primary']] * 6

    # å»ºç«‹é€£ç·š
    sources = []
    targets = []
    values = []
    link_colors = []
    link_labels = []

    for mapping in TOPIC_MAPPING:
        if mapping['taiwan_topic'] is not None and mapping['usa_topic'] is not None:
            sources.append(mapping['taiwan_topic'])
            targets.append(mapping['usa_topic'] + 7)  # ç¾åœ‹ç¯€é»ç´¢å¼•å¾7é–‹å§‹
            values.append(mapping['similarity'] * 20)  # æ”¾å¤§ç›¸ä¼¼åº¦ä»¥ä¾¿è¦–è¦ºåŒ–

            # æ ¹æ“šç›¸ä¼¼åº¦è¨­å®šé¡è‰²
            similarity = mapping['similarity']
            if similarity >= 4:
                color = f'rgba(46, 204, 113, 0.4)'  # ç¶ è‰²ï¼ˆé«˜ç›¸ä¼¼åº¦ï¼‰
            elif similarity >= 3:
                color = f'rgba(243, 156, 18, 0.4)'  # æ©˜è‰²ï¼ˆä¸­ç­‰ç›¸ä¼¼åº¦ï¼‰
            else:
                color = f'rgba(231, 76, 60, 0.3)'   # ç´…è‰²ï¼ˆä½ç›¸ä¼¼åº¦ï¼‰
            link_colors.append(color)

            # é€£ç·šæ¨™ç±¤
            stars = "â˜…" * similarity
            link_labels.append(f"{stars}")

    fig = go.Figure(data=[go.Sankey(
        node=dict(
            pad=20,
            thickness=25,
            line=dict(color="white", width=2),
            label=nodes,
            color=node_colors,
            customdata=[f"ğŸ‡¹ğŸ‡¼ å°ç£"] * 7 + [f"ğŸ‡ºğŸ‡¸ ç¾åœ‹"] * 6,
            hovertemplate='%{label}<br>%{customdata}<extra></extra>'
        ),
        link=dict(
            source=sources,
            target=targets,
            value=values,
            color=link_colors,
            customdata=link_labels,
            hovertemplate='ç›¸ä¼¼åº¦: %{customdata}<br>é€£ç·šå¼·åº¦: %{value}<extra></extra>'
        ),
        textfont=dict(size=14, family="Arial, sans-serif")
    )])

    fig.update_layout(
        title={
            'text': "å°ç¾é†«é™¢è©•è«–ä¸»é¡Œå°æ‡‰é—œä¿‚<br><sub>é€£ç·šé¡è‰²ï¼šç¶ è‰²=é«˜ç›¸ä¼¼åº¦, æ©˜è‰²=ä¸­ç­‰ç›¸ä¼¼åº¦, ç´…è‰²=ä½ç›¸ä¼¼åº¦</sub>",
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 16}
        },
        font=dict(size=13, family="Arial, sans-serif"),
        height=700,
        margin=dict(l=20, r=20, t=80, b=20)
    )

    return fig

def plot_keyword_comparison(taiwan_model, usa_model, topic_tw, topic_us):
    """ç¹ªè£½ç‰¹å®šä¸»é¡Œçš„é—œéµè©æ¬Šé‡å°æ¯”"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

    # å°ç£é—œéµè©
    tw_words = taiwan_model.show_topic(topic_tw, topn=15)
    tw_keywords = [w for w, _ in tw_words]
    tw_weights = [p for _, p in tw_words]

    ax1.barh(range(len(tw_keywords)), tw_weights, color=COLORS['taiwan']['primary'], alpha=0.7)
    ax1.set_yticks(range(len(tw_keywords)))
    ax1.set_yticklabels(tw_keywords)
    ax1.invert_yaxis()
    ax1.set_xlabel('Weight', fontsize=11)
    ax1.set_title(f"ğŸ‡¹ğŸ‡¼ {TAIWAN_TOPICS[topic_tw]['label_zh']}\nTop 15 Keywords",
                  fontsize=12, fontweight='bold')
    ax1.grid(axis='x', alpha=0.3)

    # ç¾åœ‹é—œéµè©
    us_words = usa_model.show_topic(topic_us, topn=15)
    us_keywords = [w for w, _ in us_words]
    us_weights = [p for _, p in us_words]

    ax2.barh(range(len(us_keywords)), us_weights, color=COLORS['usa']['primary'], alpha=0.7)
    ax2.set_yticks(range(len(us_keywords)))
    ax2.set_yticklabels(us_keywords)
    ax2.invert_yaxis()
    ax2.set_xlabel('Weight', fontsize=11)
    ax2.set_title(f"ğŸ‡ºğŸ‡¸ {USA_TOPICS[topic_us]['label_zh']}\nTop 15 Keywords",
                  fontsize=12, fontweight='bold')
    ax2.grid(axis='x', alpha=0.3)

    plt.tight_layout()
    return fig

def plot_rating_comparison(usa_df):
    """ç¹ªè£½è©•åˆ†å°æ¯”ç®±å‹åœ–"""
    # æº–å‚™ç¾åœ‹è³‡æ–™
    usa_ratings = []
    usa_labels = []

    for topic_id in range(6):
        ratings = usa_df[usa_df['dominant_topic'] == topic_id]['è©•åˆ†'].values
        usa_ratings.append(ratings)
        usa_labels.append(f"T{topic_id}\n{USA_TOPICS[topic_id]['emoji']}")

    # ç¹ªåœ–
    fig, ax = plt.subplots(figsize=(12, 6))

    bp = ax.boxplot(usa_ratings, labels=usa_labels, patch_artist=True,
                    showmeans=True, meanline=True)

    # è¨­å®šé¡è‰²
    for patch in bp['boxes']:
        patch.set_facecolor(COLORS['usa']['light'])
        patch.set_edgecolor(COLORS['usa']['primary'])

    for median in bp['medians']:
        median.set_color(COLORS['usa']['dark'])
        median.set_linewidth(2)

    for mean in bp['means']:
        mean.set_color('red')
        mean.set_linewidth(2)

    ax.set_ylabel('Rating (1-5 stars)', fontsize=12)
    ax.set_xlabel('Topics', fontsize=12)
    ax.set_title('ğŸ‡ºğŸ‡¸ USA Topic Rating Distribution', fontsize=14, fontweight='bold')
    ax.grid(axis='y', alpha=0.3)
    ax.set_ylim([0, 5.5])

    plt.tight_layout()
    return fig

def plot_topic_proportion_comparison(usa_df):
    """ç¹ªè£½ä¸»é¡Œæ¯”ä¾‹å°æ¯”åœ–"""
    # ç¾åœ‹ä¸»é¡Œæ¯”ä¾‹
    usa_counts = usa_df['dominant_topic'].value_counts().sort_index()
    usa_proportions = (usa_counts / len(usa_df) * 100).values

    # å°ç£ä¸»é¡Œæ¯”ä¾‹ï¼ˆä¼°ç®—ï¼‰
    taiwan_proportions = np.array([24.9, 15.1, 17.3, 10.2, 9.6, 12.5, 10.3])

    fig, ax = plt.subplots(figsize=(12, 6))

    x = np.arange(max(7, 6))
    width = 0.35

    # ç¹ªè£½å°ç£
    tw_bars = ax.bar(x[:7] - width/2, taiwan_proportions, width,
                     label='ğŸ‡¹ğŸ‡¼ Taiwan (K=7)',
                     color=COLORS['taiwan']['primary'], alpha=0.7)

    # ç¹ªè£½ç¾åœ‹
    us_bars = ax.bar(x[:6] + width/2, usa_proportions, width,
                     label='ğŸ‡ºğŸ‡¸ USA (K=6)',
                     color=COLORS['usa']['primary'], alpha=0.7)

    ax.set_ylabel('Proportion (%)', fontsize=12)
    ax.set_xlabel('Topic ID', fontsize=12)
    ax.set_title('Topic Proportion Comparison', fontsize=14, fontweight='bold')
    ax.set_xticks(x[:7])
    ax.legend()
    ax.grid(axis='y', alpha=0.3)

    # æ·»åŠ æ•¸å€¼æ¨™ç±¤
    for bar in tw_bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.1f}%', ha='center', va='bottom', fontsize=9)

    for bar in us_bars:
        height = bar.get_height()
        if height > 0:
            ax.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.1f}%', ha='center', va='bottom', fontsize=9)

    plt.tight_layout()
    return fig

# ============================================
# ä¸»ç¨‹å¼
# ============================================

def main():
    # è¼‰å…¥è³‡æ–™
    taiwan_model, taiwan_data = load_taiwan_model()
    usa_model, usa_data = load_usa_model()
    usa_df = load_usa_reviews()

    # æ¨™é¡Œ
    st.title("ğŸŒ å°ç¾é†«é™¢è©•è«–è·¨æ–‡åŒ–æ¯”è¼ƒåˆ†æç³»çµ±")
    st.markdown("### Taiwan-USA Hospital Review Cross-Cultural Comparison")
    st.markdown("---")

    # å´é‚Šæ¬„
    with st.sidebar:
        st.markdown(SIDEBAR_INFO)

        st.markdown("---")
        st.markdown("### ğŸ“‘ é é¢å°èˆª")
        page = st.radio(
            "é¸æ“‡åˆ†æé é¢",
            ["ğŸ  è·¨æ–‡åŒ–æ¦‚è¦½", "ğŸ”— ä¸»é¡Œå°æ‡‰æ˜ å°„", "ğŸ” é—œéµè©æ¯”è¼ƒ", "ğŸ“Š è©•åˆ†èˆ‡æƒ…ç·’åˆ†æ"],
            label_visibility="collapsed"
        )

    # ============================================
    # é é¢ 1: è·¨æ–‡åŒ–æ¦‚è¦½
    # ============================================

    if page == "ğŸ  è·¨æ–‡åŒ–æ¦‚è¦½":
        st.header("ğŸ  è·¨æ–‡åŒ–æ¦‚è¦½ (Cross-Cultural Overview)")

        # è³‡æ–™é›†åŸºæœ¬è³‡è¨Š
        st.subheader("ğŸ“Š è³‡æ–™é›†åŸºæœ¬è³‡è¨Š")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric(
                label="ğŸ‡¹ğŸ‡¼ å°ç£è©•è«–æ•¸",
                value=f"{DATASET_INFO['taiwan']['reviews']:,}",
                delta=f"+{DATASET_INFO['taiwan']['reviews'] - DATASET_INFO['usa']['reviews']:,} vs USA"
            )
            st.metric(
                label="ğŸ‡¹ğŸ‡¼ å°ç£ä¸»é¡Œæ•¸",
                value=f"K = {DATASET_INFO['taiwan']['topics']}"
            )
            st.metric(
                label="ğŸ‡¹ğŸ‡¼ Coherence Score",
                value=f"{DATASET_INFO['taiwan']['coherence']:.4f}",
                delta=f"+{DATASET_INFO['taiwan']['coherence'] - DATASET_INFO['usa']['coherence']:.4f}"
            )

        with col2:
            st.metric(
                label="ğŸ‡ºğŸ‡¸ ç¾åœ‹è©•è«–æ•¸",
                value=f"{DATASET_INFO['usa']['reviews']:,}"
            )
            st.metric(
                label="ğŸ‡ºğŸ‡¸ ç¾åœ‹ä¸»é¡Œæ•¸",
                value=f"K = {DATASET_INFO['usa']['topics']}"
            )
            st.metric(
                label="ğŸ‡ºğŸ‡¸ Coherence Score",
                value=f"{DATASET_INFO['usa']['coherence']:.4f}"
            )

        with col3:
            st.metric(
                label="ç¸½è©•è«–æ•¸",
                value=f"{DATASET_INFO['taiwan']['reviews'] + DATASET_INFO['usa']['reviews']:,}"
            )
            st.metric(
                label="ä¸»é¡Œæ•¸å·®ç•°",
                value=f"{DATASET_INFO['taiwan']['topics'] - DATASET_INFO['usa']['topics']}"
            )
            st.metric(
                label="æ¨£æœ¬æ¯”ä¾‹",
                value=f"{DATASET_INFO['taiwan']['reviews'] / DATASET_INFO['usa']['reviews']:.2f}:1",
                delta="Taiwan : USA"
            )

        st.markdown("---")

        # æ¨¡å‹å“è³ªæ¯”è¼ƒ
        st.subheader("ğŸ¯ æ¨¡å‹å“è³ªæ¯”è¼ƒ")
        fig_quality = plot_model_quality_comparison()
        st.pyplot(fig_quality)

        st.info("""
        **è§£è®€**ï¼š
        - ğŸ‡¹ğŸ‡¼ å°ç£æ¨¡å‹çš„ Coherence è¼ƒé«˜ (0.4175 > 0.4029)ï¼Œè¡¨ç¤ºä¸»é¡Œå…§éƒ¨èªç¾©é—œè¯æ€§æ›´å¼·
        - ğŸ‡ºğŸ‡¸ ç¾åœ‹æ¨¡å‹çš„ Perplexity è¼ƒä½ï¼Œé æ¸¬èƒ½åŠ›ç•¥å„ª
        - å…©å€‹æ¨¡å‹å“è³ªéƒ½åœ¨å¯æ¥å—ç¯„åœå…§ (Coherence > 0.35)
        """)

        st.markdown("---")

        # è³‡æ–™é›†è¦æ¨¡æ¯”è¼ƒ
        st.subheader("ğŸ“ è³‡æ–™é›†è¦æ¨¡æ¯”è¼ƒ")
        col1, col2 = st.columns([1, 1])

        with col1:
            fig_size = plot_dataset_size_comparison()
            st.pyplot(fig_size)

        with col2:
            st.markdown("""
            ### è³‡æ–™é›†ç‰¹å¾µ

            #### ğŸ‡¹ğŸ‡¼ å°ç£
            - **è©•è«–æ•¸**ï¼š5,007 å‰‡
            - **é†«é™¢æ•¸**ï¼š26 å®¶é†«ç™‚ä¸­å¿ƒ
            - **èªè¨€**ï¼šç¹é«”ä¸­æ–‡
            - **ä¸»é¡Œæ¨¡å‹**ï¼šK=7 (7å€‹ä¸»é¡Œ)

            #### ğŸ‡ºğŸ‡¸ ç¾åœ‹
            - **è©•è«–æ•¸**ï¼š3,240 å‰‡
            - **èªè¨€**ï¼šEnglish
            - **ä¸»é¡Œæ¨¡å‹**ï¼šK=6 (6å€‹ä¸»é¡Œ)

            #### ğŸ“Š æ¯”è¼ƒ
            - å°ç£æ¨£æœ¬æ•¸å¤š **54%**
            - å°ç£ä¸»é¡Œæ•¸å¤š 1 å€‹
            - å…©åœ‹éƒ½ä½¿ç”¨ Gensim LDA æ–¹æ³•
            """)

        st.markdown("---")

        # æƒ…ç·’åˆ†ä½ˆæ¯”è¼ƒ
        st.subheader("ğŸ˜ŠğŸ˜ğŸ˜  æƒ…ç·’åˆ†ä½ˆæ¯”è¼ƒ")
        fig_sentiment = plot_sentiment_distribution(usa_df)
        st.pyplot(fig_sentiment)

        st.markdown("---")

        # æ–‡åŒ–å·®ç•°é‡é»
        st.subheader("ğŸ” æ–‡åŒ–å·®ç•°é‡é»")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("### ğŸ‡¹ğŸ‡¼ å°ç£ç¨ç‰¹ä¸»é¡Œ")
            for insight in CULTURAL_INSIGHTS['taiwan_unique']:
                with st.expander(f"{TAIWAN_TOPICS[insight['topic']]['emoji']} {insight['insight']} ({insight['percentage']}%)"):
                    st.markdown(f"**ä¸»é¡Œ**: {TAIWAN_TOPICS[insight['topic']]['label_zh']}")
                    st.markdown(f"**èªªæ˜**: {insight['description']}")
                    st.markdown(f"**æ¯”ä¾‹**: {insight['percentage']}%")

        with col2:
            st.markdown("### ğŸ‡ºğŸ‡¸ ç¾åœ‹ç¨ç‰¹ä¸»é¡Œ")
            for insight in CULTURAL_INSIGHTS['usa_unique']:
                with st.expander(f"{USA_TOPICS[insight['topic']]['emoji']} {insight['insight']} ({insight['percentage']}%)"):
                    st.markdown(f"**ä¸»é¡Œ**: {USA_TOPICS[insight['topic']]['label_zh']}")
                    st.markdown(f"**èªªæ˜**: {insight['description']}")
                    st.markdown(f"**æ¯”ä¾‹**: {insight['percentage']}%")

        st.markdown("### ğŸ¤ å…±åŒé—œæ³¨é»")
        for insight in CULTURAL_INSIGHTS['common']:
            taiwan_topic = TAIWAN_TOPICS[insight['taiwan_topic']]
            usa_topic = USA_TOPICS[insight['usa_topic']]
            st.success(f"""
            **{insight['insight']}**
            - ğŸ‡¹ğŸ‡¼ {taiwan_topic['emoji']} {taiwan_topic['label_zh']}
            - ğŸ‡ºğŸ‡¸ {usa_topic['emoji']} {usa_topic['label_zh']}
            - {insight['description']}
            """)

    # ============================================
    # é é¢ 2: ä¸»é¡Œå°æ‡‰æ˜ å°„
    # ============================================

    elif page == "ğŸ”— ä¸»é¡Œå°æ‡‰æ˜ å°„":
        st.header("ğŸ”— ä¸»é¡Œå°æ‡‰æ˜ å°„ (Topic Alignment Mapping)")

        # æ¡‘åŸºåœ–
        st.subheader("ğŸ“Š ä¸»é¡Œå°æ‡‰é—œä¿‚æ¡‘åŸºåœ–")
        st.markdown("é€£ç·šç²—ç´°ä»£è¡¨ä¸»é¡Œç›¸ä¼¼åº¦ï¼Œå¾å°ç£ä¸»é¡Œï¼ˆå·¦ï¼‰é€£åˆ°ç¾åœ‹ä¸»é¡Œï¼ˆå³ï¼‰")

        fig_sankey = plot_topic_mapping_sankey()
        st.plotly_chart(fig_sankey, use_container_width=True)

        st.markdown("---")

        # ä¸»é¡Œå°æ‡‰è©³ç´°è¡¨æ ¼
        st.subheader("ğŸ“‹ ä¸»é¡Œå°æ‡‰é—œä¿‚è©³ç´°èªªæ˜")

        for mapping in TOPIC_MAPPING:
            if mapping['taiwan_topic'] is not None and mapping['usa_topic'] is not None:
                taiwan_info = TAIWAN_TOPICS[mapping['taiwan_topic']]
                usa_info = USA_TOPICS[mapping['usa_topic']]
                similarity_stars = "â˜…" * mapping['similarity'] + "â˜†" * (5 - mapping['similarity'])

                with st.expander(f"{similarity_stars} {taiwan_info['label_zh']} â†”ï¸ {usa_info['label_zh']}"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown(f"### ğŸ‡¹ğŸ‡¼ {taiwan_info['emoji']} {taiwan_info['label_zh']}")
                        st.markdown(f"**English**: {taiwan_info['label_en']}")
                        st.markdown(f"**æƒ…ç·’**: {taiwan_info['sentiment']}")
                        st.markdown(f"**é—œéµè©**: {', '.join(taiwan_info['keywords'][:5])}")
                        st.markdown(f"**èªªæ˜**: {taiwan_info['description']}")
                    with col2:
                        st.markdown(f"### ğŸ‡ºğŸ‡¸ {usa_info['emoji']} {usa_info['label_zh']}")
                        st.markdown(f"**English**: {usa_info['label_en']}")
                        st.markdown(f"**æƒ…ç·’**: {usa_info['sentiment']}")
                        st.markdown(f"**Keywords**: {', '.join(usa_info['keywords'][:5])}")
                        st.markdown(f"**èªªæ˜**: {usa_info['description']}")

                    st.success(f"**ğŸ”— å…±åŒç‰¹å¾µ**: {mapping['common_features']}")

        # ç¨ç‰¹ä¸»é¡Œ
        st.markdown("---")
        st.subheader("ğŸ¯ æ–‡åŒ–ç¨ç‰¹ä¸»é¡Œ")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("### ğŸ‡¹ğŸ‡¼ å°ç£ç¨æœ‰")
            # Topic 2: æœå‹™æ…‹åº¦å•é¡Œ
            taiwan_unique = TAIWAN_TOPICS[2]
            st.warning(f"""
            **{taiwan_unique['emoji']} {taiwan_unique['label_zh']}**

            {taiwan_unique['description']}

            **é—œéµè©**: {', '.join(taiwan_unique['keywords'][:5])}

            **æ–‡åŒ–æ„ç¾©**: å°ç£ç—…æ‚£å°é†«è­·äººå“¡çš„æœå‹™æ…‹åº¦ç‰¹åˆ¥æ•æ„Ÿï¼Œå½¢æˆç¨ç«‹ä¸”æ¯”ä¾‹é¡¯è‘—çš„ä¸»é¡Œï¼ˆ17.3%ï¼‰
            """)

            # Topic 3: è¨­æ–½èˆ‡ä¾¿åˆ©æ€§
            taiwan_facility = TAIWAN_TOPICS[3]
            st.info(f"""
            **{taiwan_facility['emoji']} {taiwan_facility['label_zh']}**

            {taiwan_facility['description']}

            **é—œéµè©**: {', '.join(taiwan_facility['keywords'][:5])}

            **æ–‡åŒ–æ„ç¾©**: åœè»Šã€å‹•ç·šç­‰è¨­æ–½ä¾¿åˆ©æ€§åœ¨å°ç£é†«ç™‚é«”é©—ä¸­ä½”é‡è¦åœ°ä½
            """)

        with col2:
            st.markdown("### ğŸ‡ºğŸ‡¸ ç¾åœ‹ç¨æœ‰")
            # Topic 5: é ç´„èˆ‡å¸³å–®
            usa_unique = USA_TOPICS[5]
            st.warning(f"""
            **{usa_unique['emoji']} {usa_unique['label_zh']}**

            {usa_unique['description']}

            **Keywords**: {', '.join(usa_unique['keywords'][:5])}

            **Cultural Significance**: é†«ç™‚å¸³å–®å’Œä¿éšªå•é¡Œæ˜¯ç¾åœ‹é†«ç™‚ç³»çµ±çš„ç¨ç‰¹ç—›é»ï¼ˆ4.1%ï¼‰
            """)

            # Topic 2: ç–¼ç—›ç®¡ç†
            usa_pain = USA_TOPICS[2]
            st.info(f"""
            **{usa_pain['emoji']} {usa_pain['label_zh']}**

            {usa_pain['description']}

            **Keywords**: {', '.join(usa_pain['keywords'][:5])}

            **Cultural Significance**: Pain management æ˜¯ç¾åœ‹é†«ç™‚è©•è«–çš„é¡¯è‘—é—œæ³¨é»ï¼ˆ14.7%ï¼‰
            """)

    # ============================================
    # é é¢ 3: é—œéµè©æ·±åº¦æ¯”è¼ƒ
    # ============================================

    elif page == "ğŸ” é—œéµè©æ¯”è¼ƒ":
        st.header("ğŸ” é—œéµè©æ·±åº¦æ¯”è¼ƒ (Keyword Analysis)")

        st.markdown("é¸æ“‡å°æ‡‰çš„å°ç¾ä¸»é¡Œï¼ŒæŸ¥çœ‹é—œéµè©æ¬Šé‡å°æ¯”")

        # é¸æ“‡å™¨
        col1, col2 = st.columns(2)

        with col1:
            taiwan_topic_options = {f"Topic {i}: {TAIWAN_TOPICS[i]['emoji']} {TAIWAN_TOPICS[i]['label_zh']}": i
                                   for i in range(7)}
            selected_tw_label = st.selectbox("é¸æ“‡å°ç£ä¸»é¡Œ", list(taiwan_topic_options.keys()))
            selected_tw = taiwan_topic_options[selected_tw_label]

        with col2:
            usa_topic_options = {f"Topic {i}: {USA_TOPICS[i]['emoji']} {USA_TOPICS[i]['label_zh']}": i
                                for i in range(6)}
            selected_us_label = st.selectbox("é¸æ“‡ç¾åœ‹ä¸»é¡Œ", list(usa_topic_options.keys()))
            selected_us = usa_topic_options[selected_us_label]

        st.markdown("---")

        # é¡¯ç¤ºé—œéµè©å°æ¯”
        fig_keywords = plot_keyword_comparison(taiwan_model, usa_model, selected_tw, selected_us)
        st.pyplot(fig_keywords)

        st.markdown("---")

        # é¡¯ç¤ºå®Œæ•´é—œéµè©åˆ—è¡¨
        st.subheader("ğŸ“ å®Œæ•´é—œéµè©åˆ—è¡¨ï¼ˆTop 30ï¼‰")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown(f"### ğŸ‡¹ğŸ‡¼ {TAIWAN_TOPICS[selected_tw]['label_zh']}")
            tw_words = taiwan_model.show_topic(selected_tw, topn=30)
            tw_df = pd.DataFrame(tw_words, columns=['é—œéµè©', 'æ¬Šé‡'])
            tw_df['æ¬Šé‡'] = tw_df['æ¬Šé‡'].round(4)
            tw_df.index = tw_df.index + 1
            st.dataframe(tw_df, use_container_width=True, height=600)

        with col2:
            st.markdown(f"### ğŸ‡ºğŸ‡¸ {USA_TOPICS[selected_us]['label_zh']}")
            us_words = usa_model.show_topic(selected_us, topn=30)
            us_df = pd.DataFrame(us_words, columns=['Keyword', 'Weight'])
            us_df['Weight'] = us_df['Weight'].round(4)
            us_df.index = us_df.index + 1
            st.dataframe(us_df, use_container_width=True, height=600)

        st.markdown("---")

        # é—œéµè©åˆ†æ
        st.subheader("ğŸ”¬ é—œéµè©ç‰¹å¾µåˆ†æ")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### ğŸ‡¹ğŸ‡¼ å°ç£ä¸»é¡Œç‰¹å¾µ")
            tw_info = TAIWAN_TOPICS[selected_tw]
            st.markdown(f"**ä¸»é¡Œåç¨±**: {tw_info['emoji']} {tw_info['label_zh']}")
            st.markdown(f"**è‹±æ–‡åç¨±**: {tw_info['label_en']}")
            st.markdown(f"**æƒ…ç·’å‚¾å‘**: {tw_info['sentiment']}")
            st.markdown(f"**ä¸»é¡Œèªªæ˜**: {tw_info['description']}")

        with col2:
            st.markdown("#### ğŸ‡ºğŸ‡¸ ç¾åœ‹ä¸»é¡Œç‰¹å¾µ")
            us_info = USA_TOPICS[selected_us]
            st.markdown(f"**ä¸»é¡Œåç¨±**: {us_info['emoji']} {us_info['label_zh']}")
            st.markdown(f"**English Name**: {us_info['label_en']}")
            st.markdown(f"**Sentiment**: {us_info['sentiment']}")
            st.markdown(f"**Description**: {us_info['description']}")

    # ============================================
    # é é¢ 4: è©•åˆ†èˆ‡æƒ…ç·’åˆ†æ
    # ============================================

    elif page == "ğŸ“Š è©•åˆ†èˆ‡æƒ…ç·’åˆ†æ":
        st.header("ğŸ“Š è©•åˆ†èˆ‡æƒ…ç·’å°æ¯”åˆ†æ (Rating & Sentiment Analysis)")

        # ä¸»é¡Œæ¯”ä¾‹å°æ¯”
        st.subheader("ğŸ“ˆ ä¸»é¡Œæ¯”ä¾‹å°æ¯”")
        fig_proportion = plot_topic_proportion_comparison(usa_df)
        st.pyplot(fig_proportion)

        st.info("""
        **è§£è®€**ï¼š
        - ğŸ‡¹ğŸ‡¼ å°ç£æœ€å¤§ä¸»é¡Œæ˜¯ã€Œé†«ç™‚å°ˆæ¥­èªå¯ã€ï¼ˆ24.9%ï¼‰ï¼Œåæ˜ æ­£é¢è©•åƒ¹
        - ğŸ‡ºğŸ‡¸ ç¾åœ‹æœ€å¤§ä¸»é¡Œæ˜¯ã€Œæ•´é«”æ­£é¢è©•åƒ¹ã€ï¼ˆ34.8%ï¼‰ï¼Œæ¯”ä¾‹æ›´é«˜
        - ğŸ‡¹ğŸ‡¼ å°ç£ã€Œæœå‹™æ…‹åº¦å•é¡Œã€ä¸»é¡Œé¡¯è‘—ï¼ˆ17.3%ï¼‰ï¼Œæ˜¯æ–‡åŒ–ç‰¹è‰²
        - ğŸ‡ºğŸ‡¸ ç¾åœ‹ã€Œæ€¥è¨ºç­‰å€™æ™‚é–“ã€å•é¡Œçªå‡ºï¼ˆ16.4%ï¼‰
        """)

        st.markdown("---")

        # ç¾åœ‹è©•åˆ†åˆ†ä½ˆç®±å‹åœ–
        st.subheader("ğŸ“Š ç¾åœ‹å„ä¸»é¡Œè©•åˆ†åˆ†ä½ˆ")
        fig_ratings = plot_rating_comparison(usa_df)
        st.pyplot(fig_ratings)

        # ç¾åœ‹çµ±è¨ˆè¡¨
        st.subheader("ğŸ“‹ ç¾åœ‹å„ä¸»é¡Œçµ±è¨ˆæ•¸æ“š")
        usa_stats = get_topic_statistics(usa_df)
        usa_stats_display = usa_stats.copy()
        usa_stats_display.index = [f"Topic {i}: {USA_TOPICS[i]['emoji']} {USA_TOPICS[i]['label_zh']}"
                                   for i in range(6)]
        st.dataframe(usa_stats_display, use_container_width=True)

        st.markdown("---")

        # è©³ç´°è©•åˆ†åˆ†æ
        st.subheader("ğŸ” å„ä¸»é¡Œè©³ç´°è©•åˆ†åˆ†æ")

        for topic_id in range(6):
            topic_info = USA_TOPICS[topic_id]
            topic_reviews = usa_df[usa_df['dominant_topic'] == topic_id]

            with st.expander(f"{topic_info['emoji']} Topic {topic_id}: {topic_info['label_zh']} ({len(topic_reviews)} reviews)"):
                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    st.metric("å¹³å‡è©•åˆ†", f"{topic_reviews['è©•åˆ†'].mean():.2f} â˜…")
                with col2:
                    st.metric("ä¸­ä½æ•¸", f"{topic_reviews['è©•åˆ†'].median():.1f} â˜…")
                with col3:
                    st.metric("æ¨™æº–å·®", f"{topic_reviews['è©•åˆ†'].std():.2f}")
                with col4:
                    st.metric("è©•è«–æ•¸", f"{len(topic_reviews):,}")

                # è©•åˆ†åˆ†ä½ˆ
                rating_counts = topic_reviews['è©•åˆ†'].value_counts().sort_index()
                fig, ax = plt.subplots(figsize=(8, 3))
                ax.bar(rating_counts.index, rating_counts.values,
                      color=COLORS['usa']['primary'], alpha=0.7)
                ax.set_xlabel('Rating (stars)')
                ax.set_ylabel('Count')
                ax.set_title(f'Rating Distribution for Topic {topic_id}')
                ax.grid(axis='y', alpha=0.3)
                st.pyplot(fig)

        st.markdown("---")

        # è·¨æ–‡åŒ–æ¯”è¼ƒé‡é»
        st.subheader("ğŸŒ è·¨æ–‡åŒ–è©•åˆ†æ¯”è¼ƒé‡é»")

        col1, col2 = st.columns(2)

        with col1:
            st.success("""
            ### âœ… æ­£é¢ä¸»é¡Œ
            **ğŸ‡¹ğŸ‡¼ å°ç£**:
            - Topic 0: é†«ç™‚å°ˆæ¥­èªå¯ (24.9%, 4.56â˜…)
            - Topic 4: æ‰‹è¡“æ²»ç™‚æˆåŠŸ (9.6%, 4.38â˜…)

            **ğŸ‡ºğŸ‡¸ ç¾åœ‹**:
            - Topic 4: æ•´é«”æ­£é¢è©•åƒ¹ (9.5%, 3.96â˜…)

            **å·®ç•°**: å°ç£æ­£é¢è©•åƒ¹çš„è©•åˆ†æ›´é«˜
            """)

        with col2:
            st.error("""
            ### âŒ è² é¢ä¸»é¡Œ
            **ğŸ‡¹ğŸ‡¼ å°ç£**:
            - Topic 2: æœå‹™æ…‹åº¦å•é¡Œ (17.3%, 1.98â˜…)
            - Topic 6: æ€¥è¨ºèˆ‡æºé€š (10.3%, 2.34â˜…)

            **ğŸ‡ºğŸ‡¸ ç¾åœ‹**:
            - Topic 5: é ç´„èˆ‡å¸³å–® (4.1%, 2.92â˜…)
            - Topic 3: è­·ç†ç…§è­·å“è³ª (14.7%, 3.08â˜…)

            **å·®ç•°**: å°ç£è² é¢è©•åˆ†æ›´æ¥µç«¯
            """)

if __name__ == "__main__":
    main()
