#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°ç£é†«é™¢è©•è«– K=7 åƒæ•¸å„ªåŒ–æ¸¬è©¦
ç›®æ¨™ï¼šæ‰¾åˆ°K=7çš„æœ€ä½³åƒæ•¸é…ç½®ï¼Œæå‡coherence score
"""

import pickle
import pandas as pd
import numpy as np
from gensim.models import LdaModel
from gensim.models.coherencemodel import CoherenceModel
from gensim import corpora
import warnings
import time
from datetime import datetime
warnings.filterwarnings('ignore')

print("\n" + "="*80)
print("å°ç£é†«é™¢è©•è«– K=7 LDA åƒæ•¸å„ªåŒ–æ¸¬è©¦")
print("Taiwan Hospital Reviews K=7 LDA Parameter Optimization")
print("="*80)

# ============================================================================
# 1. è¼‰å…¥è³‡æ–™
# ============================================================================

print("\nã€æ­¥é©Ÿ1ã€‘è¼‰å…¥å‰è™•ç†è³‡æ–™...")
df = pd.read_csv('../../data/processed/taiwan/combined_reviews.csv')

# å°‡tokens_strè½‰æ›å›list
texts = [text.split() for text in df['tokens_str']]

print(f"âœ“ å·²è¼‰å…¥ {len(texts)} ç­†è©•è«–")
print(f"  å¹³å‡è©æ•¸: {np.mean([len(t) for t in texts]):.2f}")

# ============================================================================
# 2. å»ºç«‹å­—å…¸å’Œèªæ–™åº«
# ============================================================================

print("\nã€æ­¥é©Ÿ2ã€‘å»ºç«‹å­—å…¸å’Œèªæ–™åº«...")
dictionary = corpora.Dictionary(texts)
original_size = len(dictionary)

# éæ¿¾æ¥µç«¯è©å½™
dictionary.filter_extremes(
    no_below=3,
    no_above=0.5,
    keep_n=None
)
dictionary.compactify()

print(f"  åŸå§‹è©å½™æ•¸: {original_size}")
print(f"  éæ¿¾å¾Œè©å½™æ•¸: {len(dictionary)}")

# å»ºç«‹èªæ–™åº«
corpus = [dictionary.doc2bow(text) for text in texts]
print(f"âœ“ èªæ–™åº«å»ºç«‹å®Œæˆï¼Œå…± {len(corpus)} ç­†æ–‡æª”")

# ============================================================================
# 3. å®šç¾©åƒæ•¸å„ªåŒ–æ¸¬è©¦
# ============================================================================

print("\nã€æ­¥é©Ÿ3ã€‘å®šç¾©åƒæ•¸æ¸¬è©¦ç©ºé–“...")

# åƒæ•¸æ¸¬è©¦çµ„åˆ
param_grid = {
    'test_name': [],
    'alpha': [],
    'eta': [],
    'iterations': [],
    'passes': [],
    'description': []
}

# åŸºæº–æ¨¡å‹ï¼ˆç•¶å‰åƒæ•¸ï¼‰
param_grid['test_name'].append('Baseline')
param_grid['alpha'].append('symmetric')
param_grid['eta'].append('auto')
param_grid['iterations'].append(100)
param_grid['passes'].append(10)
param_grid['description'].append('ç•¶å‰ä½¿ç”¨çš„åƒæ•¸ï¼ˆåŸºæº–ï¼‰')

# Test 1: Asymmetric alphaï¼ˆå…è¨±ä¸»é¡Œé‡è¦æ€§ä¸åŒï¼‰
param_grid['test_name'].append('Test-1-Asymmetric')
param_grid['alpha'].append('asymmetric')
param_grid['eta'].append('auto')
param_grid['iterations'].append(100)
param_grid['passes'].append(10)
param_grid['description'].append('æ”¹ç”¨asymmetric alpha')

# Test 2: é™ä½etaï¼ˆå¢åŠ è©å½™ç‰¹ç•°æ€§ï¼‰
param_grid['test_name'].append('Test-2-LowEta')
param_grid['alpha'].append('symmetric')
param_grid['eta'].append(0.01)
param_grid['iterations'].append(100)
param_grid['passes'].append(10)
param_grid['description'].append('é™ä½etaè‡³0.01')

# Test 3: å¢åŠ è¨“ç·´æ¬¡æ•¸
param_grid['test_name'].append('Test-3-MoreTraining')
param_grid['alpha'].append('symmetric')
param_grid['eta'].append('auto')
param_grid['iterations'].append(200)
param_grid['passes'].append(20)
param_grid['description'].append('å¢åŠ iterationså’Œpasses')

# Test 4: Asymmetric + Low eta
param_grid['test_name'].append('Test-4-Combo1')
param_grid['alpha'].append('asymmetric')
param_grid['eta'].append(0.01)
param_grid['iterations'].append(100)
param_grid['passes'].append(10)
param_grid['description'].append('Asymmetric + ä½eta')

# Test 5: Asymmetric + More training
param_grid['test_name'].append('Test-5-Combo2')
param_grid['alpha'].append('asymmetric')
param_grid['eta'].append('auto')
param_grid['iterations'].append(200)
param_grid['passes'].append(20)
param_grid['description'].append('Asymmetric + å¢åŠ è¨“ç·´')

# Test 6: Low eta + More training
param_grid['test_name'].append('Test-6-Combo3')
param_grid['alpha'].append('symmetric')
param_grid['eta'].append(0.01)
param_grid['iterations'].append(200)
param_grid['passes'].append(20)
param_grid['description'].append('ä½eta + å¢åŠ è¨“ç·´')

# Test 7: å…¨éƒ¨å„ªåŒ–ï¼ˆæœ€æ¿€é€²ï¼‰
param_grid['test_name'].append('Test-7-AllOptimized')
param_grid['alpha'].append('asymmetric')
param_grid['eta'].append(0.01)
param_grid['iterations'].append(200)
param_grid['passes'].append(20)
param_grid['description'].append('å…¨éƒ¨åƒæ•¸å„ªåŒ–')

# Test 8: æ¥µä½etaï¼ˆæ›´é«˜ç‰¹ç•°æ€§ï¼‰
param_grid['test_name'].append('Test-8-VeryLowEta')
param_grid['alpha'].append('asymmetric')
param_grid['eta'].append(0.001)
param_grid['iterations'].append(200)
param_grid['passes'].append(20)
param_grid['description'].append('æ¥µä½eta (0.001)')

# Test 9: æ›´å¤šè¨“ç·´è¼ªæ¬¡
param_grid['test_name'].append('Test-9-MaxTraining')
param_grid['alpha'].append('asymmetric')
param_grid['eta'].append(0.01)
param_grid['iterations'].append(300)
param_grid['passes'].append(30)
param_grid['description'].append('æœ€å¤§è¨“ç·´æ¬¡æ•¸')

n_tests = len(param_grid['test_name'])
print(f"âœ“ å…±è¨­å®š {n_tests} çµ„åƒæ•¸æ¸¬è©¦")

# ============================================================================
# 4. åŸ·è¡Œåƒæ•¸å„ªåŒ–æ¸¬è©¦
# ============================================================================

print("\nã€æ­¥é©Ÿ4ã€‘é–‹å§‹åƒæ•¸å„ªåŒ–æ¸¬è©¦...")
print("-" * 80)

results = []

for i in range(n_tests):
    test_name = param_grid['test_name'][i]
    alpha = param_grid['alpha'][i]
    eta = param_grid['eta'][i]
    iterations = param_grid['iterations'][i]
    passes = param_grid['passes'][i]
    description = param_grid['description'][i]

    print(f"\nâ–¶ {test_name}: {description}")
    print(f"  åƒæ•¸: alpha={alpha}, eta={eta}, iterations={iterations}, passes={passes}")

    start_time = time.time()

    # è¨“ç·´æ¨¡å‹
    try:
        lda_model = LdaModel(
            corpus=corpus,
            id2word=dictionary,
            num_topics=7,
            alpha=alpha,
            eta=eta,
            iterations=iterations,
            passes=passes,
            random_state=42,
            eval_every=None,
            chunksize=2000
        )

        # è¨ˆç®—coherence
        coherence_model = CoherenceModel(
            model=lda_model,
            texts=texts,
            dictionary=dictionary,
            coherence='c_v'
        )
        coherence_score = coherence_model.get_coherence()

        # è¨ˆç®—perplexity
        perplexity_score = lda_model.log_perplexity(corpus)

        training_time = time.time() - start_time

        print(f"  âœ“ Coherence: {coherence_score:.4f}")
        print(f"  âœ“ Perplexity: {perplexity_score:.4f}")
        print(f"  âœ“ è¨“ç·´æ™‚é–“: {training_time:.1f}ç§’")

        # é¡¯ç¤ºä¸»é¡Œé—œéµè©
        print(f"  ä¸»é¡Œé—œéµè©é è¦½:")
        for idx in range(7):
            topic_words = lda_model.show_topic(idx, topn=5)
            keywords = ', '.join([word for word, prob in topic_words])
            print(f"    ä¸»é¡Œ{idx+1}: {keywords}")

        # è¨˜éŒ„çµæœ
        results.append({
            'test_name': test_name,
            'description': description,
            'alpha': str(alpha),
            'eta': str(eta),
            'iterations': iterations,
            'passes': passes,
            'coherence': coherence_score,
            'perplexity': perplexity_score,
            'training_time_sec': training_time,
            'status': 'Success'
        })

        # ä¿å­˜æ¨¡å‹
        model_filename = f'../../results/taiwan_lda_k7/optimized_{test_name.lower()}_model.pkl'
        lda_model.save(model_filename)
        print(f"  âœ“ æ¨¡å‹å·²ä¿å­˜: {model_filename}")

    except Exception as e:
        print(f"  âœ— éŒ¯èª¤: {str(e)}")
        results.append({
            'test_name': test_name,
            'description': description,
            'alpha': str(alpha),
            'eta': str(eta),
            'iterations': iterations,
            'passes': passes,
            'coherence': None,
            'perplexity': None,
            'training_time_sec': None,
            'status': f'Failed: {str(e)}'
        })

# ============================================================================
# 5. çµæœåŒ¯ç¸½èˆ‡åˆ†æ
# ============================================================================

print("\n" + "="*80)
print("ã€æ­¥é©Ÿ5ã€‘åƒæ•¸å„ªåŒ–çµæœåŒ¯ç¸½")
print("="*80)

results_df = pd.DataFrame(results)

# æŒ‰coherenceæ’åº
results_df_sorted = results_df[results_df['status'] == 'Success'].sort_values(
    'coherence', ascending=False
)

print("\nğŸ“Š æ¸¬è©¦çµæœæ’åï¼ˆä¾Coherence Scoreï¼‰:")
print("-" * 80)

for idx, row in results_df_sorted.iterrows():
    rank = list(results_df_sorted.index).index(idx) + 1
    improvement = ((row['coherence'] - results_df_sorted.iloc[-1]['coherence']) /
                   results_df_sorted.iloc[-1]['coherence'] * 100)

    print(f"\nã€æ’å #{rank}ã€‘{row['test_name']}")
    print(f"  æè¿°: {row['description']}")
    print(f"  Coherence: {row['coherence']:.4f} " +
          f"(ç›¸å°åŸºæº– {improvement:+.2f}%)" if rank > 1 else "  Coherence: {:.4f} (åŸºæº–)".format(row['coherence']))
    print(f"  Perplexity: {row['perplexity']:.4f}")
    print(f"  è¨“ç·´æ™‚é–“: {row['training_time_sec']:.1f}ç§’")
    print(f"  åƒæ•¸: alpha={row['alpha']}, eta={row['eta']}, " +
          f"iter={row['iterations']}, passes={row['passes']}")

# ============================================================================
# 6. èˆ‡K=5æ¯”è¼ƒ
# ============================================================================

print("\n" + "="*80)
print("ã€æ­¥é©Ÿ6ã€‘èˆ‡K=5æœ€å„ªæ¨¡å‹æ¯”è¼ƒ")
print("="*80)

k5_coherence = 0.4326  # å¾ç ”ç©¶æ–¹æ³•è«–è¨˜éŒ„ä¸­ç²å¾—
best_k7_coherence = results_df_sorted.iloc[0]['coherence']
gap = k5_coherence - best_k7_coherence
gap_pct = (gap / k5_coherence) * 100

print(f"\nğŸ“ˆ Coherence Score æ¯”è¼ƒ:")
print(f"  K=5 (æœ€å„ª): {k5_coherence:.4f}")
print(f"  K=7 (åŸºæº–): {results_df[results_df['test_name']=='Baseline']['coherence'].values[0]:.4f}")
print(f"  K=7 (å„ªåŒ–å¾Œæœ€ä½³): {best_k7_coherence:.4f}")
print(f"\n  å·®è·:")
print(f"    K=7æœ€ä½³ vs K=5: {gap:.4f} ({gap_pct:.2f}%)")
print(f"    å„ªåŒ–æ”¹å–„å¹…åº¦: {(best_k7_coherence - results_df[results_df['test_name']=='Baseline']['coherence'].values[0]):.4f}")

if gap_pct < 3:
    print("\nâœ… å„ªåŒ–å¾Œçš„K=7èˆ‡K=5å·®è· < 3%ï¼Œçµ±è¨ˆä¸Šå¯æ¥å—ï¼")
    print("   å¯ä»¥è«–è­‰ï¼šK=7æä¾›æ›´å®Œæ•´çš„æ§‹é¢ï¼ˆç’°å¢ƒè¨­æ–½ï¼‰ï¼Œå¾®å°çš„coherenceå·®ç•°å€¼å¾—æ¬Šè¡¡")
elif gap_pct < 5:
    print("\nâš ï¸ å„ªåŒ–å¾Œçš„K=7èˆ‡K=5å·®è· < 5%ï¼Œéœ€è¦å¼·èª¿K=7çš„é¡å¤–æ§‹é¢åƒ¹å€¼")
else:
    print("\nâš ï¸ å„ªåŒ–å¾Œçš„K=7èˆ‡K=5ä»æœ‰è¼ƒå¤§å·®è·ï¼Œéœ€è¦è©³ç´°è«–è­‰é¸æ“‡K=7çš„ç†ç”±")

# ============================================================================
# 7. ä¿å­˜çµæœ
# ============================================================================

print("\nã€æ­¥é©Ÿ7ã€‘ä¿å­˜å„ªåŒ–çµæœ...")

# ä¿å­˜è©³ç´°çµæœ
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
results_filename = f'../../results/taiwan_lda_k7/param_optimization_results_{timestamp}.csv'
results_df.to_csv(results_filename, index=False, encoding='utf-8-sig')
print(f"âœ“ è©³ç´°çµæœå·²ä¿å­˜: {results_filename}")

# ä¿å­˜æ‘˜è¦å ±å‘Š
report_filename = f'../../results/taiwan_lda_k7/param_optimization_report_{timestamp}.txt'
with open(report_filename, 'w', encoding='utf-8') as f:
    f.write("="*80 + "\n")
    f.write("å°ç£é†«é™¢è©•è«– K=7 åƒæ•¸å„ªåŒ–æ¸¬è©¦å ±å‘Š\n")
    f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    f.write("="*80 + "\n\n")

    f.write("ã€æ¸¬è©¦ç›®çš„ã€‘\n")
    f.write("æ‰¾åˆ°K=7çš„æœ€ä½³åƒæ•¸é…ç½®ï¼Œç¸®å°èˆ‡K=5çš„coherenceå·®è·\n\n")

    f.write("ã€æ¸¬è©¦çµæœæ‘˜è¦ã€‘\n")
    f.write(f"å…±æ¸¬è©¦ {len(results_df[results_df['status']=='Success'])} çµ„åƒæ•¸é…ç½®\n\n")

    f.write("ã€æœ€ä½³é…ç½®ã€‘\n")
    best_row = results_df_sorted.iloc[0]
    f.write(f"æ¸¬è©¦åç¨±: {best_row['test_name']}\n")
    f.write(f"æè¿°: {best_row['description']}\n")
    f.write(f"Coherence: {best_row['coherence']:.4f}\n")
    f.write(f"Perplexity: {best_row['perplexity']:.4f}\n")
    f.write(f"åƒæ•¸:\n")
    f.write(f"  - alpha: {best_row['alpha']}\n")
    f.write(f"  - eta: {best_row['eta']}\n")
    f.write(f"  - iterations: {best_row['iterations']}\n")
    f.write(f"  - passes: {best_row['passes']}\n")
    f.write(f"è¨“ç·´æ™‚é–“: {best_row['training_time_sec']:.1f}ç§’\n\n")

    f.write("ã€èˆ‡K=5æ¯”è¼ƒã€‘\n")
    f.write(f"K=5æœ€å„ªcoherence: {k5_coherence:.4f}\n")
    f.write(f"K=7å„ªåŒ–å¾Œcoherence: {best_k7_coherence:.4f}\n")
    f.write(f"å·®è·: {gap:.4f} ({gap_pct:.2f}%)\n\n")

    f.write("ã€å®Œæ•´æ’åã€‘\n")
    for idx, row in results_df_sorted.iterrows():
        rank = list(results_df_sorted.index).index(idx) + 1
        f.write(f"\næ’å #{rank}: {row['test_name']}\n")
        f.write(f"  Coherence: {row['coherence']:.4f}\n")
        f.write(f"  æè¿°: {row['description']}\n")

print(f"âœ“ æ‘˜è¦å ±å‘Šå·²ä¿å­˜: {report_filename}")

print("\n" + "="*80)
print("âœ… åƒæ•¸å„ªåŒ–æ¸¬è©¦å®Œæˆï¼")
print("="*80)
print(f"\nğŸ† æœ€ä½³é…ç½®: {results_df_sorted.iloc[0]['test_name']}")
print(f"   Coherence: {results_df_sorted.iloc[0]['coherence']:.4f}")
print(f"   æ”¹å–„å¹…åº¦: {(best_k7_coherence - results_df[results_df['test_name']=='Baseline']['coherence'].values[0])*100:.2f}%")
print("\nğŸ“ ç”Ÿæˆçš„æª”æ¡ˆ:")
print(f"   - è©³ç´°çµæœ: {results_filename}")
print(f"   - æ‘˜è¦å ±å‘Š: {report_filename}")
print(f"   - å„ªåŒ–æ¨¡å‹: results/taiwan_lda_k7/optimized_*_model.pkl")
