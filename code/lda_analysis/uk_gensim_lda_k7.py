#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‹±åœ‹é†«é™¢è©•è«– Gensim LDA K=7 åˆ†æ
åƒè€ƒç¾åœ‹é†«é™¢çš„åˆ†ææ–¹æ³•ï¼Œä½¿ç”¨ç›¸åŒçš„ LDA åƒæ•¸
"""

import pickle
import pandas as pd
import numpy as np
from gensim.models import LdaModel
from gensim.models.coherencemodel import CoherenceModel
from gensim import corpora
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# è‹±æ–‡æ–‡æœ¬è™•ç†
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer

# ä¸‹è¼‰å¿…è¦çš„ NLTK è³‡æºï¼ˆå¦‚æœå°šæœªä¸‹è¼‰ï¼‰
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt', quiet=True)

try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords', quiet=True)

try:
    nltk.data.find('corpora/wordnet')
except LookupError:
    nltk.download('wordnet', quiet=True)

print("="*80)
print("UK Hospital Reviews - Gensim LDA K=7 Analysis")
print("è‹±åœ‹é†«é™¢è©•è«– - Gensim LDA K=7 åˆ†æ")
print("="*80)

# æ–‡æœ¬å‰è™•ç†å‡½æ•¸
def preprocess_english_text(text):
    """æ¸…ç†è‹±æ–‡æ–‡æœ¬"""
    text = str(text).lower()
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = re.sub(r'\S+@\S+', '', text)
    text = re.sub(r'[^a-zA-Z\s]', ' ', text)
    text = ' '.join(text.split())
    return text

def tokenize_and_lemmatize(text, stop_words):
    """Tokenization + Lemmatization"""
    lemmatizer = WordNetLemmatizer()
    tokens = word_tokenize(text)
    tokens = [lemmatizer.lemmatize(token) for token in tokens
              if token not in stop_words and len(token) > 2]
    return tokens

# è¼‰å…¥è³‡æ–™
print("\nğŸ“‚ Loading data...")
data_file = Path("data/processed/hospitals/uk/uk_hospitals_cleaned_recent_1year.csv")
df = pd.read_csv(data_file, encoding='utf-8-sig')
print(f"âœ“ Loaded {len(df):,} reviews from {df['hospital_name'].nunique()} hospitals")

# åŸºæœ¬çµ±è¨ˆ
print(f"\n{'='*80}")
print("DATA STATISTICS | è³‡æ–™çµ±è¨ˆ")
print(f"{'='*80}")
print(f"Total reviews: {len(df):,}")
print(f"Hospitals: {df['hospital_name'].nunique()}")
print(f"Average rating: {df['è©•åˆ†'].mean():.2f} stars")
print(f"Date range: Recent 1 year")

print(f"\nRating distribution:")
rating_dist = df['è©•åˆ†'].value_counts().sort_index()
for rating, count in rating_dist.items():
    percentage = count / len(df) * 100
    print(f"  {int(rating)} star: {count:>5,} ({percentage:>5.1f}%)")

# æ–‡æœ¬å‰è™•ç†
print(f"\n{'='*80}")
print("TEXT PREPROCESSING | æ–‡æœ¬å‰è™•ç†")
print(f"{'='*80}")

# è¨­å®šåœç”¨è©
stop_words = set(stopwords.words('english'))

# è‹±åœ‹é†«é™¢ç‰¹å®šåœç”¨è©
custom_stop_words = {
    # ä¸€èˆ¬åœç”¨è©
    'hospital', 'doctor', 'went', 'like', 'would', 'one', 'get', 'go',
    'nhs', 'said', 'told', 'came', 'made', 'asked', 'took', 'could',

    # é†«ç™‚ç›¸é—œä½†å¤ªå¸¸è¦‹
    'appointment', 'patient', 'staff', 'ward', 'treatment', 'care',
    'visit', 'visited', 'time', 'day', 'week', 'month', 'year',

    # è©•è«–å¸¸è¦‹è©
    'really', 'very', 'much', 'also', 'even', 'still', 'back', 'way',
    'thing', 'lot', 'bit', 'quite', 'rather', 'well', 'good', 'bad'
}
stop_words.update(custom_stop_words)

print(f"Stop words: {len(stop_words)} words")

# æ¸…ç†å’Œ tokenize
print("\nProcessing text...")
df['cleaned_text'] = df['è©•è«–å…§å®¹'].apply(preprocess_english_text)
df['tokens'] = df['cleaned_text'].apply(lambda x: tokenize_and_lemmatize(x, stop_words))
df = df[df['tokens'].str.len() > 0].copy()

texts = df['tokens'].tolist()
print(f"âœ“ Valid reviews after preprocessing: {len(df):,}")

# å»ºç«‹å­—å…¸å’Œèªæ–™åº«
print(f"\n{'='*80}")
print("BUILDING DICTIONARY & CORPUS | å»ºç«‹å­—å…¸å’Œèªæ–™åº«")
print(f"{'='*80}")

dictionary = corpora.Dictionary(texts)
original_size = len(dictionary)

# éæ¿¾æ¥µç«¯è©å½™
dictionary.filter_extremes(no_below=3, no_above=0.5, keep_n=None)
dictionary.compactify()

print(f"Original vocabulary size: {original_size:,}")
print(f"Filtered vocabulary size: {len(dictionary):,}")
print(f"Removed: {original_size - len(dictionary):,} words")

corpus = [dictionary.doc2bow(text) for text in texts]
print(f"âœ“ Corpus created: {len(corpus):,} documents")

# è¨“ç·´ K=7 çš„ LDA æ¨¡å‹
print(f"\n{'='*80}")
print("TRAINING LDA MODEL (K=7) | è¨“ç·´ LDA æ¨¡å‹ (K=7)")
print(f"{'='*80}")

print("\nModel parameters:")
print("  - Topics (K): 7")
print("  - Alpha: symmetric")
print("  - Eta: auto")
print("  - Iterations: 100")
print("  - Passes: 10")
print("  - Random state: 42")

lda_model = LdaModel(
    corpus=corpus,
    id2word=dictionary,
    num_topics=7,
    alpha='symmetric',
    eta='auto',
    iterations=100,
    passes=10,
    random_state=42
)

print("\nâœ“ Model training complete!")

# è¨ˆç®—æ¨¡å‹å“è³ªæŒ‡æ¨™
print(f"\n{'='*80}")
print("CALCULATING MODEL QUALITY METRICS | è¨ˆç®—æ¨¡å‹å“è³ªæŒ‡æ¨™")
print(f"{'='*80}")

# Coherence Score
coherence_model = CoherenceModel(
    model=lda_model,
    texts=texts,
    dictionary=dictionary,
    coherence='c_v',
    processes=1
)
coherence_score = coherence_model.get_coherence()

# Perplexity
perplexity_score = lda_model.log_perplexity(corpus)

print(f"\nCoherence Score: {coherence_score:.4f}")
print(f"Perplexity: {perplexity_score:.4f}")

# é¡¯ç¤ºä¸»é¡Œé—œéµè©
print(f"\n{'='*80}")
print("TOPIC KEYWORDS | ä¸»é¡Œé—œéµè©")
print(f"{'='*80}")

topics_keywords = []
for idx in range(7):
    topic_words = lda_model.show_topic(idx, topn=15)
    keywords = ', '.join([word for word, prob in topic_words])
    topics_keywords.append({
        'topic_id': idx + 1,
        'keywords': keywords,
        'top_words': [word for word, prob in topic_words[:10]]
    })
    print(f"\nTopic {idx+1}:")
    for word, prob in topic_words[:10]:
        print(f"  {word:<20} {prob:.4f}")

# ç‚ºæ¯ç¯‡è©•è«–åˆ†é…ä¸»é¡Œ
print(f"\n{'='*80}")
print("ASSIGNING TOPICS TO REVIEWS | åˆ†é…ä¸»é¡Œåˆ°è©•è«–")
print(f"{'='*80}")

topic_assignments = []
for doc_bow in corpus:
    topic_dist = lda_model.get_document_topics(doc_bow, minimum_probability=0)
    topic_probs = [prob for _, prob in topic_dist]
    dominant_topic = topic_probs.index(max(topic_probs)) + 1
    topic_assignments.append({
        'dominant_topic': dominant_topic,
        'topic_probability': max(topic_probs)
    })

df_result = pd.concat([df.reset_index(drop=True), pd.DataFrame(topic_assignments)], axis=1)

# çµ±è¨ˆæ¯å€‹ä¸»é¡Œçš„è©•è«–æ•¸é‡å’Œå¹³å‡è©•åˆ†
print(f"\n{'='*80}")
print("TOPIC STATISTICS | ä¸»é¡Œçµ±è¨ˆ")
print(f"{'='*80}")

topic_stats = df_result.groupby('dominant_topic').agg({
    'è©•åˆ†': ['count', 'mean', 'std'],
    'topic_probability': 'mean'
})
topic_stats.columns = ['review_count', 'avg_rating', 'rating_std', 'avg_probability']

topic_summary = []
for topic_id in range(1, 8):
    if topic_id in topic_stats.index:
        count = int(topic_stats.loc[topic_id, 'review_count'])
        rating = topic_stats.loc[topic_id, 'avg_rating']
        rating_std = topic_stats.loc[topic_id, 'rating_std']
        prob = topic_stats.loc[topic_id, 'avg_probability']
        percentage = (count / len(df_result)) * 100

        topic_summary.append({
            'Topic_ID': topic_id,
            'Top_Keywords': ', '.join(topics_keywords[topic_id-1]['top_words'][:5]),
            'Review_Count': count,
            'Percentage': f"{percentage:.1f}%",
            'Avg_Rating': f"{rating:.2f}",
            'Rating_Std': f"{rating_std:.2f}",
            'Avg_Probability': f"{prob:.3f}"
        })

        print(f"\nTopic {topic_id}:")
        print(f"  Keywords: {', '.join(topics_keywords[topic_id-1]['top_words'][:5])}")
        print(f"  Reviews: {count:,} ({percentage:.1f}%)")
        print(f"  Avg Rating: {rating:.2f} Â± {rating_std:.2f} stars")
        print(f"  Avg Probability: {prob:.3f}")

# å‰µå»ºè¼¸å‡ºç›®éŒ„
output_dir = Path("results/uk_lda_k7")
output_dir.mkdir(parents=True, exist_ok=True)

# å„²å­˜æ¨¡å‹
model_file = output_dir / 'uk_gensim_lda_k7_model.pkl'
with open(model_file, 'wb') as f:
    pickle.dump({
        'lda_model': lda_model,
        'dictionary': dictionary,
        'coherence_score': coherence_score,
        'perplexity_score': perplexity_score,
        'topics_keywords': topics_keywords,
        'topic_stats': topic_stats,
        'topic_summary': topic_summary,
        'data_info': {
            'total_reviews': len(df),
            'total_hospitals': df['hospital_name'].nunique(),
            'avg_rating': df['è©•åˆ†'].mean(),
            'date_range': 'Recent 1 year'
        }
    }, f)
print(f"\nâœ“ Model saved: {model_file}")

# å„²å­˜ä¸»é¡Œæ‘˜è¦
summary_df = pd.DataFrame(topic_summary)
summary_file = output_dir / 'uk_k7_topic_summary.csv'
summary_df.to_csv(summary_file, index=False, encoding='utf-8-sig')
print(f"âœ“ Topic summary saved: {summary_file}")

# å„²å­˜å®Œæ•´çµæœï¼ˆåŒ…å«æ¯ç­†è©•è«–çš„ä¸»é¡Œåˆ†é…ï¼‰
result_file = output_dir / 'uk_k7_reviews_with_topics.csv'
df_result.to_csv(result_file, index=False, encoding='utf-8-sig')
print(f"âœ“ Full results saved: {result_file}")

# å„²å­˜æ¯å®¶é†«é™¢çš„ä¸»é¡Œåˆ†å¸ƒ
print(f"\n{'='*80}")
print("HOSPITAL-LEVEL TOPIC DISTRIBUTION | é†«é™¢å±¤ç´šä¸»é¡Œåˆ†å¸ƒ")
print(f"{'='*80}")

hospital_topic_dist = df_result.groupby(['hospital_name', 'dominant_topic']).size().unstack(fill_value=0)
hospital_topic_dist['total'] = hospital_topic_dist.sum(axis=1)

# è¨ˆç®—ç™¾åˆ†æ¯”
for col in range(1, 8):
    if col in hospital_topic_dist.columns:
        hospital_topic_dist[f'Topic_{col}_%'] = (hospital_topic_dist[col] / hospital_topic_dist['total'] * 100).round(1)

hospital_dist_file = output_dir / 'uk_k7_hospital_topic_distribution.csv'
hospital_topic_dist.to_csv(hospital_dist_file, encoding='utf-8-sig')
print(f"âœ“ Hospital topic distribution saved: {hospital_dist_file}")

# é¡¯ç¤ºå‰ 5 å®¶é†«é™¢çš„ä¸»é¡Œåˆ†å¸ƒ
print(f"\nTop 5 hospitals by review count:")
top_hospitals = df_result['hospital_name'].value_counts().head(5)
for hospital, count in top_hospitals.items():
    print(f"\n{hospital} ({count} reviews):")
    hospital_reviews = df_result[df_result['hospital_name'] == hospital]
    topic_dist = hospital_reviews['dominant_topic'].value_counts().sort_index()
    for topic, cnt in topic_dist.items():
        pct = cnt / count * 100
        print(f"  Topic {topic}: {cnt:>3} ({pct:>5.1f}%)")

print(f"\n{'='*80}")
print("ANALYSIS COMPLETE! | åˆ†æå®Œæˆï¼")
print(f"{'='*80}")
print(f"\nâœ… Successfully analyzed {len(df):,} UK hospital reviews")
print(f"âœ… Identified 7 service quality dimensions using LDA")
print(f"\nğŸ“ Generated files:")
print(f"   1. {model_file.name}")
print(f"   2. {summary_file.name}")
print(f"   3. {result_file.name}")
print(f"   4. {hospital_dist_file.name}")
print(f"\nğŸ“Š Model Quality:")
print(f"   Coherence Score: {coherence_score:.4f}")
print(f"   Perplexity: {perplexity_score:.4f}")
