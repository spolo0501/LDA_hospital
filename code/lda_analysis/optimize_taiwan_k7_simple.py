#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°ç£é†«é™¢è©•è«– K=7 åƒæ•¸å„ªåŒ–æ¸¬è©¦ - ç°¡åŒ–ç©©å®šç‰ˆ
æ¸¬è©¦5çµ„æœ€é—œéµçš„åƒæ•¸é…ç½®
"""

import pickle
import pandas as pd
import numpy as np
from gensim.models import LdaModel
from gensim.models.coherencemodel import CoherenceModel
from gensim import corpora
import warnings
import time
from datetime import datetime
import os

warnings.filterwarnings('ignore')
os.environ['OMP_NUM_THREADS'] = '1'  # é™åˆ¶OpenMPç·šç¨‹

def train_single_model(config, corpus, dictionary, texts):
    """è¨“ç·´å–®å€‹LDAæ¨¡å‹ä¸¦è©•ä¼°"""
    test_name = config['name']
    alpha = config['alpha']
    eta = config['eta']
    iterations = config['iter']
    passes = config['passes']
    description = config['desc']

    print(f"\nâ–¶ {test_name}: {description}")
    print(f"  åƒæ•¸: alpha={alpha}, eta={eta}, iterations={iterations}, passes={passes}")

    start_time = time.time()

    try:
        # è¨“ç·´æ¨¡å‹
        lda_model = LdaModel(
            corpus=corpus,
            id2word=dictionary,
            num_topics=7,
            alpha=alpha,
            eta=eta,
            iterations=iterations,
            passes=passes,
            random_state=42,
            per_word_topics=False
        )

        # è¨ˆç®—coherenceï¼ˆå–®é€²ç¨‹ï¼‰
        coherence_model = CoherenceModel(
            model=lda_model,
            texts=texts,
            dictionary=dictionary,
            coherence='c_v',
            processes=1
        )
        coherence_score = coherence_model.get_coherence()

        # è¨ˆç®—perplexity
        perplexity_score = lda_model.log_perplexity(corpus)

        training_time = time.time() - start_time

        print(f"  âœ“ Coherence: {coherence_score:.4f}")
        print(f"  âœ“ Perplexity: {perplexity_score:.4f}")
        print(f"  âœ“ è¨“ç·´æ™‚é–“: {training_time:.1f}ç§’")

        # é¡¯ç¤ºä¸»é¡Œé—œéµè©
        print(f"  ä¸»é¡Œé—œéµè©é è¦½:")
        for idx in range(min(3, 7)):  # åªé¡¯ç¤ºå‰3å€‹ä¸»é¡Œ
            topic_words = lda_model.show_topic(idx, topn=5)
            keywords = ', '.join([word for word, prob in topic_words])
            print(f"    ä¸»é¡Œ{idx+1}: {keywords}")

        return {
            'test_name': test_name,
            'description': description,
            'alpha': str(alpha),
            'eta': str(eta),
            'iterations': iterations,
            'passes': passes,
            'coherence': coherence_score,
            'perplexity': perplexity_score,
            'training_time_sec': training_time,
            'status': 'Success',
            'model': lda_model
        }

    except Exception as e:
        print(f"  âœ— éŒ¯èª¤: {str(e)}")
        return {
            'test_name': test_name,
            'description': description,
            'alpha': str(alpha),
            'eta': str(eta),
            'iterations': iterations,
            'passes': passes,
            'coherence': None,
            'perplexity': None,
            'training_time_sec': None,
            'status': f'Failed: {str(e)}',
            'model': None
        }

def main():
    print("\n" + "="*80)
    print("å°ç£é†«é™¢è©•è«– K=7 LDA åƒæ•¸å„ªåŒ–æ¸¬è©¦ - ç°¡åŒ–ç‰ˆ")
    print("Taiwan Hospital Reviews K=7 LDA Parameter Optimization")
    print("="*80)

    # ========================================================================
    # 1. è¼‰å…¥è³‡æ–™
    # ========================================================================
    print("\nã€æ­¥é©Ÿ1ã€‘è¼‰å…¥å‰è™•ç†è³‡æ–™...")
    with open('../../data/processed/taiwan/reviews_for_lda.txt', 'r', encoding='utf-8') as f:
        lines = f.readlines()
    texts = [line.strip().split() for line in lines if line.strip()]
    print(f"âœ“ å·²è¼‰å…¥ {len(texts)} ç­†è©•è«–")

    # ========================================================================
    # 2. å»ºç«‹å­—å…¸å’Œèªæ–™åº«
    # ========================================================================
    print("\nã€æ­¥é©Ÿ2ã€‘å»ºç«‹å­—å…¸å’Œèªæ–™åº«...")
    dictionary = corpora.Dictionary(texts)
    dictionary.filter_extremes(no_below=3, no_above=0.5, keep_n=None)
    dictionary.compactify()
    corpus = [dictionary.doc2bow(text) for text in texts]
    print(f"âœ“ èªæ–™åº«å»ºç«‹å®Œæˆ: {len(dictionary)} è©å½™, {len(corpus)} æ–‡æª”")

    # ========================================================================
    # 3. å®šç¾©æ¸¬è©¦é…ç½®ï¼ˆåªæ¸¬è©¦5çµ„æœ€é—œéµçš„ï¼‰
    # ========================================================================
    print("\nã€æ­¥é©Ÿ3ã€‘å®šç¾©5çµ„é—œéµåƒæ•¸æ¸¬è©¦...")
    test_configs = [
        {'name': 'Baseline', 'alpha': 'symmetric', 'eta': 'auto', 'iter': 100, 'passes': 10,
         'desc': 'ç•¶å‰åƒæ•¸ï¼ˆåŸºæº–ï¼‰'},
        {'name': 'Test-1-Asymmetric', 'alpha': 'asymmetric', 'eta': 'auto', 'iter': 100, 'passes': 10,
         'desc': 'Asymmetric alpha'},
        {'name': 'Test-2-LowEta', 'alpha': 'symmetric', 'eta': 0.01, 'iter': 100, 'passes': 10,
         'desc': 'ä½eta (0.01)'},
        {'name': 'Test-3-Combo', 'alpha': 'asymmetric', 'eta': 0.01, 'iter': 100, 'passes': 10,
         'desc': 'Asymmetric + ä½eta'},
        {'name': 'Test-4-AllOpt', 'alpha': 'asymmetric', 'eta': 0.01, 'iter': 150, 'passes': 15,
         'desc': 'å…¨é¢å„ªåŒ–'},
    ]

    # ========================================================================
    # 4. åŸ·è¡Œæ¸¬è©¦
    # ========================================================================
    print("\nã€æ­¥é©Ÿ4ã€‘é–‹å§‹åƒæ•¸å„ªåŒ–æ¸¬è©¦...")
    print("-" * 80)

    results = []
    for config in test_configs:
        result = train_single_model(config, corpus, dictionary, texts)
        results.append(result)
        # ä¿å­˜æˆåŠŸçš„æ¨¡å‹
        if result['status'] == 'Success' and result['model'] is not None:
            model_path = f"../../results/taiwan_lda_k7/optimized_{result['test_name'].lower()}_model.pkl"
            result['model'].save(model_path)
            print(f"  âœ“ æ¨¡å‹å·²ä¿å­˜: {model_path}")
        # å¾çµæœä¸­ç§»é™¤æ¨¡å‹å°è±¡ï¼ˆé¿å…åºåˆ—åŒ–å•é¡Œï¼‰
        result.pop('model', None)

    # ========================================================================
    # 5. çµæœåˆ†æ
    # ========================================================================
    print("\n" + "="*80)
    print("ã€æ­¥é©Ÿ5ã€‘åƒæ•¸å„ªåŒ–çµæœåŒ¯ç¸½")
    print("="*80)

    results_df = pd.DataFrame(results)
    successful = results_df[results_df['status'] == 'Success'].copy()

    if len(successful) == 0:
        print("\nâŒ æ‰€æœ‰æ¸¬è©¦éƒ½å¤±æ•—äº†")
        return

    successful_sorted = successful.sort_values('coherence', ascending=False)
    baseline_coh = successful[successful['test_name']=='Baseline']['coherence'].values[0]

    print("\nğŸ“Š æ¸¬è©¦çµæœæ’å:")
    print("-" * 80)
    for idx, row in successful_sorted.iterrows():
        rank = list(successful_sorted.index).index(idx) + 1
        improvement = ((row['coherence'] - baseline_coh) / baseline_coh * 100)
        print(f"\nã€#{rank}ã€‘{row['test_name']}")
        print(f"  Coherence: {row['coherence']:.4f} (ç›¸å°åŸºæº– {improvement:+.2f}%)")
        print(f"  Perplexity: {row['perplexity']:.4f}")
        print(f"  æ™‚é–“: {row['training_time_sec']:.1f}ç§’")

    # ========================================================================
    # 6. èˆ‡K=5æ¯”è¼ƒ
    # ========================================================================
    print("\n" + "="*80)
    print("ã€æ­¥é©Ÿ6ã€‘èˆ‡K=5æ¯”è¼ƒ")
    print("="*80)

    k5_coh = 0.4326
    best_k7_coh = successful_sorted.iloc[0]['coherence']
    gap = k5_coh - best_k7_coh
    gap_pct = (gap / k5_coh) * 100

    print(f"\nK=5æœ€å„ª: {k5_coh:.4f}")
    print(f"K=7åŸºæº–: {baseline_coh:.4f}")
    print(f"K=7å„ªåŒ–: {best_k7_coh:.4f}")
    print(f"\nå·®è·: {gap:.4f} ({gap_pct:.2f}%)")
    print(f"æ”¹å–„: {(best_k7_coh - baseline_coh):.4f} ({(best_k7_coh - baseline_coh)/baseline_coh*100:+.2f}%)")

    if gap_pct < 3:
        print("\nâœ… å·®è· < 3%ï¼Œçµ±è¨ˆä¸Šå¯æ¥å—ï¼")
    elif gap_pct < 5:
        print("\nâš ï¸ å·®è· < 5%ï¼Œéœ€å¼·èª¿K=7é¡å¤–åƒ¹å€¼")
    else:
        print("\nâš ï¸ å·®è·è¼ƒå¤§ï¼Œéœ€è©³ç´°è«–è­‰")

    # ========================================================================
    # 7. ä¿å­˜çµæœ
    # ========================================================================
    print("\nã€æ­¥é©Ÿ7ã€‘ä¿å­˜çµæœ...")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_file = f'../../results/taiwan_lda_k7/param_optimization_results_{timestamp}.csv'
    results_df.to_csv(csv_file, index=False, encoding='utf-8-sig')
    print(f"âœ“ å·²ä¿å­˜: {csv_file}")

    print("\n" + "="*80)
    print("âœ… å„ªåŒ–å®Œæˆï¼")
    print("="*80)
    print(f"\nğŸ† æœ€ä½³: {successful_sorted.iloc[0]['test_name']}")
    print(f"   Coherence: {successful_sorted.iloc[0]['coherence']:.4f}")

if __name__ == '__main__':
    main()
