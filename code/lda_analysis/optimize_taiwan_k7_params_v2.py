#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°ç£é†«é™¢è©•è«– K=7 åƒæ•¸å„ªåŒ–æ¸¬è©¦ V2
ä½¿ç”¨ reviews_for_lda.txt ä½œç‚ºè¼¸å…¥
"""

import pickle
import pandas as pd
import numpy as np
from gensim.models import LdaModel
from gensim.models.coherencemodel import CoherenceModel
from gensim import corpora
import warnings
import time
from datetime import datetime
warnings.filterwarnings('ignore')

print("\n" + "="*80)
print("å°ç£é†«é™¢è©•è«– K=7 LDA åƒæ•¸å„ªåŒ–æ¸¬è©¦ V2")
print("Taiwan Hospital Reviews K=7 LDA Parameter Optimization")
print("="*80)

# ============================================================================
# 1. è¼‰å…¥è³‡æ–™
# ============================================================================

print("\nã€æ­¥é©Ÿ1ã€‘è¼‰å…¥å‰è™•ç†è³‡æ–™...")

# è®€å– reviews_for_lda.txt
with open('../../data/processed/taiwan/reviews_for_lda.txt', 'r', encoding='utf-8') as f:
    lines = f.readlines()

# æ¯è¡Œæ˜¯ä¸€å€‹å·²åˆ†è©çš„è©•è«–
texts = [line.strip().split() for line in lines if line.strip()]

print(f"âœ“ å·²è¼‰å…¥ {len(texts)} ç­†è©•è«–")
print(f"  å¹³å‡è©æ•¸: {np.mean([len(t) for t in texts]):.2f}")

# ============================================================================
# 2. å»ºç«‹å­—å…¸å’Œèªæ–™åº«
# ============================================================================

print("\nã€æ­¥é©Ÿ2ã€‘å»ºç«‹å­—å…¸å’Œèªæ–™åº«...")
dictionary = corpora.Dictionary(texts)
original_size = len(dictionary)

# éæ¿¾æ¥µç«¯è©å½™ï¼ˆèˆ‡åŸå§‹åˆ†æç›¸åŒï¼‰
dictionary.filter_extremes(
    no_below=3,
    no_above=0.5,
    keep_n=None
)
dictionary.compactify()

print(f"  åŸå§‹è©å½™æ•¸: {original_size}")
print(f"  éæ¿¾å¾Œè©å½™æ•¸: {len(dictionary)}")

# å»ºç«‹èªæ–™åº«
corpus = [dictionary.doc2bow(text) for text in texts]
print(f"âœ“ èªæ–™åº«å»ºç«‹å®Œæˆï¼Œå…± {len(corpus)} ç­†æ–‡æª”")

# ============================================================================
# 3. å®šç¾©åƒæ•¸å„ªåŒ–æ¸¬è©¦
# ============================================================================

print("\nã€æ­¥é©Ÿ3ã€‘å®šç¾©åƒæ•¸æ¸¬è©¦ç©ºé–“...")

# åƒæ•¸æ¸¬è©¦çµ„åˆ
test_configs = [
    {'name': 'Baseline', 'alpha': 'symmetric', 'eta': 'auto', 'iter': 100, 'passes': 10,
     'desc': 'ç•¶å‰ä½¿ç”¨çš„åƒæ•¸ï¼ˆåŸºæº–ï¼‰'},

    {'name': 'Test-1-Asymmetric', 'alpha': 'asymmetric', 'eta': 'auto', 'iter': 100, 'passes': 10,
     'desc': 'æ”¹ç”¨asymmetric alpha'},

    {'name': 'Test-2-LowEta', 'alpha': 'symmetric', 'eta': 0.01, 'iter': 100, 'passes': 10,
     'desc': 'é™ä½etaè‡³0.01'},

    {'name': 'Test-3-MoreTraining', 'alpha': 'symmetric', 'eta': 'auto', 'iter': 200, 'passes': 20,
     'desc': 'å¢åŠ iterationså’Œpasses'},

    {'name': 'Test-4-Combo1', 'alpha': 'asymmetric', 'eta': 0.01, 'iter': 100, 'passes': 10,
     'desc': 'Asymmetric + ä½eta'},

    {'name': 'Test-5-Combo2', 'alpha': 'asymmetric', 'eta': 'auto', 'iter': 200, 'passes': 20,
     'desc': 'Asymmetric + å¢åŠ è¨“ç·´'},

    {'name': 'Test-6-Combo3', 'alpha': 'symmetric', 'eta': 0.01, 'iter': 200, 'passes': 20,
     'desc': 'ä½eta + å¢åŠ è¨“ç·´'},

    {'name': 'Test-7-AllOptimized', 'alpha': 'asymmetric', 'eta': 0.01, 'iter': 200, 'passes': 20,
     'desc': 'å…¨éƒ¨åƒæ•¸å„ªåŒ–'},

    {'name': 'Test-8-VeryLowEta', 'alpha': 'asymmetric', 'eta': 0.001, 'iter': 200, 'passes': 20,
     'desc': 'æ¥µä½eta (0.001)'},
]

print(f"âœ“ å…±è¨­å®š {len(test_configs)} çµ„åƒæ•¸æ¸¬è©¦")

# ============================================================================
# 4. åŸ·è¡Œåƒæ•¸å„ªåŒ–æ¸¬è©¦
# ============================================================================

print("\nã€æ­¥é©Ÿ4ã€‘é–‹å§‹åƒæ•¸å„ªåŒ–æ¸¬è©¦...")
print("-" * 80)

results = []

for config in test_configs:
    test_name = config['name']
    alpha = config['alpha']
    eta = config['eta']
    iterations = config['iter']
    passes = config['passes']
    description = config['desc']

    print(f"\nâ–¶ {test_name}: {description}")
    print(f"  åƒæ•¸: alpha={alpha}, eta={eta}, iterations={iterations}, passes={passes}")

    start_time = time.time()

    # è¨“ç·´æ¨¡å‹
    try:
        lda_model = LdaModel(
            corpus=corpus,
            id2word=dictionary,
            num_topics=7,
            alpha=alpha,
            eta=eta,
            iterations=iterations,
            passes=passes,
            random_state=42,
            eval_every=None,
            chunksize=2000
        )

        # è¨ˆç®—coherence
        coherence_model = CoherenceModel(
            model=lda_model,
            texts=texts,
            dictionary=dictionary,
            coherence='c_v'
        )
        coherence_score = coherence_model.get_coherence()

        # è¨ˆç®—perplexity
        perplexity_score = lda_model.log_perplexity(corpus)

        training_time = time.time() - start_time

        print(f"  âœ“ Coherence: {coherence_score:.4f}")
        print(f"  âœ“ Perplexity: {perplexity_score:.4f}")
        print(f"  âœ“ è¨“ç·´æ™‚é–“: {training_time:.1f}ç§’")

        # é¡¯ç¤ºä¸»é¡Œé—œéµè©
        print(f"  ä¸»é¡Œé—œéµè©é è¦½:")
        for idx in range(7):
            topic_words = lda_model.show_topic(idx, topn=5)
            keywords = ', '.join([word for word, prob in topic_words])
            print(f"    ä¸»é¡Œ{idx+1}: {keywords}")

        # è¨˜éŒ„çµæœ
        results.append({
            'test_name': test_name,
            'description': description,
            'alpha': str(alpha),
            'eta': str(eta),
            'iterations': iterations,
            'passes': passes,
            'coherence': coherence_score,
            'perplexity': perplexity_score,
            'training_time_sec': training_time,
            'status': 'Success'
        })

        # ä¿å­˜æ¨¡å‹
        model_filename = f'../../results/taiwan_lda_k7/optimized_{test_name.lower()}_model.pkl'
        lda_model.save(model_filename)
        print(f"  âœ“ æ¨¡å‹å·²ä¿å­˜: {model_filename}")

    except Exception as e:
        print(f"  âœ— éŒ¯èª¤: {str(e)}")
        results.append({
            'test_name': test_name,
            'description': description,
            'alpha': str(alpha),
            'eta': str(eta),
            'iterations': iterations,
            'passes': passes,
            'coherence': None,
            'perplexity': None,
            'training_time_sec': None,
            'status': f'Failed: {str(e)}'
        })

# ============================================================================
# 5. çµæœåŒ¯ç¸½èˆ‡åˆ†æ
# ============================================================================

print("\n" + "="*80)
print("ã€æ­¥é©Ÿ5ã€‘åƒæ•¸å„ªåŒ–çµæœåŒ¯ç¸½")
print("="*80)

results_df = pd.DataFrame(results)

# æŒ‰coherenceæ’åº
results_df_sorted = results_df[results_df['status'] == 'Success'].sort_values(
    'coherence', ascending=False
)

print("\nğŸ“Š æ¸¬è©¦çµæœæ’åï¼ˆä¾Coherence Scoreï¼‰:")
print("-" * 80)

baseline_coherence = results_df[results_df['test_name']=='Baseline']['coherence'].values[0]

for idx, row in results_df_sorted.iterrows():
    rank = list(results_df_sorted.index).index(idx) + 1
    improvement = ((row['coherence'] - baseline_coherence) / baseline_coherence * 100)

    print(f"\nã€æ’å #{rank}ã€‘{row['test_name']}")
    print(f"  æè¿°: {row['description']}")
    if rank == len(results_df_sorted) and row['test_name'] == 'Baseline':
        print(f"  Coherence: {row['coherence']:.4f} (åŸºæº–)")
    else:
        print(f"  Coherence: {row['coherence']:.4f} (ç›¸å°åŸºæº– {improvement:+.2f}%)")
    print(f"  Perplexity: {row['perplexity']:.4f}")
    print(f"  è¨“ç·´æ™‚é–“: {row['training_time_sec']:.1f}ç§’")
    print(f"  åƒæ•¸: alpha={row['alpha']}, eta={row['eta']}, " +
          f"iter={row['iterations']}, passes={row['passes']}")

# ============================================================================
# 6. èˆ‡K=5æ¯”è¼ƒ
# ============================================================================

print("\n" + "="*80)
print("ã€æ­¥é©Ÿ6ã€‘èˆ‡K=5æœ€å„ªæ¨¡å‹æ¯”è¼ƒ")
print("="*80)

k5_coherence = 0.4326  # å¾ç ”ç©¶æ–¹æ³•è«–è¨˜éŒ„ä¸­ç²å¾—
best_k7_coherence = results_df_sorted.iloc[0]['coherence']
gap = k5_coherence - best_k7_coherence
gap_pct = (gap / k5_coherence) * 100

print(f"\nğŸ“ˆ Coherence Score æ¯”è¼ƒ:")
print(f"  K=5 (æœ€å„ª): {k5_coherence:.4f}")
print(f"  K=7 (åŸºæº–): {baseline_coherence:.4f}")
print(f"  K=7 (å„ªåŒ–å¾Œæœ€ä½³): {best_k7_coherence:.4f}")
print(f"\n  å·®è·:")
print(f"    K=7æœ€ä½³ vs K=5: {gap:.4f} ({gap_pct:.2f}%)")
print(f"    å„ªåŒ–æ”¹å–„å¹…åº¦: {(best_k7_coherence - baseline_coherence):.4f} " +
      f"({(best_k7_coherence - baseline_coherence)/baseline_coherence*100:+.2f}%)")

if gap_pct < 3:
    print("\nâœ… å„ªåŒ–å¾Œçš„K=7èˆ‡K=5å·®è· < 3%ï¼Œçµ±è¨ˆä¸Šå¯æ¥å—ï¼")
    print("   å¯ä»¥è«–è­‰ï¼šK=7æä¾›æ›´å®Œæ•´çš„æ§‹é¢ï¼ˆç’°å¢ƒè¨­æ–½ï¼‰ï¼Œå¾®å°çš„coherenceå·®ç•°å€¼å¾—æ¬Šè¡¡")
elif gap_pct < 5:
    print("\nâš ï¸ å„ªåŒ–å¾Œçš„K=7èˆ‡K=5å·®è· < 5%ï¼Œéœ€è¦å¼·èª¿K=7çš„é¡å¤–æ§‹é¢åƒ¹å€¼")
else:
    print("\nâš ï¸ å„ªåŒ–å¾Œçš„K=7èˆ‡K=5ä»æœ‰è¼ƒå¤§å·®è·ï¼Œéœ€è¦è©³ç´°è«–è­‰é¸æ“‡K=7çš„ç†ç”±")

# ============================================================================
# 7. ä¿å­˜çµæœ
# ============================================================================

print("\nã€æ­¥é©Ÿ7ã€‘ä¿å­˜å„ªåŒ–çµæœ...")

# ä¿å­˜è©³ç´°çµæœ
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
results_filename = f'../../results/taiwan_lda_k7/param_optimization_results_{timestamp}.csv'
results_df.to_csv(results_filename, index=False, encoding='utf-8-sig')
print(f"âœ“ è©³ç´°çµæœå·²ä¿å­˜: {results_filename}")

# ä¿å­˜æ‘˜è¦å ±å‘Š
report_filename = f'../../results/taiwan_lda_k7/param_optimization_report_{timestamp}.txt'
with open(report_filename, 'w', encoding='utf-8') as f:
    f.write("="*80 + "\n")
    f.write("å°ç£é†«é™¢è©•è«– K=7 åƒæ•¸å„ªåŒ–æ¸¬è©¦å ±å‘Š\n")
    f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    f.write("="*80 + "\n\n")

    f.write("ã€æ¸¬è©¦ç›®çš„ã€‘\n")
    f.write("æ‰¾åˆ°K=7çš„æœ€ä½³åƒæ•¸é…ç½®ï¼Œç¸®å°èˆ‡K=5çš„coherenceå·®è·\n\n")

    f.write("ã€æ¸¬è©¦çµæœæ‘˜è¦ã€‘\n")
    f.write(f"å…±æ¸¬è©¦ {len(results_df[results_df['status']=='Success'])} çµ„åƒæ•¸é…ç½®\n\n")

    f.write("ã€æœ€ä½³é…ç½®ã€‘\n")
    best_row = results_df_sorted.iloc[0]
    f.write(f"æ¸¬è©¦åç¨±: {best_row['test_name']}\n")
    f.write(f"æè¿°: {best_row['description']}\n")
    f.write(f"Coherence: {best_row['coherence']:.4f}\n")
    f.write(f"Perplexity: {best_row['perplexity']:.4f}\n")
    f.write(f"åƒæ•¸:\n")
    f.write(f"  - alpha: {best_row['alpha']}\n")
    f.write(f"  - eta: {best_row['eta']}\n")
    f.write(f"  - iterations: {best_row['iterations']}\n")
    f.write(f"  - passes: {best_row['passes']}\n")
    f.write(f"è¨“ç·´æ™‚é–“: {best_row['training_time_sec']:.1f}ç§’\n\n")

    f.write("ã€èˆ‡K=5æ¯”è¼ƒã€‘\n")
    f.write(f"K=5æœ€å„ªcoherence: {k5_coherence:.4f}\n")
    f.write(f"K=7åŸºæº–coherence: {baseline_coherence:.4f}\n")
    f.write(f"K=7å„ªåŒ–å¾Œcoherence: {best_k7_coherence:.4f}\n")
    f.write(f"å·®è·: {gap:.4f} ({gap_pct:.2f}%)\n")
    f.write(f"æ”¹å–„å¹…åº¦: {(best_k7_coherence - baseline_coherence):.4f} " +
            f"({(best_k7_coherence - baseline_coherence)/baseline_coherence*100:+.2f}%)\n\n")

    f.write("ã€å®Œæ•´æ’åã€‘\n")
    for idx, row in results_df_sorted.iterrows():
        rank = list(results_df_sorted.index).index(idx) + 1
        f.write(f"\næ’å #{rank}: {row['test_name']}\n")
        f.write(f"  Coherence: {row['coherence']:.4f}\n")
        f.write(f"  æè¿°: {row['description']}\n")

print(f"âœ“ æ‘˜è¦å ±å‘Šå·²ä¿å­˜: {report_filename}")

print("\n" + "="*80)
print("âœ… åƒæ•¸å„ªåŒ–æ¸¬è©¦å®Œæˆï¼")
print("="*80)
print(f"\nğŸ† æœ€ä½³é…ç½®: {results_df_sorted.iloc[0]['test_name']}")
print(f"   Coherence: {results_df_sorted.iloc[0]['coherence']:.4f}")
print(f"   æ”¹å–„å¹…åº¦: {(best_k7_coherence - baseline_coherence)*100:.2f}%")
print("\nğŸ“ ç”Ÿæˆçš„æª”æ¡ˆ:")
print(f"   - è©³ç´°çµæœ: {results_filename}")
print(f"   - æ‘˜è¦å ±å‘Š: {report_filename}")
print(f"   - å„ªåŒ–æ¨¡å‹: results/taiwan_lda_k7/optimized_*_model.pkl")
