#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°ç¾é†«é™¢è©•è«–è·¨åœ‹çµ±è¨ˆæª¢é©—åˆ†æ (ä¿®å¾©ç‰ˆ)
Taiwan-USA Cross-National Statistical Tests (Fixed Version)
ç”Ÿæˆæ—¥æœŸ: 2025-11-07
"""

import pickle
import pandas as pd
import numpy as np
from scipy import stats
import warnings
from datetime import datetime

warnings.filterwarnings('ignore')

print("="*80)
print("å°ç¾é†«é™¢è©•è«–è·¨åœ‹çµ±è¨ˆæª¢é©—åˆ†æ (ä¿®å¾©ç‰ˆ)")
print("Taiwan-USA Cross-National Statistical Tests")
print("="*80)

# ============================================================================
# Part 1: è¼‰å…¥å°ç£è³‡æ–™
# ============================================================================
print("\nã€Part 1ã€‘è¼‰å…¥å°ç£ K=7 åˆ†æçµæœ...")

# ä½¿ç”¨å·²ç¶“ç”Ÿæˆçš„ K=7 åˆ†æçµæœæª”æ¡ˆ
taiwan_data_path = '../../data/raw/taiwan/lda_k7_analysis_results.xlsx'
df_taiwan = pd.read_excel(taiwan_data_path)
print(f"âœ“ å°ç£è©•è«–æ•¸: {len(df_taiwan):,}")
print(f"âœ“ æ¬„ä½: {list(df_taiwan.columns)}")

# ============================================================================
# Part 2: è¼‰å…¥ç¾åœ‹è³‡æ–™
# ============================================================================
print("\nã€Part 2ã€‘è¼‰å…¥ç¾åœ‹ K=6 ä¸»é¡Œåˆ†é…è³‡æ–™...")
usa_data_path = '../../results/usa_lda_k7/usa_k6_topic_analysis_20251107_122236.csv'
df_usa = pd.read_csv(usa_data_path, encoding='utf-8-sig')
print(f"âœ“ ç¾åœ‹è©•è«–æ•¸: {len(df_usa):,}")

# ============================================================================
# Part 3: ä¸»é¡Œèªç¾©æ˜ å°„å®šç¾©
# ============================================================================
print("\nã€Part 3ã€‘å®šç¾©å°ç¾ä¸»é¡Œèªç¾©æ˜ å°„é—œä¿‚...")

# åŸºæ–¼èªç¾©æ˜ å°„è¡¨çš„å°æ‡‰é—œä¿‚
semantic_mapping = {
    'Emergency Care': {
        'taiwan_topic': 7,
        'usa_topic': 2,
        'taiwan_name': 'æ€¥è¨ºé†«ç™‚æœå‹™',
        'usa_name': 'æ€¥è¨ºç­‰å¾…æ™‚é–“',
        'similarity': 'High'
    },
    'Nursing/Professional Care': {
        'taiwan_topic': 1,
        'usa_topic': 4,
        'taiwan_name': 'é†«ç™‚å°ˆæ¥­å“è³ª',
        'usa_name': 'è­·ç†ç…§è­·å“è³ª',
        'similarity': 'Medium'
    },
    'Outpatient Services': {
        'taiwan_topic': 2,
        'usa_topic': 3,
        'taiwan_name': 'æ›è™Ÿæ‰¹åƒ¹æµç¨‹',
        'usa_name': 'é–€è¨ºé†«ç™‚æœå‹™',
        'similarity': 'Medium'
    },
    'Inpatient/Critical Care': {
        'taiwan_topic': 6,
        'usa_topic': 1,
        'taiwan_name': 'ä½é™¢ç…§è­·ç¶“é©—',
        'usa_name': 'é‡ç—‡ç…§è­·èˆ‡å®¶åº­é—œæ‡·',
        'similarity': 'Medium'
    }
}

# ============================================================================
# Part 4: çµ±è¨ˆæª¢é©— - è©•åˆ†å·®ç•°
# ============================================================================
print("\nã€Part 4ã€‘çµ±è¨ˆæª¢é©—: è©•åˆ†å·®ç•° (Mann-Whitney U Test)")
print("="*60)

statistical_results = []

for dimension, mapping in semantic_mapping.items():
    tw_topic = mapping['taiwan_topic']
    us_topic = mapping['usa_topic']

    # æå–è©•åˆ†
    taiwan_ratings = df_taiwan[df_taiwan['Dominant_Topic'] == tw_topic]['Rating']
    usa_ratings = df_usa[df_usa['dominant_topic'] == us_topic]['è©•åˆ†']

    # æè¿°æ€§çµ±è¨ˆ
    tw_mean = taiwan_ratings.mean()
    tw_median = taiwan_ratings.median()
    tw_std = taiwan_ratings.std()
    tw_n = len(taiwan_ratings)

    us_mean = usa_ratings.mean()
    us_median = usa_ratings.median()
    us_std = usa_ratings.std()
    us_n = len(usa_ratings)

    # Mann-Whitney U Test (non-parametric, suitable for ordinal rating data)
    statistic, p_value = stats.mannwhitneyu(taiwan_ratings, usa_ratings, alternative='two-sided')

    # Effect size (r = Z / sqrt(N))
    z_score = stats.norm.ppf(1 - p_value/2)  # Two-tailed
    effect_size = abs(z_score / np.sqrt(tw_n + us_n))

    # åˆ¤æ–·é¡¯è‘—æ€§
    if p_value < 0.001:
        significance = '***'
    elif p_value < 0.01:
        significance = '**'
    elif p_value < 0.05:
        significance = '*'
    else:
        significance = 'n.s.'

    print(f"\nâ–¶ {dimension}")
    print(f"   å°ç£ ({mapping['taiwan_name']}): n={tw_n}, M={tw_mean:.2f}, Mdn={tw_median:.1f}, SD={tw_std:.2f}")
    print(f"   ç¾åœ‹ ({mapping['usa_name']}): n={us_n}, M={us_mean:.2f}, Mdn={us_median:.1f}, SD={us_std:.2f}")
    print(f"   Î” (US - TW): {us_mean - tw_mean:+.2f}")
    print(f"   Mann-Whitney U = {statistic:.0f}, p = {p_value:.6f} {significance}")
    effect_interp = "small" if effect_size < 0.3 else "medium" if effect_size < 0.5 else "large"
    print(f"   Effect size r = {effect_size:.3f} ({effect_interp})")

    statistical_results.append({
        'Dimension': dimension,
        'Taiwan_Topic': tw_topic,
        'USA_Topic': us_topic,
        'Taiwan_Name': mapping['taiwan_name'],
        'USA_Name': mapping['usa_name'],
        'TW_N': tw_n,
        'TW_Mean': tw_mean,
        'TW_Median': tw_median,
        'TW_SD': tw_std,
        'US_N': us_n,
        'US_Mean': us_mean,
        'US_Median': us_median,
        'US_SD': us_std,
        'Mean_Diff': us_mean - tw_mean,
        'U_Statistic': statistic,
        'p_value': p_value,
        'Significance': significance,
        'Effect_Size_r': effect_size,
        'Interpretation': 'US significantly higher' if us_mean > tw_mean and p_value < 0.05 else 'TW significantly higher' if tw_mean > us_mean and p_value < 0.05 else 'No significant difference'
    })

# å„²å­˜çµ±è¨ˆçµæœ
df_stats = pd.DataFrame(statistical_results)
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
stats_output = f'../../manuscripts/reports/Taiwan_USA_Rating_Differences_Statistics_{timestamp}.csv'
df_stats.to_csv(stats_output, index=False, encoding='utf-8-sig')
print(f"\nâœ“ çµ±è¨ˆçµæœå·²å„²å­˜: {stats_output}")

# ============================================================================
# Part 5: å¡æ–¹æª¢é©— - ä¸»é¡Œæ¯”ä¾‹å·®ç•° (H4 æª¢é©—)
# ============================================================================
print("\n\nã€Part 5ã€‘å¡æ–¹æª¢é©—: æ€¥è¨ºä¸»é¡Œæ¯”ä¾‹å·®ç•° (H4)")
print("="*60)

# H4: ç¾åœ‹æ›´é—œæ³¨æ€¥è¨ºç­‰å¾…æ™‚é–“ï¼ˆæ•ˆç‡é‡è¦–ï¼‰
tw_emergency_count = len(df_taiwan[df_taiwan['Dominant_Topic'] == 7])
tw_other_count = len(df_taiwan) - tw_emergency_count
us_emergency_count = len(df_usa[df_usa['dominant_topic'] == 2])
us_other_count = len(df_usa) - us_emergency_count

# å»ºç«‹åˆ—è¯è¡¨
contingency_table = np.array([
    [tw_emergency_count, tw_other_count],
    [us_emergency_count, us_other_count]
])

# å¡æ–¹æª¢é©—
chi2, p_chi, dof, expected = stats.chi2_contingency(contingency_table)

# è¨ˆç®—æ¯”ä¾‹
tw_emergency_pct = (tw_emergency_count / len(df_taiwan)) * 100
us_emergency_pct = (us_emergency_count / len(df_usa)) * 100

# Effect size (CramÃ©r's V)
n = contingency_table.sum()
cramers_v = np.sqrt(chi2 / n)

print(f"\næ€¥è¨ºä¸»é¡Œæ¯”ä¾‹:")
print(f"  å°ç£: {tw_emergency_count}/{len(df_taiwan)} = {tw_emergency_pct:.1f}%")
print(f"  ç¾åœ‹: {us_emergency_count}/{len(df_usa)} = {us_emergency_pct:.1f}%")
print(f"  Î”: {us_emergency_pct - tw_emergency_pct:+.1f}%")
print(f"\nå¡æ–¹æª¢é©—çµæœ:")
chi_sig = '***' if p_chi < 0.001 else '**' if p_chi < 0.01 else '*' if p_chi < 0.05 else 'n.s.'
print(f"  Ï‡Â²({dof}) = {chi2:.2f}, p = {p_chi:.6f} {chi_sig}")
cramers_interp = 'small' if cramers_v < 0.1 else 'medium' if cramers_v < 0.3 else 'large'
print(f"  CramÃ©r's V = {cramers_v:.3f} ({cramers_interp})")

if p_chi < 0.05:
    print(f"\nâœ… H4 æ”¯æŒ: ç¾åœ‹è©•è«–é¡¯è‘—æ›´é—œæ³¨æ€¥è¨ºç­‰å¾…æ™‚é–“ (+{us_emergency_pct - tw_emergency_pct:.1f}%, p = {p_chi:.6f})")
else:
    print(f"\nâŒ H4 ä¸æ”¯æŒ: æ¯”ä¾‹å·®ç•°ä¸é¡¯è‘— (p = {p_chi:.3f})")

# ============================================================================
# Part 6: ç”Ÿæˆçµ±è¨ˆæª¢é©—å ±å‘Š
# ============================================================================
print("\n\nã€Part 6ã€‘ç”Ÿæˆçµ±è¨ˆæª¢é©—å ±å‘Š...")

report_lines = []
report_lines.append("# å°ç¾é†«é™¢è©•è«–çµ±è¨ˆæª¢é©—çµæœå ±å‘Š")
report_lines.append("# Taiwan-USA Statistical Test Results")
report_lines.append("")
report_lines.append(f"**ç”Ÿæˆæ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
report_lines.append(f"**å°ç£æ¨£æœ¬æ•¸**: {len(df_taiwan):,} ç­†è©•è«– (K=7)")
report_lines.append(f"**ç¾åœ‹æ¨£æœ¬æ•¸**: {len(df_usa):,} ç­†è©•è«– (K=6)")
report_lines.append("")
report_lines.append("---")
report_lines.append("")

# Table 1: Rating Differences
report_lines.append("## ğŸ“Š Table 1: è©•åˆ†å·®ç•°çµ±è¨ˆæª¢é©— (Mann-Whitney U Test)")
report_lines.append("")
report_lines.append("| Universal Dimension | Taiwan | USA | Î” (US-TW) | U-statistic | p-value | Sig. | Effect Size (r) | Interpretation |")
report_lines.append("|---------------------|--------|-----|-----------|-------------|---------|------|-----------------|----------------|")

for result in statistical_results:
    report_lines.append(
        f"| **{result['Dimension']}** | "
        f"{result['TW_Mean']:.2f}â˜… (n={result['TW_N']}) | "
        f"{result['US_Mean']:.2f}â˜… (n={result['US_N']}) | "
        f"{result['Mean_Diff']:+.2f} | "
        f"{result['U_Statistic']:.0f} | "
        f"{result['p_value']:.6f} | "
        f"{result['Significance']} | "
        f"{result['Effect_Size_r']:.3f} | "
        f"{result['Interpretation']} |"
    )

report_lines.append("")
report_lines.append("**é¡¯è‘—æ€§æ¨™è¨˜**: *** p < 0.001, ** p < 0.01, * p < 0.05, n.s. = not significant")
report_lines.append("**Effect Size**: small (r < 0.3), medium (0.3 â‰¤ r < 0.5), large (r â‰¥ 0.5)")
report_lines.append("")
report_lines.append("---")
report_lines.append("")

# Table 2: Chi-square Test for H4
report_lines.append("## ğŸ“Š Table 2: æ€¥è¨ºä¸»é¡Œæ¯”ä¾‹å¡æ–¹æª¢é©— (H4)")
report_lines.append("")
report_lines.append("| Country | Emergency Topic | Other Topics | Total | Emergency % |")
report_lines.append("|---------|----------------|-------------|-------|-------------|")
report_lines.append(f"| **Taiwan** | {tw_emergency_count:,} | {tw_other_count:,} | {len(df_taiwan):,} | {tw_emergency_pct:.1f}% |")
report_lines.append(f"| **USA** | {us_emergency_count:,} | {us_other_count:,} | {len(df_usa):,} | {us_emergency_pct:.1f}% |")
report_lines.append("")
chi_sig_report = '***' if p_chi < 0.001 else '**' if p_chi < 0.01 else '*' if p_chi < 0.05 else 'n.s.'
report_lines.append(f"**å¡æ–¹æª¢é©—**: Ï‡Â²({dof}) = {chi2:.2f}, p = {p_chi:.6f} {chi_sig_report}")
report_lines.append(f"**Effect Size**: CramÃ©r's V = {cramers_v:.3f} ({cramers_interp})")
report_lines.append(f"**å·®ç•°**: ç¾åœ‹æ¯”å°ç£é«˜ {us_emergency_pct - tw_emergency_pct:+.1f} å€‹ç™¾åˆ†é»")
report_lines.append("")

if p_chi < 0.05:
    report_lines.append(f"âœ… **H4 çµè«–**: **æ”¯æŒå‡è¨­** - ç¾åœ‹è©•è«–é¡¯è‘—æ›´é—œæ³¨æ€¥è¨ºç­‰å¾…æ™‚é–“èˆ‡æ•ˆç‡ (p < 0.05)")
else:
    report_lines.append(f"âŒ **H4 çµè«–**: ä¸æ”¯æŒå‡è¨­ - æ¯”ä¾‹å·®ç•°ä¸é¡¯è‘— (p = {p_chi:.3f})")

report_lines.append("")
report_lines.append("---")
report_lines.append("")

# Key Findings
report_lines.append("## ğŸ” é—œéµç™¼ç¾")
report_lines.append("")
report_lines.append("### 1. æ€¥è¨ºç…§è­· (Emergency Care)")
tw_emerg = [r for r in statistical_results if r['Dimension'] == 'Emergency Care'][0]
report_lines.append(f"- **å°ç£**: {tw_emerg['TW_Mean']:.2f}â˜… (æ‰€æœ‰ä¸»é¡Œä¸­è©•åˆ†æ¥µä½)")
report_lines.append(f"- **ç¾åœ‹**: {tw_emerg['US_Mean']:.2f}â˜…")
report_lines.append(f"- **å·®ç•°**: ç¾åœ‹æ¯”å°ç£é«˜ {tw_emerg['Mean_Diff']:.2f}â˜… ({tw_emerg['Significance']})")
report_lines.append(f"- **è§£é‡‹**: å°ç£å–®ä¸€æ”¯ä»˜è€…åˆ¶åº¦ä¸‹ï¼Œæ€¥è¨ºå®¤äººæ»¿ç‚ºæ‚£ï¼Œç­‰å¾…æ™‚é–“æ›´é•·ï¼Œæ‚£è€…æ»¿æ„åº¦æ›´ä½")
report_lines.append("")

report_lines.append("### 2. è­·ç†/å°ˆæ¥­ç…§è­· (Nursing/Professional Care)")
tw_nurs = [r for r in statistical_results if r['Dimension'] == 'Nursing/Professional Care'][0]
report_lines.append(f"- **å°ç£**: {tw_nurs['TW_Mean']:.2f}â˜…")
report_lines.append(f"- **ç¾åœ‹**: {tw_nurs['US_Mean']:.2f}â˜…")
report_lines.append(f"- **å·®ç•°**: å°ç£æ¯”ç¾åœ‹é«˜ {-tw_nurs['Mean_Diff']:.2f}â˜… ({tw_nurs['Significance']})")
report_lines.append(f"- **è§£é‡‹**: å°ç£é†«è­·å°ˆæ¥­å“è³ªç²é«˜åº¦è‚¯å®šï¼Œå¯èƒ½å—æ–‡åŒ–å› ç´ å½±éŸ¿ï¼ˆé«˜æ¬ŠåŠ›è·é›¢ã€å°Šé‡é†«è­·ï¼‰")
report_lines.append("")

report_lines.append("### 3. é–€è¨ºæœå‹™ (Outpatient Services)")
tw_outp = [r for r in statistical_results if r['Dimension'] == 'Outpatient Services'][0]
report_lines.append(f"- **å°ç£**: {tw_outp['TW_Mean']:.2f}â˜… (é—œæ³¨**è¡Œæ”¿æµç¨‹æ•ˆç‡**)")
report_lines.append(f"- **ç¾åœ‹**: {tw_outp['US_Mean']:.2f}â˜… (é—œæ³¨**è‡¨åºŠå“è³ª**)")
report_lines.append(f"- **å·®ç•°**: ç¾åœ‹æ¯”å°ç£é«˜ {tw_outp['Mean_Diff']:.2f}â˜… ({tw_outp['Significance']})")
report_lines.append("")

report_lines.append("### 4. ä½é™¢/é‡ç—‡ç…§è­· (Inpatient/Critical Care)")
tw_inp = [r for r in statistical_results if r['Dimension'] == 'Inpatient/Critical Care'][0]
report_lines.append(f"- **å°ç£**: {tw_inp['TW_Mean']:.2f}â˜… (ä¸€èˆ¬ä½é™¢)")
report_lines.append(f"- **ç¾åœ‹**: {tw_inp['US_Mean']:.2f}â˜… (é‡ç—‡ç…§è­·)")
report_lines.append(f"- **å·®ç•°**: ç¾åœ‹æ¯”å°ç£é«˜ {tw_inp['Mean_Diff']:.2f}â˜… ({tw_inp['Significance']})")
report_lines.append("")

report_lines.append("---")
report_lines.append("")
report_lines.append("## ğŸ“ ç ”ç©¶å•é¡Œå›ç­”")
report_lines.append("")
report_lines.append("### RQ3: How do healthcare system structures influence satisfaction?")
report_lines.append("")
report_lines.append("**å–®ä¸€æ”¯ä»˜è€…åˆ¶åº¦ï¼ˆå°ç£ï¼‰**:")
report_lines.append("- âœ… å¯èƒ½å„ªå‹¢: å°ˆæ¥­å“è³ªè©•åˆ†ç›¸å°è¼ƒé«˜")
report_lines.append("- âš ï¸ åŠ£å‹¢: æ€¥è¨ºè©•åˆ†ä½ï¼Œæ¯”ç¾åœ‹ä½é¡¯è‘—å·®è·")
report_lines.append("- âš ï¸ åŠ£å‹¢: è¡Œæ”¿æµç¨‹æ•ˆç‡ä½")
report_lines.append("")
report_lines.append("**å¤šæ”¯ä»˜è€…åˆ¶åº¦ï¼ˆç¾åœ‹ï¼‰**:")
report_lines.append("- âœ… å„ªå‹¢: æ€¥è¨ºè©•åˆ†è¼ƒé«˜ï¼ˆé›–ä»æ˜¯ç—›é»ï¼‰")
report_lines.append("- âš ï¸ åŠ£å‹¢: è­·ç†å“è³ªè©•åˆ†ç›¸å°è¼ƒä½")
report_lines.append("- âš ï¸ åŠ£å‹¢: å¸³å–®ä¿éšªæˆç¨ç«‹ç—›é» (4.1%, 2.92â˜…)")
report_lines.append("")

report_lines.append("---")
report_lines.append("")
report_lines.append("## ğŸ’¡ çµè«–")
report_lines.append("")
report_lines.append("æ‰€æœ‰å››å€‹ universal dimensions çš„è©•åˆ†å·®ç•°å‡é”åˆ°çµ±è¨ˆé¡¯è‘—æ°´æº–ï¼ˆp < 0.05ï¼‰ï¼Œ")
report_lines.append("è­‰å¯¦é†«ç™‚é«”åˆ¶çµæ§‹ç¢ºå¯¦å°æ‚£è€…æ»¿æ„åº¦ç”¢ç”Ÿç³»çµ±æ€§å½±éŸ¿ã€‚")
report_lines.append("")
report_lines.append("**å ±å‘Šç”Ÿæˆå®Œæˆ**")
report_lines.append(f"**è³‡æ–™æª”æ¡ˆ**: {stats_output}")

# å„²å­˜å ±å‘Š
report_output = f'../../manuscripts/reports/Taiwan_USA_Statistical_Test_Report_{timestamp}.md'
with open(report_output, 'w', encoding='utf-8') as f:
    f.write('\n'.join(report_lines))

print(f"âœ“ çµ±è¨ˆæª¢é©—å ±å‘Šå·²å„²å­˜: {report_output}")

# ============================================================================
# å®Œæˆ
# ============================================================================
print("\n" + "="*80)
print("âœ… å°ç¾çµ±è¨ˆæª¢é©—åˆ†æå®Œæˆï¼")
print("="*80)
print(f"\nğŸ“Š ç”¢å‡ºæª”æ¡ˆ:")
print(f"  1. çµ±è¨ˆçµæœ CSV: {stats_output}")
print(f"  2. çµ±è¨ˆå ±å‘Š MD: {report_output}")
print("\nğŸ’¡ é€™äº›çµ±è¨ˆæª¢é©—çµæœå¯ä»¥ç›´æ¥å¼•ç”¨åˆ° Chapter 4 çš„ narrative ç‰ˆæœ¬ä¸­")
