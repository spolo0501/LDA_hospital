#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°ç£ã€ç¾åœ‹ã€è‹±åœ‹é†«é™¢æœå‹™å“è³ªä¸‰åœ‹æ¯”è¼ƒåˆ†æ
Taiwan, USA, UK Hospital Service Quality Comparison (K=7)
"""

import pickle
import pandas as pd
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("Three-Country Hospital Service Quality Comparison")
print("å°ç£ã€ç¾åœ‹ã€è‹±åœ‹é†«é™¢æœå‹™å“è³ªæ¯”è¼ƒåˆ†æ")
print("="*80)

# è¼‰å…¥ä¸‰åœ‹çš„ LDA æ¨¡å‹
print("\nğŸ“‚ Loading LDA models...")

# å°ç£
tw_model_path = Path("results/taiwan_lda_k7/lda_k7_lda_model.pkl")
with open(tw_model_path, 'rb') as f:
    tw_model = pickle.load(f)
print(f"âœ“ Taiwan model loaded")

# ç¾åœ‹
usa_model_path = Path("results/usa_lda_k7/usa_gensim_lda_k7_model.pkl")
with open(usa_model_path, 'rb') as f:
    usa_model = pickle.load(f)
print(f"âœ“ USA model loaded")

# è‹±åœ‹
uk_model_path = Path("results/uk_lda_k7/uk_gensim_lda_k7_model.pkl")
with open(uk_model_path, 'rb') as f:
    uk_model = pickle.load(f)
print(f"âœ“ UK model loaded")

# æ¨¡å‹å“è³ªæ¯”è¼ƒ
print(f"\n{'='*80}")
print("MODEL QUALITY COMPARISON | æ¨¡å‹å“è³ªæ¯”è¼ƒ")
print(f"{'='*80}")

comparison_data = []

# å°ç£
tw_info = tw_model.get('data_info', {})
comparison_data.append({
    'Country': 'Taiwan ğŸ‡¹ğŸ‡¼',
    'Reviews': tw_info.get('total_reviews', 'N/A'),
    'Hospitals': tw_info.get('total_hospitals', 26),
    'Avg_Rating': f"{tw_info.get('avg_rating', 0):.2f}",
    'Coherence': f"{tw_model['coherence_score']:.4f}",
    'Perplexity': f"{tw_model['perplexity_score']:.4f}",
    'Language': 'ä¸­æ–‡ (Chinese)'
})

# ç¾åœ‹
usa_info = usa_model.get('data_info', {})
comparison_data.append({
    'Country': 'USA ğŸ‡ºğŸ‡¸',
    'Reviews': usa_info.get('total_reviews', 'N/A'),
    'Hospitals': usa_info.get('total_hospitals', 'N/A'),
    'Avg_Rating': f"{usa_info.get('avg_rating', 0):.2f}" if 'avg_rating' in usa_info else 'N/A',
    'Coherence': f"{usa_model['coherence_score']:.4f}",
    'Perplexity': f"{usa_model['perplexity_score']:.4f}",
    'Language': 'English'
})

# è‹±åœ‹
uk_info = uk_model.get('data_info', {})
comparison_data.append({
    'Country': 'UK ğŸ‡¬ğŸ‡§',
    'Reviews': uk_info.get('total_reviews', 2135),
    'Hospitals': uk_info.get('total_hospitals', 20),
    'Avg_Rating': f"{uk_info.get('avg_rating', 3.35):.2f}",
    'Coherence': f"{uk_model['coherence_score']:.4f}",
    'Perplexity': f"{uk_model['perplexity_score']:.4f}",
    'Language': 'English'
})

comparison_df = pd.DataFrame(comparison_data)
print("\n")
print(comparison_df.to_string(index=False))

# ä¸»é¡Œé—œéµè©æ¯”è¼ƒ
print(f"\n{'='*80}")
print("TOPIC KEYWORDS COMPARISON | ä¸»é¡Œé—œéµè©æ¯”è¼ƒ")
print(f"{'='*80}")

print("\n" + "â”€"*80)
print("ğŸ‡¹ğŸ‡¼ TAIWAN | å°ç£")
print("â”€"*80)
tw_topics = tw_model['topics_keywords']
for topic in tw_topics:
    keywords = ', '.join(topic['top_words'][:8]) if isinstance(topic, dict) else ', '.join(topic[:8])
    print(f"Topic {topic['topic_id'] if isinstance(topic, dict) else tw_topics.index(topic)+1}: {keywords}")

print("\n" + "â”€"*80)
print("ğŸ‡ºğŸ‡¸ USA | ç¾åœ‹")
print("â”€"*80)
usa_topics = usa_model['topics_keywords']
for topic in usa_topics:
    keywords = ', '.join(topic['top_words'][:8]) if isinstance(topic, dict) else ', '.join(topic[:8])
    print(f"Topic {topic['topic_id'] if isinstance(topic, dict) else usa_topics.index(topic)+1}: {keywords}")

print("\n" + "â”€"*80)
print("ğŸ‡¬ğŸ‡§ UK | è‹±åœ‹")
print("â”€"*80)
uk_topics = uk_model['topics_keywords']
for topic in uk_topics:
    keywords = ', '.join(topic['top_words'][:8]) if isinstance(topic, dict) else ', '.join(topic[:8])
    print(f"Topic {topic['topic_id'] if isinstance(topic, dict) else uk_topics.index(topic)+1}: {keywords}")

# ä¸»é¡Œæ¨™è¨»ï¼ˆæ‰‹å‹•ï¼‰
print(f"\n{'='*80}")
print("TOPIC LABELING & ALIGNMENT | ä¸»é¡Œæ¨™è¨»èˆ‡å°é½Š")
print(f"{'='*80}")

# å°ç£ä¸»é¡Œæ¨™è¨»
tw_labels = {
    1: "é†«ç™‚å°ˆæ¥­èˆ‡æ…‹åº¦ (Medical Professionalism & Attitude)",
    2: "è¨ºç™‚æ•ˆç‡èˆ‡æµç¨‹ (Treatment Efficiency & Process)",
    3: "ç’°å¢ƒè¨­æ–½ (Facility & Environment)",
    4: "ç‰¹å®šé†«ç™‚æœå‹™ (Specific Medical Services)",
    5: "æ•´é«”å°±é†«ç¶“é©— (Overall Medical Experience)",
    6: "ç­‰å¾…æ™‚é–“ (Waiting Time)",
    7: "æœå‹™å“è³ªæ•´é«”è©•åƒ¹ (Overall Service Quality)"
}

# ç¾åœ‹ä¸»é¡Œæ¨™è¨»
usa_labels = {
    1: "é†«è­·å°ˆæ¥­èˆ‡æŠ€è¡“ (Medical Staff Professionalism)",
    2: "æ€¥è¨ºèˆ‡ç·Šæ€¥é†«ç™‚ (Emergency Care)",
    3: "è­·ç†ç…§è­·å“è³ª (Nursing Care Quality)",
    4: "é†«ç™‚æµç¨‹èˆ‡æºé€š (Medical Process & Communication)",
    5: "ç—…æ‚£ç¶“é©—èˆ‡æ»¿æ„åº¦ (Patient Experience & Satisfaction)",
    6: "ç‰¹å®šç§‘åˆ¥æœå‹™ (Specialized Department Services)",
    7: "æ•´é«”é†«ç™‚å“è³ª (Overall Medical Quality)"
}

# è‹±åœ‹ä¸»é¡Œæ¨™è¨»
uk_labels = {
    1: "é†«è­·å°ˆæ¥­èˆ‡ç…§è­·å“è³ª (Professional Care & Medical Excellence)",
    2: "ç­‰å¾…æ™‚é–“èˆ‡è³‡æºéœ€æ±‚ (Waiting Time & Resource Needs)",
    3: "æœå‹™æ…‹åº¦èˆ‡å‹å–„åº¦ (Service Attitude & Friendliness)",
    4: "ç‰¹å®šé†«ç™‚å•é¡Œ (Specific Medical Issues)",
    5: "æ„Ÿæ¿€èˆ‡æ­£é¢æƒ…ç·’ (Gratitude & Positive Emotions)",
    6: "è² é¢ç­‰å¾…ç¶“é©— (Negative Waiting Experience)",
    7: "éƒ¨é–€é‹ä½œèˆ‡ç®¡ç† (Department Operations & Management)"
}

print("\nğŸ‡¹ğŸ‡¼ Taiwan Topics:")
for i, label in tw_labels.items():
    print(f"  T{i}: {label}")

print("\nğŸ‡ºğŸ‡¸ USA Topics:")
for i, label in usa_labels.items():
    print(f"  U{i}: {label}")

print("\nğŸ‡¬ğŸ‡§ UK Topics:")
for i, label in uk_labels.items():
    print(f"  K{i}: {label}")

# ä¸»é¡Œçµ±è¨ˆæ¯”è¼ƒ
print(f"\n{'='*80}")
print("TOPIC STATISTICS COMPARISON | ä¸»é¡Œçµ±è¨ˆæ¯”è¼ƒ")
print(f"{'='*80}")

# å°ç£ä¸»é¡Œçµ±è¨ˆ
print("\nğŸ‡¹ğŸ‡¼ TAIWAN")
tw_summary = tw_model.get('topic_summary', [])
for topic in tw_summary:
    print(f"  Topic {topic['Topic_ID']}: {topic['Review_Count']:>5} reviews ({topic['Percentage']:>6}) - "
          f"Avg Rating: {topic['Avg_Rating']}")

# ç¾åœ‹ä¸»é¡Œçµ±è¨ˆ
print("\nğŸ‡ºğŸ‡¸ USA")
usa_summary = usa_model.get('topic_summary', [])
for topic in usa_summary:
    print(f"  Topic {topic['Topic_ID']}: {topic['Review_Count']:>5} reviews ({topic['Percentage']:>6}) - "
          f"Avg Rating: {topic['Avg_Rating']}")

# è‹±åœ‹ä¸»é¡Œçµ±è¨ˆ
print("\nğŸ‡¬ğŸ‡§ UK")
uk_summary = uk_model.get('topic_summary', [])
for topic in uk_summary:
    print(f"  Topic {topic['Topic_ID']}: {topic['Review_Count']:>5} reviews ({topic['Percentage']:>6}) - "
          f"Avg Rating: {topic['Avg_Rating']}")

# è·¨åœ‹ä¸»é¡Œå°é½Šï¼ˆåŸºæ–¼èªç¾©ç›¸ä¼¼æ€§ï¼‰
print(f"\n{'='*80}")
print("CROSS-COUNTRY TOPIC ALIGNMENT | è·¨åœ‹ä¸»é¡Œå°é½Š")
print(f"{'='*80}")

alignment = {
    "é†«è­·å°ˆæ¥­èƒ½åŠ›": {
        "Taiwan": ["T1", "T7"],
        "USA": ["U1", "U3", "U7"],
        "UK": ["K1"]
    },
    "ç­‰å¾…æ™‚é–“å•é¡Œ": {
        "Taiwan": ["T6"],
        "USA": [],
        "UK": ["K2", "K6", "K7"]
    },
    "è¨ºç™‚æµç¨‹æ•ˆç‡": {
        "Taiwan": ["T2"],
        "USA": ["U4"],
        "UK": ["K7"]
    },
    "ç’°å¢ƒèˆ‡è¨­æ–½": {
        "Taiwan": ["T3"],
        "USA": [],
        "UK": []
    },
    "æœå‹™æ…‹åº¦é—œæ‡·": {
        "Taiwan": ["T1"],
        "USA": ["U5"],
        "UK": ["K3", "K5"]
    },
    "ç‰¹å®šé†«ç™‚æœå‹™": {
        "Taiwan": ["T4"],
        "USA": ["U2", "U6"],
        "UK": ["K4"]
    },
    "æ•´é«”å°±é†«ç¶“é©—": {
        "Taiwan": ["T5"],
        "USA": ["U5"],
        "UK": ["K1", "K5"]
    }
}

for dimension, countries in alignment.items():
    print(f"\nğŸ“Š {dimension}")
    print(f"   Taiwan: {', '.join(countries['Taiwan']) if countries['Taiwan'] else 'ç„¡å°æ‡‰'}")
    print(f"   USA:    {', '.join(countries['USA']) if countries['USA'] else 'ç„¡å°æ‡‰'}")
    print(f"   UK:     {', '.join(countries['UK']) if countries['UK'] else 'ç„¡å°æ‡‰'}")

# å‰µå»ºæ¯”è¼ƒæ‘˜è¦è¡¨
print(f"\n{'='*80}")
print("SUMMARY COMPARISON TABLE | æ‘˜è¦æ¯”è¼ƒè¡¨")
print(f"{'='*80}")

summary_table = []

# å°ç£
tw_topics_count = len(tw_summary)
tw_avg_reviews_per_topic = sum([t['Review_Count'] for t in tw_summary]) / tw_topics_count
tw_rating_range = f"{min([float(t['Avg_Rating']) for t in tw_summary]):.2f} - {max([float(t['Avg_Rating']) for t in tw_summary]):.2f}"

# ç¾åœ‹
usa_topics_count = len(usa_summary)
usa_avg_reviews_per_topic = sum([t['Review_Count'] for t in usa_summary]) / usa_topics_count
usa_rating_range = f"{min([float(t['Avg_Rating']) for t in usa_summary]):.2f} - {max([float(t['Avg_Rating']) for t in usa_summary]):.2f}"

# è‹±åœ‹
uk_topics_count = len(uk_summary)
uk_avg_reviews_per_topic = sum([t['Review_Count'] for t in uk_summary]) / uk_topics_count
uk_rating_range = f"{min([float(t['Avg_Rating']) for t in uk_summary]):.2f} - {max([float(t['Avg_Rating']) for t in uk_summary]):.2f}"

summary_table.append({
    'Metric': 'Total Topics',
    'Taiwan': tw_topics_count,
    'USA': usa_topics_count,
    'UK': uk_topics_count
})

summary_table.append({
    'Metric': 'Avg Reviews/Topic',
    'Taiwan': f"{tw_avg_reviews_per_topic:.0f}",
    'USA': f"{usa_avg_reviews_per_topic:.0f}",
    'UK': f"{uk_avg_reviews_per_topic:.0f}"
})

summary_table.append({
    'Metric': 'Rating Range',
    'Taiwan': tw_rating_range,
    'USA': usa_rating_range,
    'UK': uk_rating_range
})

summary_df = pd.DataFrame(summary_table)
print("\n")
print(summary_df.to_string(index=False))

# å„²å­˜æ¯”è¼ƒçµæœ
output_dir = Path("results/comparison")
output_dir.mkdir(parents=True, exist_ok=True)

# å„²å­˜æ¯”è¼ƒæ‘˜è¦
comparison_summary = {
    'model_quality': comparison_df,
    'taiwan_topics': tw_summary,
    'usa_topics': usa_summary,
    'uk_topics': uk_summary,
    'taiwan_labels': tw_labels,
    'usa_labels': usa_labels,
    'uk_labels': uk_labels,
    'alignment': alignment
}

with open(output_dir / 'three_country_comparison.pkl', 'wb') as f:
    pickle.dump(comparison_summary, f)

print(f"\n{'='*80}")
print("COMPARISON COMPLETE | æ¯”è¼ƒåˆ†æå®Œæˆ")
print(f"{'='*80}")
print(f"\nâœ… Three-country comparison analysis completed")
print(f"âœ… ä¸‰åœ‹æ¯”è¼ƒåˆ†æå·²å®Œæˆ")
print(f"\nğŸ“ Output directory: {output_dir}")
print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {output_dir}")
